{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRhvwNoLQr1l",
        "outputId": "d7942ba3-e653-4f32-9318-c67aad1b2860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/249.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.5/249.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.0.208 tiktoken pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"The One Page Linux Manual.pdf\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "yCN2p_HlQuSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "texts = text_splitter.split_documents(pages)\n",
        "\n",
        "print(texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW9ujW6KQ5ma",
        "outputId": "0882cf48-b6ac-45c6-8016-93baa1c054ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='THE ONE     PAGE LINUX MANUALA summary of useful Linux commands\\nVersion 3.0 May 1999 squadron@powerup.com.au\\nStarting & Stopping\\nshutdown -h now Shutdown the system now and do not\\nreboot\\nhalt Stop all processes - same as above\\nshutdown -r 5 Shutdown the system in 5 minutes and\\nreboot\\nshutdown -r now Shutdown the system now and reboot\\nreboot Stop all processes and then reboot - same\\nas above\\nstartx Start the X system\\nAccessing & mounting file systems\\nmount -t iso9660 /dev/cdrom\\n/mnt/cdromMount the device cdrom\\nand call it cdrom under the\\n/mnt directory\\nmount -t msdos /dev/hdd\\n/mnt/ddriveMount hard disk “d” as a\\nmsdos file system and call\\nit ddrive under the /mnt\\ndirectory\\nmount -t vfat /dev/hda1\\n/mnt/cdriveMount hard disk “a” as a\\nVFAT file system and call it\\ncdrive under the /mnt\\ndirectory\\numount /mnt/cdrom Unmount the cdrom\\nFinding files and text within files\\nfind / -name  fname Starting with the root directory, look\\nfor the file called fname\\nfind / -name ”*fname* ” Starting with the root directory, look\\nfor the file containing the string fname\\nlocate missingfilename Find a file called missingfilename\\nusing the locate command - this\\nassumes you have already used the\\ncommand updatedb (see next)\\nupdatedb Create or update the database of files\\non all file systems attached to the linux\\nroot directory\\nwhich missingfilename Show the subdirectory containing the\\nexecutable file  called missingfilename\\ngrep textstringtofind\\n/dirStarting with the directory called dir ,\\nlook for and list all files containing\\ntextstringtofind\\nThe X Window System\\nxvidtune Run the X graphics tuning utility\\nXF86Setup Run the X configuration menu with\\nautomatic probing of graphics cards\\nXconfigurator Run another X configuration menu with\\nautomatic probing of graphics cards\\nxf86config Run a text based X configuration menu\\nMoving, copying, deleting & viewing files\\nls -l List files in current directory using\\nlong format\\nls -F List files in current directory and\\nindicate the file type\\nls -laC List all files in current directory in\\nlong format and display in columnsrm name Remove a file or directory called\\nname\\nrm -rf name Kill off an entire directory and all it’s\\nincludes files and subdirectories\\ncp filename\\n/home/dirnameCopy the file called filename to the\\n/home/dirname directory\\nmv filename\\n/home/dirnameMove the file called filename to the\\n/home/dirname directory\\ncat filetoview Display the file called filetoview\\nman -k keyword Display man pages containing\\nkeyword\\nmore filetoview Display the file called filetoview one\\npage at a time, proceed to next page\\nusing the spacebar\\nhead filetoview Display the first 10 lines of the file\\ncalled filetoview\\nhead -20 filetoview Display the first 20 lines of the file\\ncalled filetoview\\ntail filetoview Display the last 10 lines of the file\\ncalled filetoview\\ntail -20 filetoview Display the last 20 lines of the file\\ncalled filetoview\\nInstalling software for Linux\\nrpm -ihv name.rpm Install the rpm package called name\\nrpm -Uhv name.rpm Upgrade the rpm package called\\nname\\nrpm -e package Delete the rpm package called\\npackage\\nrpm -l package List the files in the package called\\npackage\\nrpm -ql package List the files and state the installed\\nversion of the package called\\npackage\\nrpm -i --force package Reinstall the rpm package called\\nname having deleted parts of it (not\\ndeleting using rpm -e)\\ntar -zxvf archive.tar.gz or\\ntar -zxvf archive.tgzDecompress the files contained in\\nthe zipped and tarred archive called\\narchive\\n./configure Execute the script preparing the\\ninstalled files for compiling\\nUser Administration\\nadduser accountname Create a new user call accountname\\npasswd accountname Give accountname a new password\\nsu Log in as superuser from current login\\nexit Stop being superuser and revert to\\nnormal user\\nLittle known tips and tricks\\nifconfig List ip addresses for all devices on\\nthe machine\\napropos subject List manual pages for subject\\nusermount Executes graphical application for\\nmounting and unmounting file\\nsystems' metadata={'source': 'The One Page Linux Manual.pdf', 'page': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f\"You have {len(texts)} documents\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5wpgZI0RKBJ",
        "outputId": "32d81147-4e31-4f02-978b-88e0b7e543a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 2 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#====="
      ],
      "metadata": {
        "id": "LY72xoXgRo8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Helllo, my name is Ala\\n Hello again\\n\\ntesting newline.\" > LLM.txt"
      ],
      "metadata": {
        "id": "JVro99tsRtYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load a long document\n",
        "with open('LLM.txt', encoding= 'unicode_escape') as f:\n",
        "    sample_text = f.read()"
      ],
      "metadata": {
        "id": "_d131J86RLtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=10,\n",
        "    length_function=len,\n",
        ")"
      ],
      "metadata": {
        "id": "VbD9oy4sRqKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.create_documents([sample_text])\n",
        "print(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCLacGWZRzJ1",
        "outputId": "011c0607-91a5-4240-a53c-0f51d5d63666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='Helllo, my name is Ala\\n Hello again', metadata={}), Document(page_content='testing newline.', metadata={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#======"
      ],
      "metadata": {
        "id": "hdbQYMtpSVdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX4fHM6uSkoy",
        "outputId": "bb6e8a8d-35c4-4e8c-cf16-89bac2141758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a long document\n",
        "with open('LLM.txt', encoding= 'unicode_escape') as f:\n",
        "    sample_text = f.read()\n",
        "\n",
        "from langchain.text_splitter import NLTKTextSplitter\n",
        "text_splitter = NLTKTextSplitter(chunk_size=500)\n",
        "\n",
        "\n",
        "texts = text_splitter.split_text(sample_text)\n",
        "print(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4-grTQDR0QY",
        "outputId": "efa3aee6-f08b-407e-d752-d9b221d333fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Helllo, my name is Ala\\n Hello again\\n\\ntesting newline.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#======"
      ],
      "metadata": {
        "id": "a5nzGYeLTbNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import SpacyTextSplitter\n",
        "\n",
        "\n",
        "# Load a long document\n",
        "with open('LLM.txt', encoding= 'unicode_escape') as f:\n",
        "    sample_text = f.read()\n",
        "\n",
        "# Instantiate the SpacyTextSplitter with the desired chunk size\n",
        "text_splitter = SpacyTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "\n",
        "\n",
        "# Split the text using SpacyTextSplitter\n",
        "texts = text_splitter.split_text(sample_text)\n",
        "\n",
        "# Print the first chunk\n",
        "print(texts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xooCnKxQSWnf",
        "outputId": "f6246710-1e99-4ae8-a009-4ffe5e87a44c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Helllo, my name is Ala\\n \\n\\nHello again\\n\\ntesting newline.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#====="
      ],
      "metadata": {
        "id": "QTOsrDcQYjza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import MarkdownTextSplitter\n",
        "markdown_text = \"\"\"\n",
        "#\n",
        "\n",
        "# Welcome to My Blog!\n",
        "\n",
        "## Introduction\n",
        "Hello everyone! My name is **John Doe** and I am a _software developer_. I specialize in Python, Java, and JavaScript.\n",
        "\n",
        "Here's a list of my favorite programming languages:\n",
        "\n",
        "1. Python\n",
        "2. JavaScript\n",
        "3. Java\n",
        "\n",
        "You can check out some of my projects on [GitHub](https://github.com).\n",
        "\n",
        "## About this Blog\n",
        "In this blog, I will share my journey as a software developer. I'll post tutorials, my thoughts on the latest technology trends, and occasional book reviews.\n",
        "\n",
        "Here's a small piece of Python code to say hello:\n",
        "\n",
        "\\``` python\n",
        "def say_hello(name):\n",
        "    print(f\"Hello, {name}!\")\n",
        "\n",
        "say_hello(\"John\")\n",
        "\\```\n",
        "\n",
        "Stay tuned for more updates!\n",
        "\n",
        "## Contact Me\n",
        "Feel free to reach out to me on [Twitter](https://twitter.com) or send me an email at johndoe@email.com.\n",
        "\n",
        "\"\"\"\n",
        "markdown_splitter = MarkdownTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "docs = markdown_splitter.create_documents([markdown_text])\n",
        "print(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rknT3Bk1Tb3z",
        "outputId": "f2cee5b7-4d85-4503-e84a-22c3264b08df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='# \\n\\n# Welcome to My Blog!', metadata={}), Document(page_content='Introduction', metadata={}), Document(page_content='Hello everyone! My name is **John Doe** and I am a _software developer_. I specialize in Python,', metadata={}), Document(page_content='Java, and JavaScript.', metadata={}), Document(page_content=\"Here's a list of my favorite programming languages:\\n\\n1. Python\\n2. JavaScript\\n3. Java\", metadata={}), Document(page_content='You can check out some of my projects on [GitHub](https://github.com).', metadata={}), Document(page_content='About this Blog', metadata={}), Document(page_content=\"In this blog, I will share my journey as a software developer. I'll post tutorials, my thoughts on\", metadata={}), Document(page_content='the latest technology trends, and occasional book reviews.', metadata={}), Document(page_content=\"Here's a small piece of Python code to say hello:\", metadata={}), Document(page_content='\\\\``` python\\ndef say_hello(name):\\n    print(f\"Hello, {name}!\")\\n\\nsay_hello(\"John\")\\n\\\\', metadata={}), Document(page_content='Stay tuned for more updates!', metadata={}), Document(page_content='Contact Me', metadata={}), Document(page_content='Feel free to reach out to me on [Twitter](https://twitter.com) or send me an email at', metadata={}), Document(page_content='johndoe@email.com.', metadata={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#====="
      ],
      "metadata": {
        "id": "FZ2g0KI2Zb-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import TokenTextSplitter\n",
        "\n",
        "# Load a long document\n",
        "with open('LLM.txt', encoding= 'unicode_escape') as f:\n",
        "    sample_text = f.read()\n",
        "\n",
        "# Initialize the TokenTextSplitter with desired chunk size and overlap\n",
        "text_splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=50)\n",
        "\n",
        "# Split into smaller chunks\n",
        "texts = text_splitter.split_text(sample_text)\n",
        "print(texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrZxTi2IYl94",
        "outputId": "3353aec4-d822-4752-c621-40b30d303b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helllo, my name is Ala\n",
            " Hello again\n",
            "\n",
            "testing newline.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GggTVv6oZeIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}