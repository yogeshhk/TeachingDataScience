{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jFmPv7qAk-h",
        "outputId": "b1295ed9-6be8-4771-c866-8d57dcfc6f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain==0.0.208 openai python-dotenv pyvis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "!echo \"OPENAI_API_KEY='<OPENAI_API_KEY>'\" > .env\n",
        "\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdhPiWF1CbhM",
        "outputId": "116ac638-6587-4e2f-ef86-7a9b0de10e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.graphs.networkx_graph import KG_TRIPLE_DELIMITER\n",
        "\n",
        "# Prompt template for knowledge triple extraction\n",
        "_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE = (\n",
        "    \"You are a networked intelligence helping a human track knowledge triples\"\n",
        "    \" about all relevant people, things, concepts, etc. and integrating\"\n",
        "    \" them with your knowledge stored within your weights\"\n",
        "    \" as well as that stored in a knowledge graph.\"\n",
        "    \" Extract all of the knowledge triples from the text.\"\n",
        "    \" A knowledge triple is a clause that contains a subject, a predicate,\"\n",
        "    \" and an object. The subject is the entity being described,\"\n",
        "    \" the predicate is the property of the subject that is being\"\n",
        "    \" described, and the object is the value of the property.\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"It's a state in the US. It's also the number 1 producer of gold in the US.\\n\\n\"\n",
        "    f\"Output: (Nevada, is a, state){KG_TRIPLE_DELIMITER}(Nevada, is in, US)\"\n",
        "    f\"{KG_TRIPLE_DELIMITER}(Nevada, is the number 1 producer of, gold)\\n\"\n",
        "    \"END OF EXAMPLE\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"I'm going to the store.\\n\\n\"\n",
        "    \"Output: NONE\\n\"\n",
        "    \"END OF EXAMPLE\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"Oh huh. I know Descartes likes to drive antique scooters and play the mandolin.\\n\"\n",
        "    f\"Output: (Descartes, likes to drive, antique scooters){KG_TRIPLE_DELIMITER}(Descartes, plays, mandolin)\\n\"\n",
        "    \"END OF EXAMPLE\\n\\n\"\n",
        "    \"EXAMPLE\\n\"\n",
        "    \"{text}\"\n",
        "    \"Output:\"\n",
        ")\n",
        "\n",
        "KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=_DEFAULT_KNOWLEDGE_TRIPLE_EXTRACTION_TEMPLATE,\n",
        ")\n",
        "\n",
        "# Instantiate the OpenAI model\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0.9)\n",
        "\n",
        "# Create an LLMChain using the knowledge triple extraction prompt\n",
        "chain = LLMChain(llm=llm, prompt=KNOWLEDGE_TRIPLE_EXTRACTION_PROMPT)\n",
        "\n",
        "# Run the chain with the specified text\n",
        "text = \"The city of Paris is the capital and most populous city of France. The Eiffel Tower is a famous landmark in Paris.\"\n",
        "triples = chain.run(text)\n",
        "\n",
        "print(triples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XvgMXSRCeNE",
        "outputId": "03ef0f44-20d9-4092-86d7-910bf0c331d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.llms.openai:Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (Paris, is the capital of, France)<|>(Paris, is the most populous city of, France)<|>(Paris, has a, Eiffel Tower)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_triples(response, delimiter=KG_TRIPLE_DELIMITER):\n",
        "    if not response:\n",
        "        return []\n",
        "    return response.split(delimiter)\n",
        "\n",
        "triples_list = parse_triples(triples)\n",
        "\n",
        "# Print the extracted relation triplets\n",
        "print(triples_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17DGISoLDkCt",
        "outputId": "cb379dcd-b798-4c2a-dd32-d59d62f41f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' (Paris, is the capital of, France)', '(Paris, is the most populous city of, France)', '(Eiffel Tower, is a, landmark)', '(Eiffel Tower, is in, Paris)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvis.network import Network\n",
        "import networkx as nx\n",
        "\n",
        "# Create a NetworkX graph from the extracted relation triplets\n",
        "def create_graph_from_triplets(triplets):\n",
        "    G = nx.DiGraph()\n",
        "    for triplet in triplets:\n",
        "        subject, predicate, obj = triplet.strip().split(',')\n",
        "        G.add_edge(subject.strip(), obj.strip(), label=predicate.strip())\n",
        "    return G\n",
        "\n",
        "# Convert the NetworkX graph to a PyVis network\n",
        "def nx_to_pyvis(networkx_graph):\n",
        "    pyvis_graph = Network(notebook=True, cdn_resources='remote')\n",
        "    for node in networkx_graph.nodes():\n",
        "        pyvis_graph.add_node(node)\n",
        "    for edge in networkx_graph.edges(data=True):\n",
        "        pyvis_graph.add_edge(edge[0], edge[1], label=edge[2][\"label\"])\n",
        "    return pyvis_graph\n",
        "\n",
        "triplets = [t.strip() for t in triples_list if t.strip()]\n",
        "graph = create_graph_from_triplets(triplets)\n",
        "pyvis_network = nx_to_pyvis(graph)\n",
        "\n",
        "# Customize the appearance of the graph\n",
        "pyvis_network.toggle_hide_edges_on_drag(True)\n",
        "pyvis_network.toggle_physics(False)\n",
        "pyvis_network.set_edge_smooth('discrete')\n",
        "\n",
        "# Show the interactive knowledge graph visualization\n",
        "pyvis_network.show(\"knowledge_graph.html\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "l93_tobPEAvs",
        "outputId": "6a3bf1ad-bbed-48ae-a497-98c93bd9fb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "knowledge_graph.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7eff48495960>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600px\"\n",
              "            src=\"knowledge_graph.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}