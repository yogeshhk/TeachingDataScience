{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docling documentation](https://ds4sd.github.io/docling/)   \n",
    "[Docling technical report](https://arxiv.org/abs/2408.09869)   \n",
    "[RAG with LlamaIndex](https://ds4sd.github.io/docling/examples/rag_llamaindex/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU or MPS is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA GPU is enabled: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS GPU is enabled.\")\n",
    "else:\n",
    "    raise EnvironmentError(\n",
    "        \"No GPU or MPS device found. Please check your environment and ensure GPU or MPS support is configured.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "\n",
    "!wget \"https://www.kone.es/Images/KONE%20Sustainability_tcm117-105566.pdf\" -O data/kone-sustainability-report-2023.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = \"./data/kone-sustainability-report-2023.pdf\"\n",
    "FIRST_10_PAGES = \"./data/report_10_page.pdf\"\n",
    "\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "reader = PdfReader(SOURCE)\n",
    "writer = PdfWriter()\n",
    "\n",
    "# Extract the first 10 pages\n",
    "for page_num in range(min(10, len(reader.pages))):\n",
    "    writer.add_page(reader.pages[page_num])\n",
    "\n",
    "# Save the extracted pages to a new PDF\n",
    "with open(FIRST_10_PAGES, 'wb') as output_pdf:\n",
    "    writer.write(output_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "\n",
    "# Define the source and output file paths\n",
    "SOURCE = SOURCE\n",
    "OUTPUT = Path(\"./data/page_25.pdf\")\n",
    "\n",
    "# Read the PDF file\n",
    "reader = PdfReader(SOURCE)\n",
    "writer = PdfWriter()\n",
    "\n",
    "# Ensure the requested page exists in the document\n",
    "if len(reader.pages) >= 24:\n",
    "    # Add page 24 (index 23 since it's 0-based)\n",
    "    writer.add_page(reader.pages[24])\n",
    "else:\n",
    "    print(\"The PDF does not contain 24 pages.\")\n",
    "\n",
    "# Save the extracted page to a new PDF file\n",
    "with OUTPUT.open('wb') as output_pdf:\n",
    "    writer.write(output_pdf)\n",
    "\n",
    "print(f\"Page 24 has been saved to {OUTPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pdf to markdown (default options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing first 10 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = DocumentConverter()\n",
    "result = converter.convert(FIRST_10_PAGES)\n",
    "#print(result.document.export_to_markdown)\n",
    "# Save to markdown\n",
    "\n",
    "output_dir = Path(\"parsed-doc\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "doc_filename = Path(FIRST_10_PAGES).stem\n",
    "\n",
    "\n",
    "md_filename = output_dir / f\"{doc_filename}.md\"\n",
    "result.document.save_as_markdown(md_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing just page 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DocumentConverter\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Convert the document\n",
    "#result = converter.convert(FIRST_10_PAGES)\n",
    "result = converter.convert(\"./data/page_24.pdf\")\n",
    "\n",
    "# Save markdown with embedded pictures\n",
    "doc_filename = Path(\".data/page_24.pdf\").stem\n",
    "md_filename = output_dir / f\"{doc_filename}.md\"\n",
    "result.document.save_as_markdown(md_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decoding the image from markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoded string\n",
    "encoded_string = \"/uni0043/uni0061/uni0072/uni0062/uni006F/uni006E/uni0020/uni0066/uni006F/uni006F/uni0074/uni0070/uni0072/uni0069/uni006E/uni0074/uni0020/uni0028/uni006B/uni0067/uni0043/uni004F/uniE0C0/uni0065/uni002F/uni0079/uni0065/uni0061/uni0072/uni0029\"\n",
    "# Decode the string\n",
    "def decode_unicode_string(encoded):\n",
    "    # Split the string by '/' and filter out empty parts\n",
    "    parts = [part for part in encoded.split(\"/\") if part.startswith(\"uni\")]\n",
    "    # Convert each Unicode point to a character\n",
    "    decoded = \"\".join([chr(int(part[3:], 16)) for part in parts])\n",
    "    return decoded\n",
    "\n",
    "# Get the decoded string\n",
    "decoded_string = decode_unicode_string(encoded_string)\n",
    "print(decoded_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pdf to markdown (advanced options)\n",
    "- https://ds4sd.github.io/docling/usage/\n",
    "- https://ds4sd.github.io/docling/installation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling_core.types.doc import ImageRefMode\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode, EasyOcrOptions, TesseractOcrOptions, OcrMacOptions\n",
    "from docling.datamodel.settings import settings\n",
    "\n",
    "output_dir = Path(\"parsed-doc-advanced\")\n",
    "\n",
    "IMAGE_RESOLUTION_SCALE = 2.0\n",
    "\n",
    "# Define pipeline options for PDF processing\n",
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_table_structure=True,  # Enable table structure detection\n",
    "    do_ocr=True,  # Enable OCR\n",
    "    # full page ocr and language selection\n",
    "    #ocr_options=EasyOcrOptions(force_full_page_ocr=True, lang=[\"en\"]),  # Use EasyOCR for OCR\n",
    "    ocr_options=TesseractOcrOptions(force_full_page_ocr=True, lang=[\"eng\"]),  # Uncomment to use Tesseract for OCR\n",
    "    #ocr_options = OcrMacOptions(force_full_page_ocr=True, lang=['en-US']),\n",
    "    table_structure_options=dict(\n",
    "        do_cell_matching=False,  # Use text cells predicted from table structure model\n",
    "        mode=TableFormerMode.ACCURATE  # Use more accurate TableFormer model\n",
    "    ),\n",
    "    generate_page_images=True,  # Enable page image generation\n",
    "    generate_picture_images=True,  # Enable picture image generation\n",
    "    images_scale=IMAGE_RESOLUTION_SCALE, # Set image resolution scale (scale=1 corresponds to a standard 72 DPI image)\n",
    ")\n",
    "\n",
    "# Initialize the DocumentConverter with the specified pipeline options\n",
    "doc_converter_global = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable the profiling to measure the time spent\n",
    "settings.debug.profile_pipeline_timings = True\n",
    "\n",
    "# Convert the document\n",
    "#result = doc_converter_global.convert(FIRST_10_PAGES)\n",
    "#result = doc_converter_global.convert(SOURCE)\n",
    "result = doc_converter_global.convert(\"./data/page_25.pdf\")\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "#doc_filename = Path(FIRST_10_PAGES).stem\n",
    "#doc_filename = Path(FIRST_10_PAGES).stem\n",
    "doc_filename = Path(\"./data/page_25.pdf\").stem\n",
    "\n",
    "# Save markdown with embedded pictures\n",
    "#md_filename = output_dir / f\"{doc_filename}.md\"\n",
    "md_filename = output_dir / f\"{doc_filename}-with-images.md\"\n",
    "#result.document.save_as_markdown(md_filename) # just shows there is image at this point, <!-- image -->\n",
    "result.document.save_as_markdown(md_filename, image_mode=ImageRefMode.EMBEDDED) # image is embedded with base64\n",
    "#result.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED) #artifacts folder is created with this\n",
    "\n",
    "_log.info(f\"Markdown content has been saved to {md_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "#conv_res = DocumentConverter().convert(FIRST_10_PAGES)\n",
    "#doc = conv_res.document\n",
    "\n",
    "chunker = HybridChunker(tokenizer=\"BAAI/bge-small-en-v1.5\")  # set tokenizer as needed\n",
    "chunk_iter = chunker.chunk(result.document)\n",
    "\n",
    "# Convert the iterator to a list to count the chunks\n",
    "chunks = list(chunk_iter)\n",
    "num_chunks = len(chunks)\n",
    "\n",
    "# Print the number of chunks\n",
    "print(f\"The document has been divided into {num_chunks} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [FAQs](https://ds4sd.github.io/docling/faq/)\n",
    "\n",
    "### [Command Line Syntaxes](https://ds4sd.github.io/docling/v2/#cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip show tesserocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run docling data/page_24.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run docling images/caltrain_schedule.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run docling https://www.kone.es/Images/KONE%20Sustainability_tcm117-105566.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  View the base64 encoded image via this [link](https://codebeautify.org/base64-to-image-converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# Base64 string (trim \"data:image/png;base64,\" if needed)\n",
    "base64_string = \"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\"\n",
    "\n",
    "# Decode the Base64 string\n",
    "image_data = base64.b64decode(base64_string)\n",
    "\n",
    "# Convert to an image and display\n",
    "image = Image.open(BytesIO(image_data))\n",
    "image.show()\n",
    "\n",
    "# Optionally save the image\n",
    "with open(\"decoded_image.png\", \"wb\") as file:\n",
    "    file.write(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base64 string (trim \"data:image/png;base64,\" if needed)\n",
    "base64_string = \"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\"\n",
    "\n",
    "# Decode the Base64 string\n",
    "image_data = base64.b64decode(base64_string)\n",
    "\n",
    "# Convert to an image and display\n",
    "image = Image.open(BytesIO(image_data))\n",
    "\n",
    "# Display the image inline\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scanned pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv run docling data/scanned-document.pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = doc_converter_global.convert(\"./data/scanned-document.pdf\")\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "#doc_filename = Path(FIRST_10_PAGES).stem\n",
    "#doc_filename = Path(FIRST_10_PAGES).stem\n",
    "doc_filename = Path(\"./data/scanned-document.pdf\").stem\n",
    "\n",
    "# Save markdown with embedded pictures\n",
    "md_filename = output_dir / f\"{doc_filename}.md\"\n",
    "result.document.save_as_markdown(md_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n",
    "from docling.datamodel.base_models import FigureElement, InputFormat, Table\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_doc_path = FIRST_10_PAGES\n",
    "output_dir = Path(\"scratch_image\")\n",
    "\n",
    "# Important: For operating with page images, we must keep them, otherwise the DocumentConverter\n",
    "# will destroy them for cleaning up memory.\n",
    "# This is done by setting PdfPipelineOptions.images_scale, which also defines the scale of images.\n",
    "# scale=1 correspond of a standard 72 DPI image\n",
    "# The PdfPipelineOptions.generate_* are the selectors for the document elements which will be enriched\n",
    "# with the image field\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n",
    "pipeline_options.generate_page_images = True\n",
    "pipeline_options.generate_picture_images = True\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "conv_res = doc_converter.convert(input_doc_path)\n",
    "\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "doc_filename = conv_res.input.file.stem\n",
    "\n",
    "# Save page images\n",
    "for page_no, page in conv_res.document.pages.items():\n",
    "    page_no = page.page_no\n",
    "    page_image_filename = output_dir / f\"{doc_filename}-{page_no}.png\"\n",
    "    with page_image_filename.open(\"wb\") as fp:\n",
    "        page.image.pil_image.save(fp, format=\"PNG\")\n",
    "\n",
    "# Save images of figures and tables\n",
    "table_counter = 0\n",
    "picture_counter = 0\n",
    "for element, _level in conv_res.document.iterate_items():\n",
    "    if isinstance(element, TableItem):\n",
    "        table_counter += 1\n",
    "        element_image_filename = (\n",
    "            output_dir / f\"{doc_filename}-table-{table_counter}.png\"\n",
    "        )\n",
    "        with element_image_filename.open(\"wb\") as fp:\n",
    "            element.get_image(conv_res.document).save(fp, \"PNG\")\n",
    "\n",
    "    if isinstance(element, PictureItem):\n",
    "        picture_counter += 1\n",
    "        element_image_filename = (\n",
    "            output_dir / f\"{doc_filename}-picture-{picture_counter}.png\"\n",
    "        )\n",
    "        with element_image_filename.open(\"wb\") as fp:\n",
    "            element.get_image(conv_res.document).save(fp, \"PNG\")\n",
    "\n",
    "# Save markdown with embedded pictures\n",
    "md_filename = output_dir / f\"{doc_filename}-with-images.md\"\n",
    "conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.EMBEDDED)\n",
    "\n",
    "# Save markdown with externally referenced pictures\n",
    "md_filename = output_dir / f\"{doc_filename}-with-image-refs.md\"\n",
    "conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "# Save HTML with externally referenced pictures\n",
    "html_filename = output_dir / f\"{doc_filename}-with-image-refs.html\"\n",
    "conv_res.document.save_as_html(html_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "_log.info(f\"Document converted and figures exported in {end_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    input_doc_path = FIRST_10_PAGES\n",
    "    output_dir = Path(\"scratch_table\")\n",
    "\n",
    "    doc_converter = DocumentConverter()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    conv_res = doc_converter.convert(input_doc_path)\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    doc_filename = conv_res.input.file.stem\n",
    "\n",
    "    # Export tables\n",
    "    for table_ix, table in enumerate(conv_res.document.tables):\n",
    "        table_df: pd.DataFrame = table.export_to_dataframe()\n",
    "\n",
    "        # Save the table as csv\n",
    "        element_csv_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.csv\"\n",
    "        _log.info(f\"Saving CSV table to {element_csv_filename}\")\n",
    "        table_df.to_csv(element_csv_filename)\n",
    "\n",
    "        # Save the table as html\n",
    "        element_html_filename = output_dir / f\"{doc_filename}-table-{table_ix+1}.html\"\n",
    "        _log.info(f\"Saving HTML table to {element_html_filename}\")\n",
    "        with element_html_filename.open(\"w\") as fp:\n",
    "            fp.write(table.export_to_html())\n",
    "\n",
    "    end_time = time.time() - start_time\n",
    "\n",
    "    _log.info(f\"Document converted and tables exported in {end_time:.2f} seconds.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup with LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup llm\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3:latest\", request_timeout=120.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup embedding model\n",
    "# https://docs.llamaindex.ai/en/stable/examples/embeddings/ollama_embedding/\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "\n",
    "#embed_model = OllamaEmbedding(model_name=\"nomic-embed-text:latest\")\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Global Settings Configuration\n",
    "In LlamaIndex, you can define global settings so you don't have to pass the LLM / embedding model objects everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve and Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.readers.docling import DoclingReader\n",
    "\n",
    "#reader = DoclingReader()\n",
    "reader = DoclingReader(DocumentConverter = doc_converter_global)\n",
    "node_parser = MarkdownNodeParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = reader.load_data(SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_parser.get_nodes_from_documents??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract nodes from documents\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# Display the number of nodes extracted\n",
    "print(f\"Number of nodes extracted: {len(nodes)}\")\n",
    "\n",
    "\n",
    "# Iterate over each node to print its text and metadata\n",
    "for index, node in enumerate(nodes, start=1):\n",
    "    print(f\"\\nNode {index}:\")\n",
    "    print(\"Text:\")\n",
    "    print(node.text)\n",
    "    print(\"Metadata:\")\n",
    "    print(node.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VectorStoreIndex.from_documents??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.llamaindex.ai/en/stable/examples/data_connectors/DoclingReaderDemo/\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=documents,\n",
    "    transformations=[node_parser],\n",
    "    embed_model=embed_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"In how many countries does KONE operate ?\"\n",
    "result = index.as_query_engine(llm=llm).query(QUERY)\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "\n",
    "# Prettify the output using Rich\n",
    "console = Console()\n",
    "\n",
    "console.print(\n",
    "    Panel(f\"{QUERY}\".replace(\"{text}\", QUERY), title=\"Prompt\", border_style=\"bold red\")\n",
    ")\n",
    "console.print(\n",
    "    Panel(result.response.strip(), title=\"Generated Content\", border_style=\"bold green\")\n",
    ")\n",
    "\n",
    "#print(f\"Q: {QUERY}\\nA: {result.response.strip()}\\n\\nSources:\")\n",
    "display([(n.text, n.metadata) for n in result.source_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your list of queries\n",
    "queries = [\n",
    "    \"In how many countries does KONE operate?\", #2\n",
    "    \"What is the share of landfill waste at KONE's manufacturing units in 2023?\", #67\n",
    "    \"What is the plastics and rubbers content in monospace 700 dx elevator?\", #25\n",
    "    \"What are the ways to win areas ?\", #12\n",
    "    \"Who is the CEO of KONE?\" #4\n",
    "]\n",
    "\n",
    "# Initialize the query engine\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "\n",
    "# Iterate over each query, process it, and print the results\n",
    "for query in queries:\n",
    "    result = query_engine.query(query)\n",
    "    print(f\"Q: {query}\\nA: {result.response.strip()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
