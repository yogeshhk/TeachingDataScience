{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract faces from pictures of people \n",
    "### Instrutions:\n",
    "- Place photos of people (one face visible) in the folder called \"./people\"\n",
    "- Replace my photo titled \"Rajeev.jpg\" with a piture of your face for testing on a webcam\n",
    "- Faces are extracted using the haarcascade_frontalface_default detector model\n",
    "- Extracted faces are placed in the folder called \"./group_of_faces\"\n",
    "#### We are extracting the faces needed for our one-shot learning model, it will load 5 extracted faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected image names\n"
     ]
    }
   ],
   "source": [
    "# The code below extracts faces from images and places them in the folder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "# Loading out HAARCascade Face Detector \n",
    "face_detector = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Directory of image of persons we'll be extracting faces frommy\n",
    "mypath = \"./people/\"\n",
    "image_file_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(\"Collected image names\")\n",
    "\n",
    "for image_name in image_file_names:\n",
    "    person_image = cv2.imread(mypath+image_name)\n",
    "    face_info = face_detector.detectMultiScale(person_image, 1.3, 5)\n",
    "    for (x,y,w,h) in face_info:\n",
    "        face = person_image[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(face, (128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "    path = \"./group_of_faces/\" + \"face_\" + image_name \n",
    "    cv2.imwrite(path, roi)\n",
    "    cv2.imshow(\"face\", roi)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load our VGGFaceModel \n",
    "- This block of code defines the VGGFace model (which we use later) and loads the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "#author Sefik Ilkin Serengil\n",
    "#you can find the documentation of this code from the following link: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Loads image from path and resizes it\"\"\"\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "#you can download pretrained weights from https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "from tensorflow.keras.models import model_from_json\n",
    "model.load_weights('vgg_face_weights.h5')\n",
    "\n",
    "vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
    "\n",
    "model = vgg_face_descriptor\n",
    "\n",
    " \n",
    "print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test model using your Webcam\n",
    "This code looks up the faces you extracted in the \"group_of_faces\" folder and uses the similarity (Cosine Similarity) to detect which faces is most similar to the one being extracted with your webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face representations retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "#points to your extracted faces\n",
    "people_pictures = \"./group_of_faces/\"\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_people_faces[person_face] = model.predict(preprocess_image('./group_of_faces/%s.jpg' % (person_face)))[0,:]\n",
    "\n",
    "print(\"Face representations retrieved successfully\")\n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "#Open Webcam\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    faces = face_detector.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        if w > 100: #Adjust accordingly if your webcam resoluation is higher\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) #draw rectangle to main image\n",
    "            detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "            detected_face = cv2.resize(detected_face, (224, 224)) #resize to 224x224\n",
    "\n",
    "            img_pixels = image.img_to_array(detected_face)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "            img_pixels /= 255\n",
    "\n",
    "            captured_representation = model.predict(img_pixels)[0,:]\n",
    "\n",
    "            found = 0\n",
    "            for i in all_people_faces:\n",
    "                person_name = i\n",
    "                representation = all_people_faces[i]\n",
    "\n",
    "                similarity = findCosineSimilarity(representation, captured_representation)\n",
    "                if(similarity < 0.30):\n",
    "                    cv2.putText(img, person_name[5:], (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    found = 1\n",
    "                    break\n",
    "\n",
    "            #connect face and text\n",
    "            cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "            cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "            if(found == 0): #if found image is not in our people database\n",
    "                cv2.putText(img, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on a video\n",
    "### Since we're using the Friends TV Series characters, let's extract the faces from the images I placed in the \"./friends\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected image names\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import cv2\n",
    "\n",
    "# Loading out HAARCascade Face Detector \n",
    "face_detector = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Directory of image of persons we'll be extracting faces frommy\n",
    "mypath = \"./friends/\"\n",
    "image_file_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(\"Collected image names\")\n",
    "\n",
    "for image_name in image_file_names:\n",
    "    person_image = cv2.imread(mypath+image_name)\n",
    "    face_info = face_detector.detectMultiScale(person_image, 1.3, 5)\n",
    "    for (x,y,w,h) in face_info:\n",
    "        face = person_image[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(face, (128, 128), interpolation = cv2.INTER_CUBIC)\n",
    "    path = \"./friends_faces/\" + \"face_\" + image_name \n",
    "    cv2.imwrite(path, roi)\n",
    "    cv2.imshow(\"face\", roi)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, we load our faces from the \"friends_faces\" directory and we run our face classifier model our test video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face representations retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "#points to your extracted faces\n",
    "people_pictures = \"./friends_faces/\"\n",
    "\n",
    "all_people_faces = dict()\n",
    "\n",
    "for file in listdir(people_pictures):\n",
    "    person_face, extension = file.split(\".\")\n",
    "    all_people_faces[person_face] = model.predict(preprocess_image('./friends_faces/%s.jpg' % (person_face)))[0,:]\n",
    "\n",
    "print(\"Face representations retrieved successfully\")\n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "\n",
    "cap = cv2.VideoCapture('testfriends.mp4')\n",
    "\n",
    "while(True):\n",
    "        ret, img = cap.read()\n",
    "        img = cv2.resize(img, (320, 180)) # Re-size video to as smaller size to improve face detection speed\n",
    "        faces = face_detector.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            if w > 13: \n",
    "                cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) #draw rectangle to main image\n",
    "\n",
    "                detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "                detected_face = cv2.resize(detected_face, (224, 224)) #resize to 224x224\n",
    "\n",
    "                img_pixels = image.img_to_array(detected_face)\n",
    "                img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "                img_pixels /= 255\n",
    "\n",
    "                captured_representation = model.predict(img_pixels)[0,:]\n",
    "\n",
    "                found = 0\n",
    "                for i in all_people_faces:\n",
    "                    person_name = i\n",
    "                    representation = all_people_faces[i]\n",
    "\n",
    "                    similarity = findCosineSimilarity(representation, captured_representation)\n",
    "                    if(similarity < 0.30):\n",
    "                        cv2.putText(img, person_name[5:], (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                        found = 1\n",
    "                        break\n",
    "\n",
    "                #connect face and text\n",
    "                cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "                cv2.line(img,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "                if(found == 0): #if found image is not in our people database\n",
    "                    cv2.putText(img, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow('img',img)\n",
    "        if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "            break\n",
    "\n",
    "#kill open cv things\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
