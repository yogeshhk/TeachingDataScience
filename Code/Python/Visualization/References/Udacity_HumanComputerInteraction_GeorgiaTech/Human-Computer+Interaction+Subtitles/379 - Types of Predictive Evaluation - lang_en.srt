1
00:00:00,000 --> 00:00:01,710
When we talk about design principles,

2
00:00:01,710 --> 00:00:05,730
we talked about several heuristics and guidelines we use in designing interfaces.

3
00:00:05,730 --> 00:00:08,970
The first method for predictive evaluation is simply to hand

4
00:00:08,970 --> 00:00:12,345
our interface and these guidelines to a few experts to evaluate.

5
00:00:12,345 --> 00:00:14,745
This is called heuristic evaluation.

6
00:00:14,745 --> 00:00:17,880
Each individual evaluator inspects the interface alone,

7
00:00:17,880 --> 00:00:21,315
and identifies places where the interface violates some heuristic.

8
00:00:21,315 --> 00:00:23,300
We might sit with an expert while they perform

9
00:00:23,300 --> 00:00:25,855
the evaluation or they might generate our report.

10
00:00:25,855 --> 00:00:27,800
Heuristics are useful because they give us

11
00:00:27,800 --> 00:00:31,445
small snapshots into the way people might think about our interfaces.

12
00:00:31,445 --> 00:00:33,920
If we take these heuristics to an extreme though,

13
00:00:33,920 --> 00:00:38,525
we could go so far as to develop models of the way people think about our interfaces.

14
00:00:38,525 --> 00:00:40,340
During our need-finding exercises,

15
00:00:40,340 --> 00:00:42,860
we developed models of our users tasks.

16
00:00:42,860 --> 00:00:45,890
In model-based evaluation, we take these models and

17
00:00:45,890 --> 00:00:49,025
trace through it in the context of the interface that we designed.

18
00:00:49,025 --> 00:00:51,380
So, let's use a Gomez model for example,

19
00:00:51,380 --> 00:00:55,100
just we computed a Gomez model for what users data in some context,

20
00:00:55,100 --> 00:00:58,790
we can also compute a Gomez model for what they will do in our new interface.

21
00:00:58,790 --> 00:01:01,880
Then, we can compare these models side-by-side to see how

22
00:01:01,880 --> 00:01:05,650
our interface changes the task and evaluate whether a deficiency.

23
00:01:05,650 --> 00:01:07,760
So here, the classical way of disabling

24
00:01:07,760 --> 00:01:10,400
an alarm was to use a keypad mountain near the door.

25
00:01:10,400 --> 00:01:13,100
We could use this Gomez model to evaluate whether or not

26
00:01:13,100 --> 00:01:16,965
the new keychain interface was actually more efficient than the keypad interface.

27
00:01:16,965 --> 00:01:19,610
We can also use the profiles of users that we

28
00:01:19,610 --> 00:01:23,120
developed to evaluate whether the new design meets each criteria.

29
00:01:23,120 --> 00:01:26,240
For example, imagine if we identified this model as

30
00:01:26,240 --> 00:01:29,810
applying to users with low motivation to use this interface?

31
00:01:29,810 --> 00:01:32,510
Maybe it's people doing purchases that they have to do for work,

32
00:01:32,510 --> 00:01:34,370
as opposed to just shopping at their leisure.

33
00:01:34,370 --> 00:01:36,950
We can use that to inform our evaluation of

34
00:01:36,950 --> 00:01:39,905
whether or not the interface relies on high user motivation.

35
00:01:39,905 --> 00:01:42,350
If we find that the interface requires users to be

36
00:01:42,350 --> 00:01:44,960
more personally driven or to keep more in working memory,

37
00:01:44,960 --> 00:01:47,210
then we might find that the users will fail if

38
00:01:47,210 --> 00:01:49,520
they don't have high motivation to use the interface,

39
00:01:49,520 --> 00:01:51,065
and then we can revise it accordingly.

40
00:01:51,065 --> 00:01:54,010
If we take model-based evaluation to an extreme though,

41
00:01:54,010 --> 00:01:57,350
we can actually get to the point of simulation-based evaluation.

42
00:01:57,350 --> 00:01:59,030
At that point, we might construct

43
00:01:59,030 --> 00:02:00,905
an artificially intelligent agent that

44
00:02:00,905 --> 00:02:03,640
interacts with our interface in the way that a human would.

45
00:02:03,640 --> 00:02:07,430
Melody Ivory and Marti Hearst actually did some research on this back in 2001,

46
00:02:07,430 --> 00:02:11,950
on The State of the Art In Automating Usability Evaluation of User Interfaces.

47
00:02:11,950 --> 00:02:14,090
That seems like an amazing undertaking given

48
00:02:14,090 --> 00:02:16,910
how flexible and varied user interfaces can actually be.

49
00:02:16,910 --> 00:02:18,875
Can we really evaluate them automatically?

50
00:02:18,875 --> 00:02:23,270
More recently, work has even been done to create even more human-like models of users,

51
00:02:23,270 --> 00:02:25,490
like some work done by the Human-Centered Design Group

52
00:02:25,490 --> 00:02:28,040
at the Institute for Information Technology in Germany.

53
00:02:28,040 --> 00:02:30,930
Developing that agent is an enormous task on it's own,

54
00:02:30,930 --> 00:02:33,350
but if we're working on a big long-term project like

55
00:02:33,350 --> 00:02:36,440
Facebook or in a high-stakes environment like air traffic control,

56
00:02:36,440 --> 00:02:39,470
having a simulation of a human that we can run hundreds of thousands of

57
00:02:39,470 --> 00:02:42,820
times on different interface prototypes would be extremely useful.

