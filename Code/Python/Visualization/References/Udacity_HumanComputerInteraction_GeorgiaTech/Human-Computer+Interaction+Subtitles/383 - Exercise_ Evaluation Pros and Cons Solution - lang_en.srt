1
00:00:00,190 --> 00:00:02,480
Here would be my answers
to this exercise.

2
00:00:02,480 --> 00:00:05,536
These are a little bit more objective
than some of our exercises in the past.

3
00:00:05,536 --> 00:00:09,950
First, if it does not require any actual
users, predictive evaluation is the only

4
00:00:09,950 --> 00:00:13,878
evaluation we can do without involving
users in the evaluation process.

5
00:00:13,878 --> 00:00:16,490
That's both its biggest strength and
its biggest weakness.

6
00:00:16,490 --> 00:00:18,466
For identifying provable advantages,

7
00:00:18,466 --> 00:00:22,418
only empirical evaluation can reliably
generate generalizable conclusions,

8
00:00:22,418 --> 00:00:26,870
generalizable advantages, because it's
the only one who does it numerically.

9
00:00:26,870 --> 00:00:29,434
As far as informing ongoing
design decisions is concerned,

10
00:00:29,434 --> 00:00:32,618
that's definitely the case for
qualitative and predictive evaluation.

11
00:00:32,618 --> 00:00:36,151
I've left it unmarked for empirical
evaluation simply because we usually do

12
00:00:36,151 --> 00:00:38,269
this towards the end of
our design life cycle,

13
00:00:38,269 --> 00:00:41,387
although we also know that the design
life cycle never really ends.

14
00:00:41,387 --> 00:00:42,165
So eventually,

15
00:00:42,165 --> 00:00:45,620
empirical evaluation could be used
to inform ongoing design decisions.

16
00:00:45,620 --> 00:00:49,500
It's just not involved in the earlier
cycles though the design life cycle.

17
00:00:49,500 --> 00:00:52,152
As far as investing the participant's
thought process, again,

18
00:00:52,152 --> 00:00:54,105
empirical evaluation
doesn't really do that.

19
00:00:54,105 --> 00:00:56,713
It only accesses participants
performance numerically.

20
00:00:56,713 --> 00:01:00,370
Qualitative evaluation definitely does
this, because it actually asks users

21
00:01:00,370 --> 00:01:03,080
to think out lout and
describe their thought process.

22
00:01:03,080 --> 00:01:06,310
And really, predictive evaluation tries
to investigate the participant's thought

23
00:01:06,310 --> 00:01:10,400
process, just in a lower overhead,
or lower cost kind of way.

24
00:01:10,400 --> 00:01:13,490
It does so by having experts
in usability design simulate

25
00:01:13,490 --> 00:01:15,070
the participant's thought process, and

26
00:01:15,070 --> 00:01:18,230
comment on it from the perspective
of some preset heuristics.

27
00:01:18,230 --> 00:01:21,760
Similar to how only empirical evaluation
can identify provable advantages,

28
00:01:21,760 --> 00:01:24,590
it's also the only one that can
provide generalizable conclusions,

29
00:01:24,590 --> 00:01:26,510
again because it uses numbers.

30
00:01:26,510 --> 00:01:27,700
And finally, qualitative and

31
00:01:27,700 --> 00:01:30,960
empirical evaluations both draw
conclusions from actual participants.

32
00:01:30,960 --> 00:01:34,680
This is the inverse of predictive
evaluations, lack of requirement for

33
00:01:34,680 --> 00:01:35,260
actual users.

