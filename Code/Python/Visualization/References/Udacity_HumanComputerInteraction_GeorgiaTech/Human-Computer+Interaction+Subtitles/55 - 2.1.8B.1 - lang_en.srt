1
00:00:00,000 --> 00:00:03,240
To better understand how we might use these three views of the user,

2
00:00:03,240 --> 00:00:06,180
let's see how we might apply them to a design challenge.

3
00:00:06,180 --> 00:00:10,710
So, here we have the address entry screen on Tesla's Model S. At the top,

4
00:00:10,710 --> 00:00:13,245
we have the text box that the user is entering text into.

5
00:00:13,245 --> 00:00:14,895
Below, we have some results.

6
00:00:14,895 --> 00:00:18,620
At the bottom, we have the keyboard that they actually use to enter their text.

7
00:00:18,620 --> 00:00:21,680
Let's imagine we're trying to redesign it such that the user can enter

8
00:00:21,680 --> 00:00:23,780
the address of their target destination more

9
00:00:23,780 --> 00:00:26,285
quickly so that they can get on with navigation.

10
00:00:26,285 --> 00:00:27,700
With the processor model,

11
00:00:27,700 --> 00:00:30,360
we're strictly looking at the user's observable behavior.

12
00:00:30,360 --> 00:00:33,980
So, we might construct a controlled study where we bring participants in,

13
00:00:33,980 --> 00:00:36,739
give them addresses to enter and different interfaces to use,

14
00:00:36,739 --> 00:00:38,945
and time them on different versions.

15
00:00:38,945 --> 00:00:41,260
Whichever interface has the fastest times

16
00:00:41,260 --> 00:00:43,385
would be the interface we might want to go with.

17
00:00:43,385 --> 00:00:45,410
There are some benefits to using this model.

18
00:00:45,410 --> 00:00:49,475
One big one is that we might actually be able to use existing data for this.

19
00:00:49,475 --> 00:00:52,130
If we assume that every time a user brings up the search bar,

20
00:00:52,130 --> 00:00:54,440
they're going to input an address and navigate to,

21
00:00:54,440 --> 00:00:56,870
we can look back and look how long does it usually

22
00:00:56,870 --> 00:01:00,565
take from opening that search bar to access starting navigation.

23
00:01:00,565 --> 00:01:04,520
We might be able to do that on an absolutely massive quantity of data.

24
00:01:04,520 --> 00:01:07,895
Another benefit of this is it enables objective comparisons.

25
00:01:07,895 --> 00:01:10,385
That means we can compare this text entry screen to

26
00:01:10,385 --> 00:01:13,940
a voice system or some other way of inputting addresses to

27
00:01:13,940 --> 00:01:17,270
understand how different interfaces entirely or different modes

28
00:01:17,270 --> 00:01:20,920
of interaction entirely can have different efficiencies associated with them.

29
00:01:20,920 --> 00:01:24,080
Most importantly, those comparisons are objective.

30
00:01:24,080 --> 00:01:27,605
There's no real interpretation involved in saying that it takes an average

31
00:01:27,605 --> 00:01:32,015
of 5.2 seconds to go from entering an address to starting navigation.

32
00:01:32,015 --> 00:01:33,635
That's just a descriptive statistic.

33
00:01:33,635 --> 00:01:36,145
However, there are some pretty major drawbacks as well.

34
00:01:36,145 --> 00:01:38,025
When we're employing the processor model,

35
00:01:38,025 --> 00:01:41,240
we don't see the reason for the differences that we observe.

36
00:01:41,240 --> 00:01:45,425
We have no real basis to understand why one interface performs better than the other.

37
00:01:45,425 --> 00:01:48,230
We also can't differentiate by expertise.

38
00:01:48,230 --> 00:01:50,360
Usually, when we're using the processor model,

39
00:01:50,360 --> 00:01:51,830
we're working with expert users,

40
00:01:51,830 --> 00:01:54,055
and we're not really worried about what they're thinking about.

41
00:01:54,055 --> 00:01:56,330
For novices though, it's very difficult for

42
00:01:56,330 --> 00:02:00,260
the processor model to understand what a novice finds confusing or misleading.

43
00:02:00,260 --> 00:02:02,900
Most generally, the processor model is usually

44
00:02:02,900 --> 00:02:05,630
good for optimization but not for redesign.

45
00:02:05,630 --> 00:02:07,640
If we're making small changes like the size of

46
00:02:07,640 --> 00:02:09,980
buttons or the responsiveness of the screen,

47
00:02:09,980 --> 00:02:13,335
then it can help us compare and understand which interface is performing better.

48
00:02:13,335 --> 00:02:16,685
But if we're going to try a comprehensive new redesign,

49
00:02:16,685 --> 00:02:19,010
the processor model isn't very helpful.

50
00:02:19,010 --> 00:02:22,510
It might be good for evaluating that new redesign once we've created it,

51
00:02:22,510 --> 00:02:26,690
but it doesn't give us very much input on what we should include in that redesign.

52
00:02:26,690 --> 00:02:29,065
If we shift to the predictor model,

53
00:02:29,065 --> 00:02:32,075
then we're going to actually start asking our users for input.

54
00:02:32,075 --> 00:02:33,680
We could bring them in for interviews,

55
00:02:33,680 --> 00:02:36,550
conduct focus groups, send out surveys.

56
00:02:36,550 --> 00:02:39,680
We can also show them prototypes for new interfaces and

57
00:02:39,680 --> 00:02:42,780
have them describe their thought process while trying to interact with them.

58
00:02:42,780 --> 00:02:46,640
We might find some simple changes that we wouldn't have stumbled upon otherwise.

59
00:02:46,640 --> 00:02:48,530
For example, we might find that users find

60
00:02:48,530 --> 00:02:51,695
a certain icon to be misleading compared to its real meaning.

61
00:02:51,695 --> 00:02:53,990
We might also find some information about why users

62
00:02:53,990 --> 00:02:56,525
choose different interfaces at different times.

63
00:02:56,525 --> 00:02:58,910
For example, users might prefer the voice interface while

64
00:02:58,910 --> 00:03:01,675
driving but this text interface while they're parked.

65
00:03:01,675 --> 00:03:03,410
So, the big advantage here is that we get

66
00:03:03,410 --> 00:03:07,265
a more complete picture of the user's interaction with the interface.

67
00:03:07,265 --> 00:03:09,680
We get to ask them why they do certain things,

68
00:03:09,680 --> 00:03:12,320
or what they're thinking about, or why they made certain choices.

69
00:03:12,320 --> 00:03:16,405
Additionally, this model lets us target different levels of expertise.

70
00:03:16,405 --> 00:03:18,380
We can bring in novices who've never seen

71
00:03:18,380 --> 00:03:20,540
the interface before and say, "Take a look at this.

72
00:03:20,540 --> 00:03:22,490
What do you think you should do next?"

73
00:03:22,490 --> 00:03:26,210
But we could also bring in experts and have them reflect on how some new interface

74
00:03:26,210 --> 00:03:30,050
might make it more or less efficient to accomplish what they want to accomplish.

75
00:03:30,050 --> 00:03:31,895
But again, there are drawbacks.

76
00:03:31,895 --> 00:03:35,734
One big drawback is that the analysis of this can be very expensive.

77
00:03:35,734 --> 00:03:38,855
We're not looking at numbers and conducting a little statistical tests.

78
00:03:38,855 --> 00:03:41,150
We're often looking at plain text transcripts of

79
00:03:41,150 --> 00:03:44,164
interviews or plain text responses to surveys.

80
00:03:44,164 --> 00:03:48,365
Analyzing those requires a lot of human attention and a lot of effort.

81
00:03:48,365 --> 00:03:51,635
Even then, that analysis can be subject to biases.

82
00:03:51,635 --> 00:03:53,750
If the person analyzing that data has

83
00:03:53,750 --> 00:03:56,450
some suspicions about what they think the better interface would be,

84
00:03:56,450 --> 00:03:59,360
they're very likely to imbue their analysis with

85
00:03:59,360 --> 00:04:04,195
those biases and only focus on data that confirms what they already think was true.

86
00:04:04,195 --> 00:04:07,280
So, we have to make sure that they control for those biases.

87
00:04:07,280 --> 00:04:09,600
Additionally, when we're using the predictor model,

88
00:04:09,600 --> 00:04:13,195
we're still usually ignoring the broader interaction context.

89
00:04:13,195 --> 00:04:15,739
We're usually looking at the person in the interface,

90
00:04:15,739 --> 00:04:20,090
but not the real authentic environment in which they usually use that interface.

91
00:04:20,090 --> 00:04:22,850
For this interface, that could be a problem because we might have an interface

92
00:04:22,850 --> 00:04:25,760
that works very well when it has the full user attention.

93
00:04:25,760 --> 00:04:30,095
But it's significantly harder to use when the user is, for instance, driving.

94
00:04:30,095 --> 00:04:33,680
For example, if we were only testing a new interface in a lab setting,

95
00:04:33,680 --> 00:04:37,100
we might have a feature that hides what the user has been searching for if

96
00:04:37,100 --> 00:04:40,790
they haven't entered any new text or made a selection in the past five seconds.

97
00:04:40,790 --> 00:04:43,370
In a lab setting, that's probably fine because our users are

98
00:04:43,370 --> 00:04:45,900
generally only focused on the task that we're giving them,

99
00:04:45,900 --> 00:04:48,160
which is entering some address into that search bar.

100
00:04:48,160 --> 00:04:49,890
But if they're actually out driving,

101
00:04:49,890 --> 00:04:52,355
they might start entering an address at one red light,

102
00:04:52,355 --> 00:04:54,140
had light turn green and want to pause,

103
00:04:54,140 --> 00:04:56,390
and continue entering it at the next red light.

104
00:04:56,390 --> 00:04:58,295
If it disappears after five seconds,

105
00:04:58,295 --> 00:05:01,854
that's not really aware of the way they're using it in the real environment.

106
00:05:01,854 --> 00:05:04,120
So, that's where the participant model comes in.

107
00:05:04,120 --> 00:05:05,560
With a participant model,

108
00:05:05,560 --> 00:05:10,655
we view the interface and the user in the context in which they actually interact.

109
00:05:10,655 --> 00:05:15,530
We want to look at the user in the interface as participants in some broader activity,

110
00:05:15,530 --> 00:05:17,405
the broader activity of driving,

111
00:05:17,405 --> 00:05:20,119
not just as a user interacting with one interface.

112
00:05:20,119 --> 00:05:22,290
Now, the benefit of this should be pretty obvious.

113
00:05:22,290 --> 00:05:25,055
It evaluates the interaction in context.

114
00:05:25,055 --> 00:05:28,160
We can understand things like the driver is distracted or they're

115
00:05:28,160 --> 00:05:31,355
going to do things in different batches as it come to different red lights.

116
00:05:31,355 --> 00:05:35,440
We also capture an authentic representation of the user's level of attention.

117
00:05:35,440 --> 00:05:37,795
If the user is going to be distracted, for example,

118
00:05:37,795 --> 00:05:40,130
we'll see that when we analyze the activity

119
00:05:40,130 --> 00:05:42,700
and the authentic contexts in which it takes place.

120
00:05:42,700 --> 00:05:45,620
But unsurprisingly, there are also drawbacks to this approach to.

121
00:05:45,620 --> 00:05:50,285
Just as the predictor model suggested evaluations that were difficult to analyze,

122
00:05:50,285 --> 00:05:55,250
the participant model emphasizes evaluations that can actually be difficult to perform.

123
00:05:55,250 --> 00:05:58,440
To evaluate this interface in the authentic contexts in which it's used,

124
00:05:58,440 --> 00:06:01,435
we need to actually go right along with participants.

125
00:06:01,435 --> 00:06:03,920
That's a lot harder to do than just sending out a survey

126
00:06:03,920 --> 00:06:06,790
or bring people into our controlled lab environment.

127
00:06:06,790 --> 00:06:10,505
It also means we need to have real functional interfaces.

128
00:06:10,505 --> 00:06:12,800
We can't have a person driving a car and keep holding up

129
00:06:12,800 --> 00:06:15,530
some prototype next to them while they're actually trying to drive.

130
00:06:15,530 --> 00:06:17,450
We need these interfaces to actually be

131
00:06:17,450 --> 00:06:20,150
designed and implemented to work in that real context.

132
00:06:20,150 --> 00:06:24,235
So, it's hard to use this model when we're just getting started with a new design task.

133
00:06:24,235 --> 00:06:26,840
Finally, using the participant model means that we're

134
00:06:26,840 --> 00:06:30,095
exposing ourselves to a lot of uncontrollable variables.

135
00:06:30,095 --> 00:06:32,299
The more that's going on in the environment,

136
00:06:32,299 --> 00:06:36,560
the harder it is to zoom in and focus only on the impact of our designs.

137
00:06:36,560 --> 00:06:38,720
Now, hopefully you'll notice that the pros of some

138
00:06:38,720 --> 00:06:41,045
of these models address to cons of others.

139
00:06:41,045 --> 00:06:42,620
The processor model, for example,

140
00:06:42,620 --> 00:06:45,130
doesn't give us much insight into what novices are thinking.

141
00:06:45,130 --> 00:06:48,595
But the predictor model is particularly good at targeting novices.

142
00:06:48,595 --> 00:06:52,480
To predict a model makes it difficult to conduct real objective comparisons.

143
00:06:52,480 --> 00:06:54,915
That's exactly what the processor model is good for.

144
00:06:54,915 --> 00:06:58,880
Neither the processor nor the predictor model take into consideration context,

145
00:06:58,880 --> 00:07:01,240
but that's what we get when we consider the participant model.

146
00:07:01,240 --> 00:07:03,170
But it doesn't isolate variables very well.

147
00:07:03,170 --> 00:07:06,055
It's subject to interference from things that we can't control.

148
00:07:06,055 --> 00:07:09,199
But the processor model is very good at isolating those variables.

149
00:07:09,199 --> 00:07:11,945
So the major takeaway here is it will likely use

150
00:07:11,945 --> 00:07:15,380
all of these different models at different times and in different contexts.

151
00:07:15,380 --> 00:07:19,260
The data we gather from one might inform what we do with another.

152
00:07:19,260 --> 00:07:21,500
We might start with a participant model or we

153
00:07:21,500 --> 00:07:24,110
just ride around with users watching what they do.

154
00:07:24,110 --> 00:07:26,570
Based on that, we might observe that they spend a lot of time

155
00:07:26,570 --> 00:07:29,150
fumbling around a return to the same few locations.

156
00:07:29,150 --> 00:07:32,045
So, we might redesign an interface to include some kind of

157
00:07:32,045 --> 00:07:35,680
bookmarking system and present it to users in interviews.

158
00:07:35,680 --> 00:07:38,670
There, they might tell us they like that design,

159
00:07:38,670 --> 00:07:41,550
but further note, they don't need a long list of bookmarks.

160
00:07:41,550 --> 00:07:43,805
They really only need work and home.

161
00:07:43,805 --> 00:07:46,805
So based on that, we might then design an interface where

162
00:07:46,805 --> 00:07:50,650
a simple swipe takes him to work or to home depending on where they are right now.

163
00:07:50,650 --> 00:07:53,380
In fact, that's how that Tesla navigation screen works.

164
00:07:53,380 --> 00:07:56,119
If you just swipe across to navigate button,

165
00:07:56,119 --> 00:07:58,585
it'll automatically take you to work if you're at home,

166
00:07:58,585 --> 00:08:00,120
or home if you're at work.

167
00:08:00,120 --> 00:08:04,130
Then, finally, we might test it with the processor model to see just how much

168
00:08:04,130 --> 00:08:08,410
more efficiently that new interface allows users to put in their destination.

169
00:08:08,410 --> 00:08:11,235
The results of each design phase inform the next,

170
00:08:11,235 --> 00:08:14,480
and different phases call for different types of evaluation,

171
00:08:14,480 --> 00:08:17,050
which echoed the different models of the user.

