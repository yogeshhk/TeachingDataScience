1
00:00:00,240 --> 00:00:03,770
When we discussed prototyping,
we talked about how over time

2
00:00:03,770 --> 00:00:07,100
the nature of our prototypes
get higher and higher fidelity.

3
00:00:07,100 --> 00:00:09,430
Something similar
happens with evaluation.

4
00:00:09,430 --> 00:00:12,200
Over time, the evaluation
method we'll use will change.

5
00:00:13,510 --> 00:00:17,520
Throughout most of our design process
our evaluations are formative.

6
00:00:17,520 --> 00:00:22,030
Meaning their primary purpose is to help
us redesign and improve our interface.

7
00:00:22,030 --> 00:00:24,880
At the end, though, we might want
to do something more summative to

8
00:00:24,880 --> 00:00:26,560
conclude the design process,

9
00:00:26,560 --> 00:00:30,420
especially if we want to demonstrate
that the new interface is better.

10
00:00:30,420 --> 00:00:33,960
Formative evaluation is
evaluation with the intention of

11
00:00:33,960 --> 00:00:36,090
improving the interface going forward.

12
00:00:36,090 --> 00:00:39,510
Summative is with the intention
of conclusively saying at the end

13
00:00:39,510 --> 00:00:41,250
what the difference was.

14
00:00:41,250 --> 00:00:43,810
In reality, hopefully we never
do summative evaluation.

15
00:00:43,810 --> 00:00:46,370
Hopefully our evaluations
are always with the purpose

16
00:00:46,370 --> 00:00:48,980
of revising our interface and
making it better over time.

17
00:00:48,980 --> 00:00:52,310
But in practice, there might come times
when you need to demonstrate a very

18
00:00:52,310 --> 00:00:54,760
clear quantitative difference.

19
00:00:54,760 --> 00:00:56,370
And because of this difference,

20
00:00:56,370 --> 00:00:58,980
our early evaluations tend
to be more qualitative.

21
00:01:00,130 --> 00:01:04,129
Qualitative evaluations tend to be
more interpretative and informal.

22
00:01:04,129 --> 00:01:07,243
Their goal is to help us improve or
understand the task.

23
00:01:07,243 --> 00:01:11,710
Our later evaluations are likely more
empirical, controlled, and formal.

24
00:01:11,710 --> 00:01:14,820
Their goal is to demonstrate or
assess change.

25
00:01:14,820 --> 00:01:17,470
So while formative evaluation and
summative evaluation were

26
00:01:17,470 --> 00:01:20,700
the purposes of our evaluations,
qualitative evaluations and

27
00:01:20,700 --> 00:01:24,140
empirical evaluations are ways to
actually fulfill those purposes.

28
00:01:25,140 --> 00:01:27,260
Predictive evaluation is
a little outside the spectrum,

29
00:01:27,260 --> 00:01:28,780
so we'll talk about that as well.

30
00:01:28,780 --> 00:01:30,029
As far as this is concerned,

31
00:01:30,029 --> 00:01:33,470
predictive evaluations tend to be very
similar to qualitative evaluations.

32
00:01:33,470 --> 00:01:37,450
They inform how we revise and
improve our interfaces over time.

33
00:01:37,450 --> 00:01:40,410
These three categories actually form
the bulk of what we'll talk about

34
00:01:40,410 --> 00:01:41,940
in this lesson.

35
00:01:41,940 --> 00:01:44,990
Recall also that earlier we talked about
the difference between qualitative and

36
00:01:44,990 --> 00:01:46,370
quantitative data.

37
00:01:46,370 --> 00:01:47,560
As you've probably realized,

38
00:01:47,560 --> 00:01:52,210
if qualitative evaluation occurs early,
an empirical evaluation occurs late.

39
00:01:52,210 --> 00:01:54,970
And chances are, we're using
qualitative data more early, and

40
00:01:54,970 --> 00:01:56,730
quantitative data more late.

41
00:01:56,730 --> 00:02:01,050
In reality, qualitative data is really
always useful to improve our interfaces,

42
00:02:01,050 --> 00:02:03,370
whereas quantitative data,
while always useful,

43
00:02:03,370 --> 00:02:06,760
really can only arise when we
have pretty rigorous evaluations.

44
00:02:06,760 --> 00:02:10,910
And then one last area we can look at
is where the evaluation takes place.

45
00:02:10,910 --> 00:02:13,995
In a controlled lab setting or
actually out in the field.

46
00:02:13,995 --> 00:02:16,685
Generally when we're testing our
early low fidelity interfaces,

47
00:02:16,685 --> 00:02:20,055
we probably want to do it in a lab
setting as opposed to out in the wild.

48
00:02:20,055 --> 00:02:22,635
We want to bring participants into our
lab and actually describe what we're

49
00:02:22,635 --> 00:02:26,607
going for, the rationale behind certain
decisions, and get their feedback.

50
00:02:26,607 --> 00:02:29,890
Later on we might want to do real field
testing where we give users a somewhat

51
00:02:29,890 --> 00:02:32,927
working prototype, or something
resembling a working prototype.

52
00:02:32,927 --> 00:02:35,770
And they can actually reflect on it
as they go about their regular lives,

53
00:02:35,770 --> 00:02:39,407
participating in whatever task that
interface is supposed to help with.

54
00:02:39,407 --> 00:02:42,547
This helps us focus exclusively
on the interface early on, and

55
00:02:42,547 --> 00:02:45,800
in transition to focusing on
the interface in context later.

56
00:02:45,800 --> 00:02:49,210
But of course we want to also
think about the context early on.

57
00:02:49,210 --> 00:02:53,242
We could for example, develop a very
navigation app that works great when we

58
00:02:53,242 --> 00:02:56,649
test in our lab, because it demands
a very high cognitive load.

59
00:02:56,649 --> 00:02:59,866
But doesn't work at all out in the field
because when participants are actually

60
00:02:59,866 --> 00:03:03,170
driving, they can't spare that
cognitive load to focus on our app.

61
00:03:03,170 --> 00:03:05,270
Now of course none of these are hard and
fast rules.

62
00:03:05,270 --> 00:03:08,110
We'll very likely often do
qualitative evaluation late or

63
00:03:08,110 --> 00:03:09,930
maybe do some field testing early.

64
00:03:09,930 --> 00:03:12,900
But as general principles, this is
probably the order in which we want to

65
00:03:12,900 --> 00:03:14,470
think about our different
evaluation styles.

