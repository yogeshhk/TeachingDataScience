1
00:00:00,000 --> 00:00:04,560
Null and alternative hypotheses are common to all kinds of hypothesis tests.

2
00:00:04,560 --> 00:00:08,070
The specific kind of hypothesis tests you conduct however,

3
00:00:08,070 --> 00:00:10,440
depends on the kind of data that you have.

4
00:00:10,440 --> 00:00:13,380
Recall when we first started talking about quantitative data,

5
00:00:13,380 --> 00:00:16,155
we discussed four general kinds: Nominal,

6
00:00:16,155 --> 00:00:18,090
ordinal, interval and ratio.

7
00:00:18,090 --> 00:00:23,445
What kinds of hypothesis tests we use will depend on what kind of data we've collected.

8
00:00:23,445 --> 00:00:25,710
Note that my goal here isn't for you to know off

9
00:00:25,710 --> 00:00:27,990
the top of your head how to do each of these tests.

10
00:00:27,990 --> 00:00:30,945
Instead, I want you to know when to use each kind of test.

11
00:00:30,945 --> 00:00:32,730
So, you can go and look it up when needed.

12
00:00:32,730 --> 00:00:34,680
I've used all these kind of tests before and I

13
00:00:34,680 --> 00:00:37,050
can't remember off the top my head how to do any of them.

14
00:00:37,050 --> 00:00:41,175
But I know when to go look up which test and that's the most important thing for now.

15
00:00:41,175 --> 00:00:45,800
For nominal data, we generally want to do something called a Chi-squared test.

16
00:00:45,800 --> 00:00:48,860
A Chi-squared test checks to see if the distribution of values to

17
00:00:48,860 --> 00:00:51,970
a number of buckets is the same across two conditions.

18
00:00:51,970 --> 00:00:54,080
For all of these, I'm going to use a series of examples

19
00:00:54,080 --> 00:00:56,090
inspired by comparison that I did recently

20
00:00:56,090 --> 00:01:00,470
between my online undergraduate course and in traditional undergraduate course.

21
00:01:00,470 --> 00:01:03,145
So for example, one of my questions was,

22
00:01:03,145 --> 00:01:05,105
does the distribution of majors

23
00:01:05,105 --> 00:01:08,570
differ between the online section and the traditional section?

24
00:01:08,570 --> 00:01:11,680
Here our independent variable would be a pair of categories.

25
00:01:11,680 --> 00:01:13,760
For me it's online and traditional,

26
00:01:13,760 --> 00:01:15,950
and our dependent variable will be

27
00:01:15,950 --> 00:01:19,880
the distribution among some other set of categories, here it's majors.

28
00:01:19,880 --> 00:01:22,900
We always assume that the distributions are equal.

29
00:01:22,900 --> 00:01:26,930
So, our alternative hypothesis would be the distributions are unequal.

30
00:01:26,930 --> 00:01:29,900
Now, obviously the distributions are unequal in some ways.

31
00:01:29,900 --> 00:01:32,260
There's a lot more students in traditional section.

32
00:01:32,260 --> 00:01:35,810
That ratio isn't perfectly mirrored across all these categories.

33
00:01:35,810 --> 00:01:38,660
Our question is, are these differences big

34
00:01:38,660 --> 00:01:42,695
enough to assume that it's an actual difference between online and traditional?

35
00:01:42,695 --> 00:01:45,865
Or, are the differences just a product of random noise?

36
00:01:45,865 --> 00:01:47,570
If there are four times as many students in

37
00:01:47,570 --> 00:01:49,750
the traditional section as the online section,

38
00:01:49,750 --> 00:01:52,310
then we wouldn't expect exactly four times as

39
00:01:52,310 --> 00:01:55,720
many computer science majors and exactly four times as many math majors.

40
00:01:55,720 --> 00:01:59,230
But we also wouldn't expect the ratios to be way off either.

41
00:01:59,230 --> 00:02:02,030
So, a Chi-squared test lets us test to see whether

42
00:02:02,030 --> 00:02:05,195
distributions to this categories are comparable.

43
00:02:05,195 --> 00:02:08,965
For ordinal data, we actually go with a very similar process.

44
00:02:08,965 --> 00:02:10,525
Just like with nominal data,

45
00:02:10,525 --> 00:02:13,440
we have our different categories as our independent variable and

46
00:02:13,440 --> 00:02:17,510
our dependent variable is some distribution among a number of categories.

47
00:02:17,510 --> 00:02:20,810
The difference here is that these categories are ranked.

48
00:02:20,810 --> 00:02:23,900
What that means is we could actually use the exact same test.

49
00:02:23,900 --> 00:02:25,595
We could use the Chi-squared test.

50
00:02:25,595 --> 00:02:28,490
The weakness there is that the Chi-squared test isn't as

51
00:02:28,490 --> 00:02:31,585
sensitive to systematic changes across these categories.

52
00:02:31,585 --> 00:02:35,960
The Chi-squared test assumes all these different categories are independent.

53
00:02:35,960 --> 00:02:40,820
We know though that if we see a small shift in all the categories from left to right,

54
00:02:40,820 --> 00:02:44,064
that might actually be a significant difference between the two sections.

55
00:02:44,064 --> 00:02:48,275
So, it's generally better to use what's called the Kolmogorov-Smirnov test.

56
00:02:48,275 --> 00:02:50,720
It's very similar to the Chi-squared test but

57
00:02:50,720 --> 00:02:53,300
it's sensitive to the fact that those categories are ordered.

58
00:02:53,300 --> 00:02:56,270
Now that said, using the Chi-squared test isn't going to

59
00:02:56,270 --> 00:02:59,240
hurt you with this kinda data and sometimes it can be easier to run.

60
00:02:59,240 --> 00:03:02,330
There's also an alternative that more simply just test to see whether

61
00:03:02,330 --> 00:03:05,415
it's likely that the medians of the two are different.

62
00:03:05,415 --> 00:03:08,600
It's also not terribly uncommon to make the assumption

63
00:03:08,600 --> 00:03:12,010
that these ordinal data categories are evenly spaced.

64
00:03:12,010 --> 00:03:14,720
Now, remember when we talked about ordinal data and that

65
00:03:14,720 --> 00:03:17,180
was exactly one of the weaknesses that we noted.

66
00:03:17,180 --> 00:03:21,470
We noted that we can't know the difference between highly dissatisfied and dissatisfied,

67
00:03:21,470 --> 00:03:24,910
is the same as the difference between dissatisfied and neutral.

68
00:03:24,910 --> 00:03:26,490
Because we can't know that,

69
00:03:26,490 --> 00:03:28,550
we're really not supposed to just average

70
00:03:28,550 --> 00:03:32,285
these but in practice it's not uncommon for people to do so anyway.

71
00:03:32,285 --> 00:03:35,240
In that case, we might just assign these categories numbers like one,

72
00:03:35,240 --> 00:03:36,800
two, three, four and five,

73
00:03:36,800 --> 00:03:39,745
multiply the number of observations by those numbers,

74
00:03:39,745 --> 00:03:41,210
average them over the number of

75
00:03:41,210 --> 00:03:45,050
actual respondents and see if there's a statistically significant difference.

76
00:03:45,050 --> 00:03:47,510
It's not good to do that but if you

77
00:03:47,510 --> 00:03:50,605
chose to do that you wouldn't be the first person ever to do so.

78
00:03:50,605 --> 00:03:53,210
When we get to interval and ratio data,

79
00:03:53,210 --> 00:03:55,850
the kinds of tests we use actually shift a good bit.

80
00:03:55,850 --> 00:03:59,750
First, we really never treat interval and ratio data as different.

81
00:03:59,750 --> 00:04:03,235
The fact that ratio data has a zero-point and interval data doesn't,

82
00:04:03,235 --> 00:04:05,555
doesn't affect any of our statistical tests.

83
00:04:05,555 --> 00:04:08,270
The statistical tests that we do for this kind of data are

84
00:04:08,270 --> 00:04:11,270
always dependent on the average and the standard deviation.

85
00:04:11,270 --> 00:04:14,785
The most common test is called the Student's t-test.

86
00:04:14,785 --> 00:04:17,300
I'm not going to talk about it right now but I do recommend looking

87
00:04:17,300 --> 00:04:19,640
up why it's called the Student's t-test.

88
00:04:19,640 --> 00:04:21,290
It's kind of an interesting story.

89
00:04:21,290 --> 00:04:23,030
For these are independent variable,

90
00:04:23,030 --> 00:04:24,410
is the same as it's been in the past.

91
00:04:24,410 --> 00:04:27,890
It's a category we're comparing between two different populations.

92
00:04:27,890 --> 00:04:32,270
But our dependent variable is actually just the average of some kind of outcome.

93
00:04:32,270 --> 00:04:36,140
We're not talking about distributions into subcategories but rather

94
00:04:36,140 --> 00:04:40,250
just looking at a certain outcome for all participants in each category.

95
00:04:40,250 --> 00:04:43,535
Our null hypothesis is that the outcomes are equal and

96
00:04:43,535 --> 00:04:47,465
our alternative hypothesis is that the outcomes are unequal.

97
00:04:47,465 --> 00:04:50,420
A t-test lets us pretty straightforwardly compare between the

98
00:04:50,420 --> 00:04:53,754
two and see if the difference is actually statistically significant.

99
00:04:53,754 --> 00:04:56,390
Again, we wouldn't expect the two numbers to have to be

100
00:04:56,390 --> 00:05:00,280
exactly identical to say that the populations are not any different.

101
00:05:00,280 --> 00:05:02,480
Here, an average of 10.2 compared to

102
00:05:02,480 --> 00:05:06,260
9.9 probably isn't big enough to actually conclude that

103
00:05:06,260 --> 00:05:09,770
the online section did any better than the traditional section especially when

104
00:05:09,770 --> 00:05:13,730
the standard deviations are pretty significant fractions of those averages.

105
00:05:13,730 --> 00:05:16,490
Don't worry though if you don't fully understand the math behind this,

106
00:05:16,490 --> 00:05:18,410
you're really not supposed to right now.

107
00:05:18,410 --> 00:05:22,040
For now all you really need to know is that the difference has to be big enough to

108
00:05:22,040 --> 00:05:25,760
justify that one is actually different from the other and how big,

109
00:05:25,760 --> 00:05:27,200
big enough actually is,

110
00:05:27,200 --> 00:05:30,145
is dependent on how big that standard deviation is.

111
00:05:30,145 --> 00:05:31,795
The bigger the standard deviation,

112
00:05:31,795 --> 00:05:33,485
the bigger the difference needs to be.

113
00:05:33,485 --> 00:05:36,140
Now it's also worth noting that we're only supposed to use

114
00:05:36,140 --> 00:05:39,169
t-tests when the data distribution is normal.

115
00:05:39,169 --> 00:05:41,330
That means it mirrors irregular bell-curve.

116
00:05:41,330 --> 00:05:42,650
If it's not normal,

117
00:05:42,650 --> 00:05:43,790
we're supposed to use things like

118
00:05:43,790 --> 00:05:47,315
the Mann-Whitney-Wilcoxon test or the Kruskal-Wallis Test.

119
00:05:47,315 --> 00:05:49,640
But those topics are kind of outside our scope.

120
00:05:49,640 --> 00:05:53,840
Generally speaking, a Chi-squared test and a t-test will get you most of what you

121
00:05:53,840 --> 00:05:58,570
need at least until we get to having three different levels of our independent variable.

