1
00:00:00,000 --> 00:00:03,930
Chi-squared tests and t-tests are probably the most commonly used tests in HCI.

2
00:00:03,930 --> 00:00:07,950
However, there are some assumptions embedded in the ones we just looked at.

3
00:00:07,950 --> 00:00:12,030
First, notice that we only ever had two levels to our independent variable.

4
00:00:12,030 --> 00:00:15,030
We were only ever comparing online and traditional students.

5
00:00:15,030 --> 00:00:18,240
For your work, that might mean only comparing two different interfaces.

6
00:00:18,240 --> 00:00:21,825
What if we wanted to test three? How can we do that?

7
00:00:21,825 --> 00:00:23,810
Imagine for example, I wanted to test

8
00:00:23,810 --> 00:00:26,785
these two classes against a third class or flipped class.

9
00:00:26,785 --> 00:00:29,300
Here we'd be testing the online section versus

10
00:00:29,300 --> 00:00:32,825
the traditional section versus the flipped section, how would we do that?

11
00:00:32,825 --> 00:00:35,660
You might be tempted to just test them in a pairwise fashion,

12
00:00:35,660 --> 00:00:37,175
test online versus traditional,

13
00:00:37,175 --> 00:00:39,740
traditional verse flipped and online verse flipped.

14
00:00:39,740 --> 00:00:43,040
You use that to try to uncover any differences between pairs.

15
00:00:43,040 --> 00:00:44,945
That's called repeated testing,

16
00:00:44,945 --> 00:00:49,325
and the problem, is that it raises the likelihood of a type one error.

17
00:00:49,325 --> 00:00:51,890
A type one error is also called a false positive,

18
00:00:51,890 --> 00:00:55,175
and it's where we falsely reject the null hypothesis.

19
00:00:55,175 --> 00:00:57,590
In other words, we falsely say that we have

20
00:00:57,590 --> 00:01:00,380
enough data to conclude the alternative hypothesis.

21
00:01:00,380 --> 00:01:02,600
Here that would mean, falsely concluding

22
00:01:02,600 --> 00:01:05,065
that there is a difference when there isn't actually a difference.

23
00:01:05,065 --> 00:01:08,210
The reason repeated testing raises likelihood of this,

24
00:01:08,210 --> 00:01:11,870
is that remember we said that we reject the null hypothesis if there's

25
00:01:11,870 --> 00:01:16,040
generally less than a five percent chance it could have occurred by random chance.

26
00:01:16,040 --> 00:01:18,010
But if you do three different tests,

27
00:01:18,010 --> 00:01:20,180
you raise the likelihood of one of them turning

28
00:01:20,180 --> 00:01:22,535
up conclusive even though it really isn't.

29
00:01:22,535 --> 00:01:24,200
Think of it like playing the lottery.

30
00:01:24,200 --> 00:01:27,860
If I say you have a one in 20 chance of winning and you play 20 times,

31
00:01:27,860 --> 00:01:29,305
you'll still win once.

32
00:01:29,305 --> 00:01:32,555
That's because your overall odds of winning increased.

33
00:01:32,555 --> 00:01:38,080
Performing multiple tests, raises our overall likelihood of finding a false positive.

34
00:01:38,080 --> 00:01:39,640
So instead, what we need,

35
00:01:39,640 --> 00:01:43,835
is a single test that can compare against all these different treatments at once.

36
00:01:43,835 --> 00:01:46,340
Now fortunately, for ordinal or nominal data,

37
00:01:46,340 --> 00:01:48,485
it's actually just the same test.

38
00:01:48,485 --> 00:01:53,070
A chi-squared test can handle more than just two levels of our independent variable.

39
00:01:53,070 --> 00:01:55,100
Our alternative tests change a little bit,

40
00:01:55,100 --> 00:01:56,935
if we're dealing with more than two levels.

41
00:01:56,935 --> 00:02:02,030
The weakness here, is if we do a Chi-squared test on all three of these levels at once,

42
00:02:02,030 --> 00:02:06,185
all it will tell us is if there's any difference between any of the levels.

43
00:02:06,185 --> 00:02:08,255
It doesn't tell us where the difference is.

44
00:02:08,255 --> 00:02:10,920
So, if this chi-squared test shows that there is a difference,

45
00:02:10,920 --> 00:02:12,355
we don't have any way of knowing,

46
00:02:12,355 --> 00:02:14,600
is it the difference between the online and traditional,

47
00:02:14,600 --> 00:02:16,775
online and flipped, traditional and flipped,

48
00:02:16,775 --> 00:02:19,040
or is it a case where the flipped is different

49
00:02:19,040 --> 00:02:21,520
from both the online and traditional or something like that.

50
00:02:21,520 --> 00:02:22,690
So, generally what we do,

51
00:02:22,690 --> 00:02:25,835
is we do an overall chi-squared tests on all of the levels,

52
00:02:25,835 --> 00:02:28,310
and then we can follow up if that first test was

53
00:02:28,310 --> 00:02:31,765
successful with a pairwise comparison between the conditions.

54
00:02:31,765 --> 00:02:34,370
In that case, for basically concluding that we know there's

55
00:02:34,370 --> 00:02:36,830
a difference before we actually do the repeated testing.

56
00:02:36,830 --> 00:02:40,370
So, the overall odds of finding a false positive aren't changing.

57
00:02:40,370 --> 00:02:42,755
For interval and ratio data though,

58
00:02:42,755 --> 00:02:44,735
we need to use a different test altogether.

59
00:02:44,735 --> 00:02:48,670
This test is called an analysis of variance or ANOVA.

60
00:02:48,670 --> 00:02:50,090
A one-way ANOVA test,

61
00:02:50,090 --> 00:02:52,940
let's us compare between three or more groups simultaneously.

62
00:02:52,940 --> 00:02:56,960
Here, that means we could test between all three of our classes at the same time.

63
00:02:56,960 --> 00:03:00,505
For you that can mean guessing between three or four interfaces at the same time.

64
00:03:00,505 --> 00:03:03,390
With a two-way ANOVA, we could actually take this a step further.

65
00:03:03,390 --> 00:03:06,410
We could have two dimensions of independent variables,

66
00:03:06,410 --> 00:03:08,780
we could test online traditional and flipped

67
00:03:08,780 --> 00:03:11,510
against upper class mean versus lower-class mean.

68
00:03:11,510 --> 00:03:13,400
We could actually get it differences like,

69
00:03:13,400 --> 00:03:16,940
do freshmen do better at online but sophomores do better in traditional.

70
00:03:16,940 --> 00:03:20,420
The weakness though, is the same as the weakness with the chi-squared test,

71
00:03:20,420 --> 00:03:24,080
and analysis of variance will tell us if there are differences,

72
00:03:24,080 --> 00:03:26,845
but it won't tell us where the differences are.

73
00:03:26,845 --> 00:03:30,140
Our approach to that is the same as it was with the chi-squared test as well.

74
00:03:30,140 --> 00:03:33,440
If the analysis of variance indicates there's an overall difference,

75
00:03:33,440 --> 00:03:36,865
then we can follow up with pairwise t-tests.

76
00:03:36,865 --> 00:03:39,440
Notice though, there's still one assumption that's been

77
00:03:39,440 --> 00:03:42,005
embedded in every single analysis we've talked about.

78
00:03:42,005 --> 00:03:45,610
Our independent variables have always been categorical,

79
00:03:45,610 --> 00:03:48,280
that's generally true for most of the tests we're going to do.

80
00:03:48,280 --> 00:03:50,450
If we're testing one interface against another,

81
00:03:50,450 --> 00:03:52,295
then those are our two categories.

82
00:03:52,295 --> 00:03:54,830
If we're testing one body of people against another,

83
00:03:54,830 --> 00:03:56,470
then those are our two categories.

84
00:03:56,470 --> 00:03:59,090
So, this isn't really a weakness or a challenge,

85
00:03:59,090 --> 00:04:00,470
but there are cases where we want

86
00:04:00,470 --> 00:04:03,140
our independent variable to be something non-categorical.

87
00:04:03,140 --> 00:04:04,610
Mostly that happens when we want

88
00:04:04,610 --> 00:04:07,885
our independent variable to be some interval or ratio data.

89
00:04:07,885 --> 00:04:13,340
So, imagine for example I wanted to see if GPA was a good predictor of course grade.

90
00:04:13,340 --> 00:04:16,010
GPA though is generally considered interval data,

91
00:04:16,010 --> 00:04:19,340
we might consider it ratio data but it's usually discussed as interval data.

92
00:04:19,340 --> 00:04:22,610
We could do this by breaking GPA down into categories.

93
00:04:22,610 --> 00:04:27,290
Instead of this, we could average the course grades for anyone with a GPA from 3.5-4,

94
00:04:27,290 --> 00:04:28,910
3-3.5, and so on.

95
00:04:28,910 --> 00:04:31,130
Or we could leave the GPA is interval data,

96
00:04:31,130 --> 00:04:32,890
and just do a direct analysis.

97
00:04:32,890 --> 00:04:35,600
Generally, here we'd be doing a regression or

98
00:04:35,600 --> 00:04:38,290
we would see how well one variable predicts another.

99
00:04:38,290 --> 00:04:39,765
Most of our regressions are linear,

100
00:04:39,765 --> 00:04:41,450
but we could also do a logistic regression,

101
00:04:41,450 --> 00:04:43,655
a polynomial regression, and lots more.

102
00:04:43,655 --> 00:04:46,580
Again, I'm getting outside the scope of our class.

103
00:04:46,580 --> 00:04:50,120
Here, our null hypothesis is that the variables are unrelated,

104
00:04:50,120 --> 00:04:53,300
and our alternative hypothesis is that they are related.

105
00:04:53,300 --> 00:04:56,305
So, we need evidence that they're related before assuming that they are.

106
00:04:56,305 --> 00:04:58,370
Here things get a little bit more complex as well,

107
00:04:58,370 --> 00:05:00,830
because we're not quite as emphatic about how we

108
00:05:00,830 --> 00:05:04,145
reject our null hypothesis and accept our alternative hypothesis.

109
00:05:04,145 --> 00:05:07,495
Usually with regressions, we describe how well the two fit.

110
00:05:07,495 --> 00:05:08,680
They might fit very well,

111
00:05:08,680 --> 00:05:11,015
somewhat well, not well at all, and so on.

112
00:05:11,015 --> 00:05:14,675
Before we move on, there's one last type of data I'd like to talk about,

113
00:05:14,675 --> 00:05:16,250
and that's binomial data.

114
00:05:16,250 --> 00:05:20,480
Binomial data is data with only two possible outcomes, like a coin flip.

115
00:05:20,480 --> 00:05:23,650
For us we might have outcomes like success in a class.

116
00:05:23,650 --> 00:05:25,820
In HCI, we might be curious which of

117
00:05:25,820 --> 00:05:29,945
multiple interfaces allows users to succeeded a task with greater frequency.

118
00:05:29,945 --> 00:05:33,275
Notice there that, success and failure are binary,

119
00:05:33,275 --> 00:05:36,055
and that's what makes this binomial data.

120
00:05:36,055 --> 00:05:37,390
What can be tricky here,

121
00:05:37,390 --> 00:05:39,470
is that our data actually looks continuous,

122
00:05:39,470 --> 00:05:42,245
it looks just like straightforward continuous ratio data.

123
00:05:42,245 --> 00:05:46,095
Here we might say online students succeed 94.9 percent of the time,

124
00:05:46,095 --> 00:05:49,100
in traditional students succeed 92.1 percent of the time,

125
00:05:49,100 --> 00:05:52,075
and we might be tempted just to do a straightforward t-test on that.

126
00:05:52,075 --> 00:05:53,520
But if you try to do the math,

127
00:05:53,520 --> 00:05:55,260
you'll quickly find that it doesn't work.

128
00:05:55,260 --> 00:05:57,820
A t-test requires a standard deviation,

129
00:05:57,820 --> 00:06:00,290
and if every single student is either a one or a zero,

130
00:06:00,290 --> 00:06:01,580
a success or a failure,

131
00:06:01,580 --> 00:06:04,625
then you don't really have a standard deviation in the same way.

132
00:06:04,625 --> 00:06:07,160
So instead, we have a specific tests that we use for

133
00:06:07,160 --> 00:06:09,805
binomial data called a binomial test.

134
00:06:09,805 --> 00:06:11,935
With a two sample binomial test,

135
00:06:11,935 --> 00:06:14,000
we compare two different sets of trials,

136
00:06:14,000 --> 00:06:16,130
each with a certain number of successes.

137
00:06:16,130 --> 00:06:17,750
So, we can answer questions like;

138
00:06:17,750 --> 00:06:20,720
does one lead to a greater ratio of successes than the other?

139
00:06:20,720 --> 00:06:24,590
Alternatively, we can also do a one-sample binomial test.

140
00:06:24,590 --> 00:06:29,970
That's where we compare only one set of trials to some arbitrary number. So, for example.

141
00:06:29,970 --> 00:06:32,780
If we wanted to prove that a coin was unbalanced,

142
00:06:32,780 --> 00:06:37,490
we would use a one-sample binomial test comparing it to a ratio of 50 percent.

143
00:06:37,490 --> 00:06:40,250
You'll know that you want to use binomial data,

144
00:06:40,250 --> 00:06:44,255
if the individual observations you're getting out of users are binary.

145
00:06:44,255 --> 00:06:47,540
If you're only concerned with whether they succeeded or failed on

146
00:06:47,540 --> 00:06:49,790
a particular task and if your data is

147
00:06:49,790 --> 00:06:52,510
just a bunch of instances of successes and failures,

148
00:06:52,510 --> 00:06:54,255
then you're using binomial data.

149
00:06:54,255 --> 00:06:56,900
If the data you're getting out of your users is more complex

150
00:06:56,900 --> 00:06:59,585
like multiple categories or continuous observations,

151
00:06:59,585 --> 00:07:01,910
then you're probably looking at using a chi-squared test or

152
00:07:01,910 --> 00:07:04,400
a t-test or any of the ones we talked about before.

153
00:07:04,400 --> 00:07:07,010
Now, we've gone through a lot of tests and we've gone through them very quickly,

154
00:07:07,010 --> 00:07:11,315
but remember our goal is just for you to know what test to use and when.

155
00:07:11,315 --> 00:07:13,670
Once you've identified the appropriate test,

156
00:07:13,670 --> 00:07:16,205
looking at how to do it and actually putting the data in,

157
00:07:16,205 --> 00:07:18,360
is usually a much simpler task.

