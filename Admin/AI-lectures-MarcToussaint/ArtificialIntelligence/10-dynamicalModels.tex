\input{../shared/shared}

\renewcommand{\course}{Artificial Intelligence}
\renewcommand{\coursepicture}{course_ai}
\renewcommand{\coursedate}{Winter 2019}
\renewcommand{\topic}{Dynamic Models}
\renewcommand{\keywords}{}

\slides

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\story{

This lecture covors a special case of graphical models for dynamic
processes, where the graph is a chain. Such models are called
Markov processes, or hidden Markov model when the random variable of
the dynamic process is not observable. These models are a cornerstone
of time series analysis, as well as for temporal models for language,
for instance. A special case of inference in the continuous case is
the Kalman filter, which can be used to tracking objects or the state
of controlled system.

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \slide{Motivation}{

%% -- Robotics slides

%% -- Speech recognition

%% -- Music

%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\key{Markov Process}
\slide{Markov processes (Markov chains)}{

\defn{Markov assumption}: $X_t$ depends on \emph{bounded} subset of $X_{0:t-1}$

\defn{First-order Markov process}: $P(X_t\|X_{0:t-1}) = P(X_t\|X_{t-1})$\\
\defn{Second-order Markov process}: $P(X_t\|X_{0:t-1}) = P(X_t\|X_{t-2},X_{t-1})$

\vspace*{0.2in}

\show[1.0]{russell/markov-processes.pdf}

\defn{Sensor Markov assumption}: $P(Y_t\|X_{0:t},Y_{0:t-1}) =  P(Y_t\|X_t)$

\defn{Stationary} process: transition model $P(X_t\|X_{t-1})$ and\\
sensor model $P(Y_t\|X_t)$ fixed for all $t$

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\key{Hidden Markov Model}
\slide{Hidden Markov Models}{

\item We assume we have

-- observed (discrete or continuous) variables $Y_t$ in each time slice

-- a discrete latent variable $X_t$ in each time slice

-- some observation model $P(Y_t \| X_t ; \t)$

-- some transition model $P(X_t \| X_{t\1} ; \t)$

~

\item A \textbf{Hidden Markov Model (HMM)} is defined as the joint distribution
$$
P(X_{0:T},Y_{0:T}) = P(X_0)~ \prod_{t=1}^T
P(X_t|X_{t\1})~ \prod_{t=0}^T P(Y_t | X_t) ~.
$$

~

\show[.5]{vl4-hmm}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\key{Filtering, Smoothing, Prediction}
\slide{Different inference problems in Markov Models}{

~

\hspace*{-10mm}
\twocol{.6}{.4}{\center
\show[.6]{filter}
}{
%\item $P(x_{0:T} \| y_{0:T})$ inferring hidden state given $y_{0:T}$
\item $P(x_t \| y_{0:T})$ marginal posterior
\item $P(x_t \| y_{0:t})$ \textbf{filtering}
\item $P(x_t \| y_{0:a})$, $t > a$ prediction
\item $P(x_t \| y_{0:b})$, $t < b$ \textbf{smoothing}
\item $P(y_{0:T})$ likelihood calculation
}

~

~

\item \textbf{Viterbi} alignment: Find sequence $x_{0:T}^*$ that maximizes
$P(x_{0:T} \| y_{0:T})$

{\small
(This is done using max-product, instead of sum-product message passing.)

}

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\key{HMM: Inference}
\slide{Inference in an HMM -- a tree!}{

~

\show[.6]{vl4-hmm3}

~\mypause

\item The marginal posterior $P(X_t \| Y_{1:T})$ is the product of three messages

$$P(X_t \| Y_{1:T}) \propto P(X_t, Y_{1:T}) = \underbrace{\mu_\text{past}}_\a(X_t)~ \underbrace{\mu_\text{now}}_\r(X_t)~ \underbrace{\mu_\text{future}}_\b(X_t)$$

~\mypause

\item For all $a< t$ and $b>t$

-- $X_a$ conditionally independent from $X_b$ given $X_t$

-- $Y_a$ conditionally independent from $Y_b$ given $X_t$

\cen{``The future is independent of the past given the present''}

\cen{\textbf{Markov property}}

~

\tiny
(conditioning on $Y_t$ does not yield any conditional
independences)

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\key{HMM inference}
\slide{Inference in HMMs}{

~

\show[.5]{vl4-hmm3}

~

Applying the general message passing equations:\\[-2ex]
{\tiny
\begin{align*}
\hspace*{-7mm}
\text{forward msg.} &&
\a_t(x_t)
&= \sum_{x_{t\1}} P(x_t|x_{t\1})~ \a_{t\1}(x_{t\1})~ \r_{t\1}(x_{t\1}) \\
&&
\a_0(x_0)
 &= P(x_0) \\
\hspace*{-7mm}
\text{backward msg.} &&
\b_t(x_t)
&= \sum_{x_{t\po}} P(x_{t\po}|x_t)~ \b_{t\po}(x_{t\po})~ \r_{t\po}(x_{t\po}) \\
&&
\b_T(x_T)
 &= 1 \\
\hspace*{-7mm}
\text{observation msg.}
&&
\r_t(x_t)
&= P(y_t \| x_t) \\
\hspace*{-7mm}
\text{posterior marginal}
&&
q(x_t) &\propto \a_t(x_t)~ \r_t(x_t)~ \b_t(x_t) \\
\hspace*{-7mm}
\text{posterior marginal}
&&
q(x_t,x_{t\po}) &\propto \a_t(x_t)~ \r_t(x_t)~
P(x_{t\po}|x_t)~ \r_{t\po}(x_{t\po})~ \b_{t\po}(x_{t\po})
\end{align*}

}

%% \mypause
%% In matrix notation:
%% \tiny
%% \begin{align*}
%% \text{forward msg.}
%% &&
%% \vec\a_t
%%  &= \vec P~ (\vec\a_{t\1} \circ \vec\r_{t\1}) \\
%% \text{backward msg.}
%% &&
%% \vec\b_t
%%  &= \vec P^\T (\vec\b_{t\po} \circ \vec\r_{t\po}) \\
%% \text{posterior belief}
%% &&
%% \vec b_t &= \vec\a_t \circ \vec\r_t \circ \vec\b_t
%% \end{align*}
%% $\vec\a_t, \vec\b_t, \vec\r_t$ denote probability tables over discrete
%% latent variable $x_t$; $\circ$ is the \emph{element-wise product};
%% $\vec P$ is $P(x'|x)$ written as CPT.

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{General Bayes Filter}{

\item Recall: Filtering means conditioning only on \emph{past} observations $y_{0:t}$

~

\item[] $\To$ the \emph{backward messages is 1}, $\b_t(x_t)\equiv 1$

\item[] $\To$ the filter estimate
\begin{align*}
P(x_t \| y_{1:t})
 &\propto \r(x_t)~ \a(x_t) \\
 &= P(y_t \| x_t)~ \sum_{x_{t\1}} P(x_t|x_{t\1})~ P(x_{t\1} |\ y_{1:t\1}) \\
\end{align*}

~

\item This is the general Bayes Filter. Kalman filter variants, particle filter, and some SLAM methods are approximations to this exact Bayesian filter

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Inference in HMMs -- implementation notes}{

\small
\newcommand{\for}{{\texttt{for}}}

\item The message passing equations can be implemented by reinterpreting
them as matrix equations: Let $\vec\a_t, \vec\b_t, \vec\r_t$ be the
vectors corresponding to the probability tables
$\a_t(x_t), \b_t(x_t), \r_t(x_t)$; and let $\vec P$ be the matrix with
enties $P(x_t \| x_{t\1})$. Then

\begin{algo}
\State $\vec\a_0=\vec\pi$,~ $\vec\b_T=1$
\State $\for_{t=1:T\1}:$~ $\vec\a_t = \vec P~ (\vec\a_{t\1} \circ \vec\r_{t\1})$
\State $\for_{t=T\1:0}:$~ $\vec\b_t = \vec P^\T~ (\vec\b_{t\po} \circ \vec\r_{t\po})$
\State $\for_{t=0:T}:$~ $\vec q_t = \vec\a_t \circ \vec\r_t \circ \vec\b_t$
\State $\for_{t=0:T\1}:$~
$\vec Q_t =  \vec P \circ [(\vec\b_{t\po} \circ \vec\r_{t\po})~ (\vec\a_t \circ \vec\r_t)^\T]$
\end{algo}

%% \begin{align*}
%% \text{forward msg.}
%% &&
%% \vec\a_t
%%  &= \vec P~ (\vec\a_{t\1} \circ \vec\r_{t\1}) \\
%% \text{backward msg.}
%% &&
%% \vec\b_t
%%  &= \vec P^\T (\vec\b_{t\po} \circ \vec\r_{t\po}) \\
%% \text{posterior marginal}
%% &&
%% \vec q_t &= \vec\a_t \circ \vec\r_t \circ \vec\b_t
%% \end{align*}

where $\circ$ is the \emph{element-wise product!} Here,
$\vec q_t$ is the vector with entries $q(x_t)$, and $\vec
Q_t$ the matrix with entries $q(x_{t\po},x_t)$. Note that the equation
for $\vec Q_t$ describes $Q_t(x',x) = P(x'|x)
[(\b_{t\po}(x') \r_{t\po}(x')) (\a_t(x)\r_t(x))]$.

%% \item Generally, the operations for message passing in factor graphs
%% (with potentially high-dimensional factors) are tensor operations -- a
%% general software would first implement a general tensor library, then
%% message passing.

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{}{
%% \center

%% \hspace*{-10mm}
%% \showh[.5]{codepics/hmm3}
%% \showh[.5]{codepics/hmm4}\\

%% \showh[.6]{codepics/hmm5}

%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\slide{Inference in HMMs: classical derivation}{

{\tiny Given our knowledge of Belief propagation, inference in HMMs is
simple. For reference, here is a more classical derivation:

}

{\small
\begin{align*}
P(x_t \| y_{0:T})
&= \frac{P(y_{0:T} \| x_t)~ P(x_t)}{P(y_{0:T})} \\
&= \frac{P(y_{0:t} \| x_t)~ P(y_{t\po:T} \| x_t)~ P(x_t)}{P(y_{0:T})} \\
&= \frac{P(y_{0:t}, x_t)~ P(y_{t\po:T} \| x_t)}{P(y_{0:T})} \\
&= \frac{\a_t(x_t)~ \b_t(x_t)}{P(y_{0:T})} \\
\a_t(x_t)
&:= P(y_{0:t}, x_t)
 = P(y_t|x_t)~ P(y_{0:t\1}, x_t) \\
%&=P(y_t|x_t)~ \sum_{x_{t\1}} P(x_t \| x_{t\1})~ P(y_{0:t\1}, x_{t\1}) \\
&= P(y_t|x_t)~ \sum_{x_{t\1}} P(x_t \| x_{t\1})~ \a_{t\1}(x_{t\1}) \\
\b_t(x_t)
&:=P(y_{t\po:T} \| x_t)
 =\sum_{x_{t\po}} P(y_{t\po:T} \| x_{t\po})~ P(x_{t\po} \| x_t) \\
%&=\sum_{x_{t\po}} \[P(y_{t\myplus 2:T} \| x_{t\po})~ P(y_{t\po}|x_{t\po})\] P(x_{t\po} \| x_t) \\
&=\sum_{x_{t\po}} \[\b_{t\po}(x_{t\po})~ P(y_{t\po}|x_{t\po})\]~ P(x_{t\po} \| x_t)
\end{align*}
}
%
Note: $\a_t$ here is the same as $\a_t\circ\r_t$ on all other slides!

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\key{Kalman filter}
\slide{HMM remarks}{

\item The computation of forward and backward messages along the
Markov chain is also called \textbf{forward-backward algorithm}

\item Sometimes, computing forward and backward messages (in disrete
or continuous context) is also called \textbf{Bayesian
filtering/smoothing}

\item The EM algorithm to learn the HMM parameters is also
called \textbf{Baum-Welch algorithm}

\item If the latent variable $x_t$ is \textbf{continuous} $x_t\in\RRR^d$
instead of discrete, then such a Markov model is also
called \textbf{state space model}.

\item If the continuous transitions and observations are linear Gaussian
$$P(x_{t\po}|x_t) = \NN(x_{t\po} \| A x_t + a, Q) \comma
P(y_t |x_t) = \NN(y_t \| C x_t + c, W)$$
then the forward and backward messages $\a_t$ and $\b_t$ are also
Gaussian.

$\to$ forward filtering is also called \textbf{Kalman filtering}

$\to$ smoothing is also called \textbf{Kalman smoothing}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\slide{Kalman Filter example}{

\item filtering of a position $(x,y)\in\RRR^2$:\\
\show[.7]{russell/kalman-filtering.pdf}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Kalman Filter example}{

\item smoothing of a position $(x,y)\in\RRR^2$:\\
\show[.7]{russell/kalman-smoothing.pdf}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{HMM remarks}{

%% ~

%% \item HMMs are frequently used in

%% -- speech recognition

%% -- molecular biology sequences

%% -- text analysis (e.g.\ syntax tagging)

%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{HMM example: Learning Bach}{

\item A machine ``listens'' (reads notes of) Bach pieces over and over
   again

$\to$ It's supposed to learn how to write Bach pieces itself (or at least
   harmonize them).

~

\item \emph{Harmonizing Chorales in the Style of J S
Bach} Moray Allan \& Chris Williams (NIPS 2004)

~

\item use an HMM

-- observed sequence $Y_{0:T}$ Soprano melody

-- latent sequence $X_{0:T}$ chord \& and harmony:

~

\centerline{\includegraphics[width=8cm]{allan}}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{HMM example: Learning Bach}{

\item results: {\small\url{http://www.anc.inf.ed.ac.uk/demos/hmmbach/}}

~

\centerline{\includegraphics[width=8cm]{allan2}}

~

\item See also work by Gerhard
Widmer \url{http://www.cp.jku.at/people/widmer/}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Dynamic Bayesian Networks}{\label{lastpage}

-- Arbitrary BNs in each time slide

-- Special case: MDPs, speech, etc

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slidesfoot
