\input{../shared/shared}

\renewcommand{\course}{Artificial Intelligence}
\renewcommand{\coursepicture}{course_ai}
\renewcommand{\coursedate}{Winter 2019}
\renewcommand{\topic}{Introduction}
\renewcommand{\keywords}{}

\slides

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{}{

%% \item The current hype about AI
%% \begin{items}
%% \item The \emph{singularity}
%% \item Ethics
%% \item The value problem
%% \item The outrageous inability of humans to define what is ``good''
%% \item Paper clips
%% \end{items}

%% ~

%% \item What's the route to AI?
%% \begin{items}
%% \item Neuroscience? (EU Big Brain project)
%% \item Deep Learning? (Pure \textbf{Machine Learning}?, DeepMind (London))
%% \item Social/Emotional/conciousnes/Feelings stuff?
%% \item Hardcore classical AI? \textbf{Modern probabilistic/learning AI}?
%% \item \textbf{Robotics}?
%% \end{items}

%% ~

%% \item What are things AI never be able to do?

%% \item Why is there no university department for Intelligence Research?!

%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{What is AI?}{

\item AI is a research field

~\pause

\item AI research is about systems that take decisions
\begin{items}
\item AI formalizes decision processes: interactive (decisions change world state), or passive
\item AI distinguishes between agent(s) and the external world: decision variables
\end{items}

~\pause

\item ... systems that take optimal/desirable decisions
\begin{items}
\item AI formalizes decision objectives
\item AI aims for systems to exhibit functionally \emph{desirable behavior}
\end{items}

~\pause

\item ... systems that take optimal decisions on the basis of all available information
\begin{items}
\item AI is about inference
\item AI is about learning
\end{items}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{1) ... systems that take decisions}{

\show[.4]{RLagenAndEnvironment}

\item We assume the agent is in \emph{interaction} with a domain.
\begin{items}
\item The world is in a state $s_t\in\SS$ ~ (see below on what that
means)
\item The agent senses observations $y_t\in\OO$
\item The agent decides on an action $a_t\in\AA$
\item The world transitions to a new state $s_{t\po}$
\end{items}

~

\item The \emph{observation} $y_t$ describes all information
received by the agent (sensors, also rewards, feedback, etc) if not
explicitly stated otherwise

~

\small\hfill (The technical term for this is a POMDP)

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{State}{

\item The notion of \emph{state} is often used imprecisely

\item At any time $t$, we assume the world is in a state $s_t \in \SS$

\item $s_t$ is a \emph{state description} of a domain such that future
observations $y_{t^+}, t^+>t$ are conditionally independent of all
history observations $y_{t^-}, t^-<t$ given $s_t$ and future
actions $a_{t:t^+}$:

\medskip

\show[.6]{markov}

~

\item Notes:
\begin{items}
\item Intuitively, $s_t$ describes everything about the world that is ``relevant''
\item Worlds do not have additional latent (hidden) variables to the
state $s_t$
\end{items}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Examples}{

\item What is a sufficient definition of \emph{state} of a computer
that you interact with?

~

\item What is a sufficient definition of \emph{state} for a thermostat
scenario?

(First, assume the 'room' is an isolated chamber.)

~

\item What is a sufficient definition of \emph{state} in an autonomous
car case?

~

~\mypause

$\to$ in real worlds, the exact \emph{state} is practically not
representable

$\to$ all models of domains will have to make approximating
assumptions (e.g., about independencies)

}

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{Taxonomy of domains I}{

%% \item Domains (or models of domains) can be distinguished
%% based on their state representation
%% \begin{items}
%% \item Discrete, continuous, hybrid
%% \item Factored
%% \item Structured/relational
%% \end{items}

%% ~

%% \show[.6]{rn-factoredStateRepresentation}

%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{Relational representations of state}{

%% \item The world is composed of objects; its state described in terms
%% of properties and relations of objects. Formally
%% \begin{items}
%% \item A set of constants (referring to objects)
%% \item A set of predicates (referring to object properties or
%% relations)
%% \item A set of functions (mapping to constants)
%% \end{items}

%% ~

%% \item A (grounded) state can then described by a conjunction of predicates
%% (and functions). For example:
%% \begin{items}
%% \item Constants: $C_1, C_2, P_1, P_2, SFO, JFK$
%% \item Predicates: $At(.,.), Cargo(.), Plane(.), Airport(.)$
%% \item A state description:

%% $At(C_1, SFO) \wedge At(C_2, JFK) \wedge  At(P_1, SFO) \wedge  At(P_2, JFK)
%% \wedge Cargo(C_1) \wedge Cargo(C_2) \wedge Plane(P_1) \wedge  Plane(P_2)
%% \wedge Airport (JFK) \wedge Airport (SFO)$
%% \end{items}

%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{Taxonomy of domains}{

%% \item Domains (or models of domains) can be
%% distinguished based on:

%% ~

%% \item Categories of Russel \& Norvig:
%% \begin{items}
%% \item Fully observable vs.\ partially observable
%% \item Single agent vs.\ multiagent
%% \item Deterministic vs.\ stochastic
%% {\color{gray}
%% \item Episodic vs.\ sequential
%% \item Static vs.\ dynamic
%% \item Discrete vs.\ continuous
%% %\item Known vs.\ unknown
%% }
%% \end{items}

%% ~

%% \item We add:
%% \begin{items}
%% \item Propositional vs.\ relational
%% \item Time discrete vs.\ time continuous
%% \end{items}

%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{How can agents be formally described?}{

...or, what formal classes of agents do exist?

~

\item Basic alternative agent models:
\begin{items}
\item The agent maps $y_t \mapsto a_t$ \\ (\textbf{stimulus-response} mapping.. non-optimal)
\item The agent stores all previous observations and maps
$$f:~ y_{0:t},a_{0:t\1} \mapsto a_t$$
$f$ is called \textbf{agent function}. This is the most general model,
including the others as special cases.
\item The agent stores only the recent history and maps\\
$y_{t-k:t},a_{t-k:t\1} \mapsto a_t$ (crude, but may be a good heuristic)
\item The agent is some machine with its own \textbf{internal state} $n_t$,
e.g., a computer, a finite state machine, a brain...
The agent maps $(n_{t\1},y_t) \mapsto n_t$ (internal state update) and
$n_t \mapsto a_t$
\item The agent maintains a full probability distribution
(\textbf{belief}) $b_t(s_t)$ over the state, maps
$(b_{t\1},y_t) \mapsto b_t$ (Bayesian belief update), and
$b_t \mapsto a_t$
\end{items}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{POMDP coupled to a state machine agent}{

~

\show[.5]{pomdp_fsm}

%% ~

%% \item Is this a very limiting agent model?

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Multi-agent domain models}{

(The technical term for this is a Decentralized POMDPs)

~

\show[.4]{DECpomdp}

{\tiny\hfill (from Kumar et al., IJCAI 2011)}

~

\item This is a special type (simplification) of a general DEC-POMDP

~

\item This level of description is very general, but
NEXP-hard

Approximate methods can yield very good results, though

}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{2) ... take optimal/desirable decisions}{

\item A cognitive scientist or psychologist: ``Why are
you AI people always so obsessed with optimization? Humans are not
optimal!''

~\mypause

\item That's a total misunderstanding of what ``being optimal'' means.

\item Optimization principles are a means to describe systems:
\begin{items}
\item Feynman's ``unworldliness measure'' objective function
\item Everything can be cast optimal -- under \emph{some} objective
\item Optimality principles are just a scientific means of formally describing
systems and their behaviors (esp.\ in physics, economy, ... and AI)
\item \cit{Toussaint, Ritter \& Brock}{The Optimization Route to
Robotics -- and Alternatives}{K\"unstliche Intelligenz, 2015}
\end{items}

~\mypause

\item Vocabulary:
\begin{items}
\item Utility, typically ``expected future accumulated discounted reward''
\item A ``rational'' agent: taking decisions to maximize utility
\end{items}

%% \color{gray}
%% \item Generally, I would roughly distinguish three basic types of problems:
%% \begin{items}
%% \item Optimization 
%% \item Logical/categorial Inference ~ (CSP, find feasible solutions)
%% \item Probabilistic Inference
%% \end{items}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{What are interesting objectives?}{

\item Learn to control all degrees of freedom of the environment that
are controllable
\begin{items}
\item DOFs are mechanical/kinematics DOFs, objects, light/temperature,
mood of humans
\item This objective is generic: no preferences, not limits
\item Implies to actively go exploring and finding controllable DOFs
\item Acting to Learning (instead of 'Learning to Act' for a fixed
task)
\item Related notions in other fields: \emph{(Bayesian) Experimental
Design}, \emph{Active Learning}, curiosity, intrinsic motivation
\end{items}

~

\item At time $T$, the system will be given a random task (e.g., random goal
configuration of DOFs); the objective then is to reach it as quickly as possible

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{More on objectives}{

\item The value alignment dilemma

\item What are objectives that describe things like ``creativity'', ``empathy'', ``morale'', etc?

\item Coming up with objective functions that imply desired behavior is a core part of AI research

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{3) ... on the basis of all available information}{

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{AI = ML?}{

\item In large parts, ML is: \quad (let's call this ML$^0$)

\cen{\emph{Fitting a function $f: x\mapsto y$ to given data $D=\{ (x_i,y_i) \}_{i=1}^n$}}

~\pause

\item And what does that have to do with AI?

\item Literally, not much:
\begin{items}
\item The decision made by a ML$^0$ method is only a single decision: Decide on the function $f\in\HH$ in the hypothesis space $\HH$

\item This ``single-decision process'' is not interactive; ML$^0$ does not formalize/model/consider how the choice of $f$ changes the world

\item The objective $\LL(f, D)$ in ML$^0$ depends only on the given static data $D$ and the decision $f$, not how $f$ might change the world

\item ``Learning'' in ML$^0$ is not an interactive process, but some method to pick $f$ on the basis of the static $D$. The typically iterative optimization process is not the decision process that ML$^0$ focusses on.
\end{items}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{}{

\textbf{But,} function approximation can be used to help solving AI (interactive decision process) problems:

\item Building a trained/fixed $f$ into an interacting system based on human expert knowledge

{\tiny E.g., an engineer trains a NN $f$ to recognize street signs based on
a large fixed data set $D$. S/he builds $f$ into a car to drive
autonomously. That car certainly solves an AI problem; $f$
continuously makes decisions that change the state of the world. But
$f$ was never optimized literally for the task of interacting with the
world; it was only optimized to minimze a loss on the static data
$D$. It is not a priori clear that minimizing the loss of $f$ on $D$
is related to maximizing rewards in car driving. That fact is the
expertise of the engineer; it is not some AI algorithm that discovered
that fact. At no place there was an AI method that ``learns to drive a
car''. There was only an optimization method to minimize the loss of
$f$ on $D$.

}

\item Using ML in interactive decision processes

{\tiny
E.g., to approximate a $Q$-function, state evaluation function, reward
function, the system dynamics, etc. Then, other AI methods can use
these approximate models to actually take decisions in the interactive
context.

}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{Ups and downs of AI -- history}{

%% \tiny

%% \begin{tabular}{ll}
%% \emph{1943}       & McCulloch \& Pitts: Boolean circuit model of brain\\
%% \emph{1950}       & Turing's ``Computing Machinery and Intelligence''\\
%% \emph{1952--69}   & Look, Ma, no hands! \\
%% \emph{1950s}      & Early AI programs, including Samuel's checkers program,\\
%%            & Newell \& Simon's Logic Theorist, Gelernter's Geometry Engine\\
%% \emph{1956}       & Dartmouth meeting: ``Artificial Intelligence'' adopted\\
%% \emph{1965}       & Robinson's complete algorithm for logical reasoning\\
%% \emph{1966--74}   & AI discovers computational complexity\\
%%            & Neural network research almost disappears\\
%% \emph{1969--79}   & Early development of knowledge-based systems\\
%% \emph{1980--88}   & Expert systems industry booms\\
%% \emph{1988--93}   & Expert systems industry busts: ``AI Winter''\\
%% \emph{1985--95}   & Neural networks return to popularity\\
%% \emph{1988}--     & Resurgence of probability; general increase in technical depth\\
%%            & ``Nouvelle AI'': ALife, GAs, soft computing\\
%% \emph{1995}--     & Agents, agents, everywhere $\ldots$\\
%% \emph{2003}--     & Human-level AI back on the agenda
%% \end{tabular}

%% \hfill{\tiny(slide from Stuart Russell)}
%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Summary -- AI is about:}{

~

\item Systems that interact with the environment
\begin{items}
\item We distinguish between 'system' and 'environment' (cf.\ embodiment)
\item We just introduced basic models of interaction
\item A core part of AI research is to develop formal models for interaction
\end{items}

~

\item Systems that aim to manipulate their invironment towards 'desired' states (optimality)
\begin{items}
\item Optimality principles are a standard way to describe desired behaviors
\item We sketched some interesting objectives
\item Coming up with objective functions that imply desired behavior is a core part of AI research
\end{items}

~

\item Systems that exploit all available data, i.e., learn and infer
\begin{items}
\item Machine Learning plays a major role, but it is usually only a component in an embedding AI framework
\end{items}

}


%% \slide{}{

%% \item We gave a very general model of what
%% it means that an agent takes decisions in an interactive environment


%% \item There are many flavors of this:
%% \begin{items}
%% \item Fully observable vs.\ partially observable
%% \item Single agent vs.\ multiagent
%% \item Deterministic vs.\ stochastic
%% %{\color{gray}
%% %\item Episodic vs.\ sequential
%% %\item Static vs.\ dynamic
%% %\item Discrete vs.\ continuous
%% %\item Known vs.\ unknown
%% %}
%% \item Structure of the state space: Discrete, continuous, hybrid;
%% factored; relational 
%% \item Discrete vs.\ continuous time
%% \end{items}

%% %% ~

%% %% \item Next we need to decide on \textbf{Objectives}

%% }


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Organisation}{
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{Overview of this course}{
%% \show[1.]{overview}
%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{Vorlesungen der Abteilung MLR}{

%% \item Bachelor:
%% \begin{items}
%% \item Grundlagen der K{\"u}nstlichen Intelligenz (3+1 SWS)
%% \end{items}
%% \item Master:
%% \begin{items}
%% \item Vertiefungslinie Intelligente Systeme (gemeinsam mit Andres
%% Bruhn)
%% \item WS: Maths for Intelligent Systems
%% \item WS: Introduction to Robotics
%% \item SS: Machine Learning
%% \item (SS: Optimization)
%% \item (Reinforcement Learning), (Advanced Robotics)
%% \item Practical Course Robotics (SS)
%% \item (Hauptseminare: Machine Learning (WS), Robotics (SS))
%% \end{items}

%% }

%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \slide{Andres Bruhn's Vorlesungen in der Vertiefungslinie}{

%% \begin{items}
%% \item WS: Computer Vision
%% \item SS: Correspondence Problems in Computer Vision
%% \item Hauptseminar: Recent Advances in Computer Vision
%% \end{items}

%% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Vorraussetzungen f{\"u}r die KI Vorlesung}{

\item Mathematik f{\"u}r Informatiker und Softwaretechniker

\item au{\ss}erdem hilfreich:
\begin{items}
\item Algorithmen und Datenstrukturen
\item Theoretische Informatik
\end{items}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Vorlesungsmaterial}{

\item Webseite zur Vorlesung:

{\url{https://ipvs.informatik.uni-stuttgart.de/mlr/marc/teaching/}}

die Folien und {\"U}bungsaufgaben werden dort online gestellt

~

\item Alle Materialien des letzten Jahres sind online

~

\item Hauptliteratur:

{\emph{Stuart Russell \& Peter Norvig: Artificial Intelligence – A
Modern Approach}}

\begin{items}
\item Some slides are adopted from Stuart
\end{items}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{Pr{\"u}fung}{

\item Schriftliche Pr{\"u}fung, 90 Minuten
\item Termin zentral organisiert
\item keine Hilfsmittel erlaubt
\item Anmeldung: Im LSF / beim Pr{\"u}fungsamt
\item Pr{\"u}fungszulassung:
\begin{items}
\item 50\% der Punkte der Programmieraufgaben
\item UND 50\% der Votieraufgaben
\end{items}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\slide{{\"U}bungen}{\label{lastpage}

\item 8 {\"U}bungsgruppen (4 Tutoren)
\item 2 Arten von Aufgaben: Coding- und Votier-{\"U}bungen
\item Coding-Aufgaben: Teams von bis zu 3 Studenten geben die Coding-Aufgaben zusammen ab
\item Votier-Aufgaben:
\begin{items}
\item Zu Beginn der {\"U}bung eintragen, welche Aufgaben bearbeiten wurden/pr{\"a}sentiert werden k{\"o}nnen
\item Zuf{\"a}llige Auswahl
\end{items}
\item Schein-Kriterium:
\begin{items}
\item 50\% der Punkte der Programmieraufgaben
\item UND 50\% der Votieraufgaben
\end{items}

~

\item \textbf{Registrierung}

{\small\url{https://ipvs.informatik.uni-stuttgart.de/mlr/teaching/course-registration/}}

Passwort: ki2019


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\slidesfoot
