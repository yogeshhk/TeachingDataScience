\input{../shared/shared}

\renewcommand{\course}{Artificial Intelligence}
\renewcommand{\coursepicture}{course_ai}
\renewcommand{\coursedate}{Winter 2019}
\renewcommand{\exnum}{2}

\exercises

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Programmieraufgabe: Schach}

Implementieren Sie ein Schach spielendes Programm. Der grundlegende
Python code ist dafür in Ihren Repositories. Wir haben auch bereits
die Grundstruktur eines UCT Algorithmus implementiert, so dass Sie
nur die einzelnen Funktionen implementieren müssen. Die Implementierung von möglichen Erweiterungen steht Ihnen frei. 
\begin{description}
% \item[Modifiziertes Spielende] Zur Vereinfachung wird das Spiel nach
% spätestens 50 Zügen abgebrochen. Der Gewinn ist dann der Wert der
% beiliegenden Evaluations-Funktion (positiv, wenn man gut steht,
% negative, wenn man schlecht steht). Dies veringert die Suchtiefe
% deutlich und gibt ein viel detaillierteres Signal als nur $\{+1/-1\}$
% für gewonnen/verloren.

\item[Evaluations-Funktion statt Random Rollouts:] 
Es stellte sich heraus, dass der Erfolg naiver UCT Algorithmen
bescheiden ist.  Um die Baumsuche deutlich zu vereinfachen kann man die
Evaluations-Funktion nutzen, um neue Blätter des Baums zu evaluieren (und
    den backup zu machen), statt eines random rollouts. Aber: Die
    Evaluations-Funktion ist deterministisch, und könnte die Suche
    fehlleiten. Als nächsten Schritt kann man deshalb sehr kurze random
    rollouts nehmen, die schon nach wenigen Schritten enden und mit der
    Evaluations-Funktion bewertet werden.

\item[Ziel:] Wir 'be-punkten' diese Aufgabe automatisiert
    indem wir den Schach-Agenten 10 mal gegen einen Random-Spieler
    antreten lassen. Ziel ist es nach Punkten zu gewinnern. (Sieg - 1 Punkt, Unentschieden - 0.5 Punkte, Niederlage - 0 Punkte).


\item[Turnier:] Außerdem planen wir alle Schach-Agenten in einem Turnier gegeneinander antreten zu lassen. Das Gewinnerteam darf sich über eine kleine Belohnung freuen!

% \item[Ziel: Besser als zufällig] Wir 'be-punkten' diese Aufgaben nicht
% automatisch mit einem Unit-Test. Stattdessen werden die Tutoren die in
% git eingecheckten Lösungen während der Übung auschecken; Sie müssen
% dann den Code beschreiben und live demonstrieren, dass Ihr Algorithmus im
% Mittel einen random Spieler schlägt.
\end{description}

Ihr Algorithmus soll auf  folgendes Interface zugreifen:
{\small
\begin{verbatim}

class ChessPlayer(object):
    def __init__(self, board, player):
        # The game board is the board at the beginning, player is
        # either chess.WHITE or chess.BLACK.
        pass

    def inform_move(self, move):
        # after each move (also your own) this function is called to inform 
        # the player of the move played (which can be a different one than you
        # chose, if you chose a illegal one.
        pass

    def get_next_move(self):
        # yields the move that you want to play next.
        pass

\end{verbatim}
}

Sie können Ihre Implementierung testen mit

{\small\verb+$ python2 interface.py --human --white --secs 2+}

um als Mensch gegen Ihren Spieler zu spielen. Oder mit

{\small\verb+$ python2 interface.py --random --white --secs 2+}

um einen zufällig spielenden Spieler gegen ihr Programm antreten zu lassen.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Votieraufgabe: ~ Bayes}

a) Box 1 contains 8 apples and 4 oranges. Box 2 contains 10 apples and 2
oranges. Boxes are chosen with equal probability. What is the
probability of choosing an apple? If an apple is chosen, what is the
probability that it came from box 1?

~

b) The blue M\&M was introduced in 1995.
Before then, the color mix in a bag of plain M\&Ms was:
30\% Brown, 20\% Yellow, 20\% Red, 10\% Green, 10\% Orange, 10\% Tan.
Afterward it was: 24\% Blue , 20\% Green, 16\% Orange, 14\% Yellow, 13\% Red,
13\% Brown.

A friend of mine has two bags of M\&Ms, and he tells me that one is from
1994 and one from 1996.  He won't tell me which is which, but he gives me
one M\&M from each bag.  One is yellow and one is green.  What is the
probability that the yellow M\&M came from the 1994 bag?

~

c) The Monty Hall Problem: I have three boxes. In one I put a prize,
and two are empty. I then mix up the boxes. You want to pick the box
with the prize in it. You choose one box. I then open \emph{another}
one of the two remaining boxes and show that it is empty. I then give
you the chance to change your choice of boxes---should you do so? Please give a rigorous argument using Bayes.

~

d) Given a joint probability $P(X,Y)$ over 2 binary random variables
as the table\\
\cen{\begin{tabular}{lrr}
\hline
       & Y=0 & Y=1 \\
\hline
X=0    & .06 & .24 \\
X=1    & .14 & .56 \\
\hline
\end{tabular}}
What are $P(X)$ and $P(Y)$? Are $X$ and $Y$ independent?

%% \begin{enumerate}

%% \item Die Wahrscheinlichkeit, an der bestimmten tropischen Krankheit
%%   zu erkranken, betr"agt 0,02\%.  Ein Test, der bestimmt, ob man
%%   erkrankt ist, ist in 99,995\% der F"alle korrekt. Wie hoch ist die
%%   Wahrscheinlichkeit, tats"achlich an der Krankheit zu leiden, wenn
%%   der Test positiv ausf"allt?

%% \item Eine andere seltene Krankheit betrifft 0,005\% aller
%%   Menschen. Ein entsprechender Test ist in 99,99\% der F"alle
%%   korrekt. Mit welcher Wahrscheinlichkeit ist man bei positivem
%%   Testergebnis von der Krankheit betroffen?

%% \item Es gibt einen neuen Test f"ur die Krankheit aus b), der in
%%   99,995\% der F"alle korrekt ist. Wie hoch ist hier die
%%   Wahrscheinlichkeit, erkrankt zu sein, wenn der Test positiv
%%   ausf"allt?

%% \end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Präsenzaufgabe: ~ Bandits}

Assume you have 3 bandits. You have already tested them a few times
and received returns
\begin{itemize}
\item From bandit 1:~ 8 7 12 13 11 9
\item From bandit 2:~ 8 12
\item From bandit 3:~ 5 13
\end{itemize}

For the returns of each bandit separately, compute a) the mean return,
the b) standard deviation of returns, and c) standard deviation of the
mean estimator.

Which bandid would you choose next? (Distinguish cases: a) if you know
this is the last chance to pull a bandit; b) if you will have many
more trials thereafter.)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exerfoot
