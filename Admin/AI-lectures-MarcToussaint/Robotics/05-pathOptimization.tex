\input{../shared/shared}

\renewcommand{\course}{Robotics}
\renewcommand{\coursepicture}{roboticsLecture}
\renewcommand{\coursedate}{Winter 2014}
\renewcommand{\topic}{Path Optimization -- briefly}

\slides

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\slide{Outline}{

\item These are only some very brief notes on path optimization

~

\item The aim is to explain how to \emph{formulate} the optimization
problem. Concerning the optimization algortihm itself, refer to the
\emph{Optimization} lecture.

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\key{From inverse kinematics to path costs}
\slide{From inverse kinematics to path costs}{

\item Recall our optimality principle of inverse kinematics
$$\argmin_q \norm{q-q_0}_W^2 + \norm{\Phi(q)}^2$$

\item A trajectory $q_{0:T}$ is a sequence of robot configurations
$q_t \in\RRR^n$

\item Consider the cost function
\begin{align*}
f(q_{0:T})
 = \sum_{t=0}^T \norm{q_{t\1}-q_t}_W^2
%\norm{\Psi_t(q_{t\myminus k},..,q_t)}^2
 + \sum_{t=0}^T \norm{\Phi_t(q_t)}^2
\end{align*}
\hfill{\tiny (where $(q_{\1}$ is a given prefix)}

\item $\norm{q_{t\1}-q_t}_W^2$ represents \textbf{control costs}

%$k$ denotes the \textbf{order} of the control costs

$\Phi_t(q_t)$ represents \textbf{task costs}

%(More generally, task costs could depend on $\Phi_t(q_{t\myminus k},..,q_t)$)

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\key{General $k$-order cost terms}
\slide{General $k$-order cost terms}{

{\tiny [Notation: $x_t$ instead of $q_t$ represents joint state]}

\begin{align*}
\min_{x_{0:T}}\quad&
\sum_{t=0}^{T} f_t(x_{t-k:t})^\T f_t(x_{t-k:t})
%~+~ \sum_{t,t'} k(t,t') x_t^\T x_{t'}
 \feed
\st&
 \forall_t:~ g_t(x_{t-k:t}) \le 0 \comma h_t(x_{t-k:t}) = 0 ~.
\end{align*}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\slide{Cost terms}{

\item The $f_t(x_{t-k:t})$ terms can penalize various things:

~

\small
\begin{tabular}{|c|l|p{.3\columnwidth}|}
\hline
%$k=0$ & $f_t(x_t) = x_t - x_0$ & penalize offset from zero \\
$k=1$ & $f_t(x_{t\1},x_t) = x_t-x_{t\1}$ & penalize velocity \\
$k=2$ & $f_t(x_{t\2},..,x_t) = x_t-2x_{t\1}+x_{t\2}$ & penalize acceleration \\
$k=3$ & $f_t(x_{t\myminus 3},..,x_t) = x_t-3x_{t\1}+3x_{t\2}-x_{t\myminus 3}$ &
penalize jerk\\
\hline
\end{tabular}

or in some arbitrary task spaces

\begin{tabular}{|c|l|p{.2\columnwidth}|}
\hline
$k=0$ & $f_t(x_t) = \phi(x_t) - y^*$ & penalize offset in some task space \\
$k=1$ & $f_t(x_{t\1},x_t) = \phi x_t-\phi x_{t\1}$ & \\
$k=2$ & $f_t(x_{t\2},..,x_t) = \phi x_t-2\phi x_{t\1}+\phi x_{t\2}$ & \\
$k=3$ & $f_t(x_{t\myminus 3},..,x_t) = \phi x_t-3\phi x_{t\1}+3\phi
x_{t\2}-\phi x_{t\myminus 3}$ & \\
\hline
\end{tabular}

~

\item And terms $f_t$ can be stacked arbitrarily

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\key{Choice of optimizer}
\slide{Choice of optimizer}{\label{lastpage}

\begin{align*}
\min_{x_{0:T}}\quad&
\sum_{t=0}^{T} f_t(x_{t-k:t})^\T f_t(x_{t-k:t})
%~+~ \sum_{t,t'} k(t,t') x_t^\T x_{t'}
 \feed
\st&
 \forall_t:~ g_t(x_{t-k:t}) \le 0 \comma h_t(x_{t-k:t}) = 0 ~.
\end{align*}

~

\item Constrained optimization methods:
\begin{items}
\item Log-barrier, squared penalties
\item \textbf{Augmented Lagrangian}
\end{items}

~

\item Note: also the Lagrangian is the form of the
so-called \textbf{Gauss-Newton} form. The pseudo Hessian is a banded,
symmetric, positive-definite matrix.

}

\slidesfoot

