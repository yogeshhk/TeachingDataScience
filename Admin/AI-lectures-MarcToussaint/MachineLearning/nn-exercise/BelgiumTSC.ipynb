{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.color import rgb2gray\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_directory):\n",
    "    directories = [d for d in os.listdir(data_directory)\n",
    "                   if os.path.isdir(os.path.join(data_directory, d))]\n",
    "    labels = []\n",
    "    images = []\n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(data_directory, d)\n",
    "        file_names = [os.path.join(label_directory, f)\n",
    "                      for f in os.listdir(label_directory)\n",
    "                      if f.endswith(\".ppm\")]\n",
    "        for f in file_names:\n",
    "            images.append(skimage.data.imread(f))\n",
    "            labels.append(int(d))\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "def plot_data(signs, labels):\n",
    "    for i in range(len(signs)):\n",
    "        plt.subplot(4, len(signs)/4 + 1, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Label {0}\".format(labels[i]))\n",
    "        plt.imshow(signs[i])\n",
    "        plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_data(\"belgiumTS/Training\")\n",
    "# display 30 random images\n",
    "#randind = np.random.randint(0, len(images), 30)\n",
    "#plot_data(images[randind], labels[randind])\n",
    "\n",
    "images = np.expand_dims(rgb2gray(np.array([transform.resize(image, (50, 50)) for image in images])), axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize placeholders \n",
    "x_input = tf.placeholder(dtype = tf.float32, shape = [None, 50, 50, 1])\n",
    "y = tf.placeholder(dtype = tf.int32, shape = [None])\n",
    "\n",
    "# Convolution layer(s)\n",
    "conv1 = tf.contrib.layers.conv2d(inputs=x_input,\n",
    "                                 num_outputs=8,\n",
    "                                 kernel_size=[3,3])\n",
    "\n",
    "# Flatten the input data\n",
    "images_flat = tf.contrib.layers.flatten(conv1)\n",
    "\n",
    "# Fully-connected layer(s)\n",
    "logits = tf.contrib.layers.fully_connected(images_flat, 100, tf.nn.relu)\n",
    "\n",
    "logits = tf.contrib.layers.fully_connected(images_flat, 62, tf.nn.relu)\n",
    "\n",
    "# Define a loss function\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, \n",
    "                                                                    logits = logits))\n",
    "# Define an optimizer \n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "# Convert logits to label indexes\n",
    "correct_pred = tf.argmax(logits, 1)\n",
    "\n",
    "# Define an accuracy metric\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ( 0 ):  4.134216\n",
      "Loss ( 10 ):  2.7979045\n",
      "Loss ( 20 ):  2.2245066\n",
      "Loss ( 30 ):  1.9525799\n",
      "Loss ( 40 ):  1.7790805\n",
      "Loss ( 50 ):  1.6547081\n",
      "Loss ( 60 ):  1.576188\n",
      "Loss ( 70 ):  1.5227932\n",
      "Loss ( 80 ):  1.4843622\n",
      "Loss ( 90 ):  1.4530287\n",
      "Loss ( 100 ):  1.4294744\n",
      "Loss ( 110 ):  1.4097914\n",
      "Loss ( 120 ):  1.3936386\n",
      "Loss ( 130 ):  1.3799673\n",
      "Loss ( 140 ):  1.3684415\n",
      "Loss ( 150 ):  1.3585111\n",
      "Loss ( 160 ):  1.3499606\n",
      "Loss ( 170 ):  1.3427266\n",
      "Loss ( 180 ):  1.3363845\n",
      "Loss ( 190 ):  1.3309339\n",
      "Loss ( 200 ):  1.3262886\n",
      "Loss ( 210 ):  1.3220586\n",
      "Loss ( 220 ):  1.3184222\n",
      "Loss ( 230 ):  1.3152616\n",
      "Loss ( 240 ):  1.3124679\n",
      "Loss ( 250 ):  1.3100126\n",
      "Loss ( 260 ):  1.3080052\n",
      "Loss ( 270 ):  1.30592\n",
      "Loss ( 280 ):  1.3041596\n",
      "Loss ( 290 ):  1.3025684\n",
      "Loss ( 300 ):  1.3011526\n",
      "Loss ( 310 ):  1.2998755\n",
      "Loss ( 320 ):  1.2987092\n",
      "Loss ( 330 ):  1.2976573\n",
      "Loss ( 340 ):  1.2966928\n",
      "Loss ( 350 ):  1.2958184\n",
      "Loss ( 360 ):  1.2950062\n",
      "Loss ( 370 ):  1.2942449\n",
      "Loss ( 380 ):  1.2935634\n",
      "Loss ( 390 ):  1.2929057\n",
      "Loss ( 400 ):  1.2923033\n",
      "Loss ( 410 ):  1.2917618\n",
      "Loss ( 420 ):  1.2912434\n",
      "Loss ( 430 ):  1.2908148\n",
      "Loss ( 440 ):  1.2903421\n",
      "Loss ( 450 ):  1.2899132\n",
      "Loss ( 460 ):  1.2895392\n",
      "Loss ( 470 ):  1.2891594\n",
      "Loss ( 480 ):  1.288833\n",
      "Loss ( 490 ):  1.2885258\n",
      "Loss ( 500 ):  1.2882109\n",
      "Loss ( 510 ):  1.2879331\n",
      "Loss ( 520 ):  1.2876673\n",
      "Loss ( 530 ):  1.2874055\n",
      "Loss ( 540 ):  1.2871774\n",
      "Loss ( 550 ):  1.2869413\n",
      "Loss ( 560 ):  1.2867327\n",
      "Loss ( 570 ):  1.286516\n",
      "Loss ( 580 ):  1.2863841\n",
      "Loss ( 590 ):  1.2861694\n",
      "Loss ( 600 ):  1.2859805\n",
      "Loss ( 610 ):  1.2858127\n",
      "Loss ( 620 ):  1.2856419\n",
      "Loss ( 630 ):  1.2854983\n",
      "Loss ( 640 ):  1.2853503\n",
      "Loss ( 650 ):  1.2852057\n",
      "Loss ( 660 ):  1.2851282\n",
      "Loss ( 670 ):  1.2849594\n",
      "Loss ( 680 ):  1.2848207\n",
      "Loss ( 690 ):  1.284712\n",
      "Loss ( 700 ):  1.2846056\n",
      "Loss ( 710 ):  1.2845371\n",
      "Loss ( 720 ):  1.2844424\n",
      "Loss ( 730 ):  1.2842883\n",
      "Loss ( 740 ):  1.284227\n",
      "Loss ( 750 ):  1.2841506\n",
      "Loss ( 760 ):  1.2840427\n",
      "Loss ( 770 ):  1.2839291\n",
      "Loss ( 780 ):  1.283836\n",
      "Loss ( 790 ):  1.2837659\n",
      "Loss ( 800 ):  1.2837265\n",
      "Loss ( 810 ):  1.2836719\n",
      "Loss ( 820 ):  1.2835773\n",
      "Loss ( 830 ):  1.2835038\n",
      "Loss ( 840 ):  1.2835064\n",
      "Loss ( 850 ):  1.2833723\n",
      "Loss ( 860 ):  1.2832888\n",
      "Loss ( 870 ):  1.2832453\n",
      "Loss ( 880 ):  1.283178\n",
      "Loss ( 890 ):  1.2831261\n",
      "Loss ( 900 ):  1.2830812\n",
      "Loss ( 910 ):  1.2830354\n",
      "Loss ( 920 ):  1.2829983\n",
      "Loss ( 930 ):  1.2829243\n",
      "Loss ( 940 ):  1.2828779\n",
      "Loss ( 950 ):  1.2828488\n",
      "Loss ( 960 ):  1.2828014\n",
      "Loss ( 970 ):  1.2827568\n",
      "Loss ( 980 ):  1.2827258\n",
      "Loss ( 990 ):  1.2826995\n",
      "Loss ( 1000 ):  1.2826532\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1001):\n",
    "        #print('EPOCH', i)\n",
    "        _, accuracy_val, train_loss = sess.run([train_op, accuracy, loss], feed_dict={x_input: images, y: labels})\n",
    "        if i % 10 == 0:\n",
    "            print(\"Loss (\", i, \"): \", train_loss)\n",
    "        #print('DONE WITH EPOCH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.601\n"
     ]
    }
   ],
   "source": [
    "test_images, test_labels = load_data(\"belgiumTS/Testing\")\n",
    "\n",
    "test_images = np.expand_dims(rgb2gray(np.array([transform.resize(image, (50, 50)) for image in test_images])), axis=3)\n",
    "\n",
    "# Run predictions against the full test set.\n",
    "predicted = sess.run([correct_pred], feed_dict={x_input: test_images})[0]\n",
    "\n",
    "# Calculate correct matches \n",
    "match_count = sum([int(y == y_) for y, y_ in zip(test_labels, predicted)])\n",
    "# Calculate the accuracy\n",
    "accuracy = match_count / len(test_labels)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
