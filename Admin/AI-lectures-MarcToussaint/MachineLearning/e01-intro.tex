\input{../shared/shared}

\renewcommand{\course}{Machine Learning}
\renewcommand{\exnum}{1}

\exercises

There will be no credit points for the first exercise -- we'll do them
on the fly. (\emph{Pr\"asenz\"ubung}) For those of you that had
lectures with me before this is redundant---you're free to skip the
tutorial.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \exsection{Hastie, Tibshirani \& Friedman}

%% Read chapter 1 of Hastie et al.'s ``Elements of Statistical Learning''
%% ({\tiny\url{http://www-stat.stanford.edu/~tibs/ElemStatLearn/}}). Consider
%% the DNA microarray data of Figure 1.3. Let's assume that samples 1-32
%% are taken from cancer cells whereas samples 33-64 from non-cancer
%% cells. How could one analyze which genes are ``involved with
%% cancer''? No formal answers needed, but ceative ideas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Reading: Pedro Domingos}

Read at least until section 5 of Pedro Domingos's \emph{A Few Useful
Things to Know about Machine Learning}
{\small\url{http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf}}. 
Be able to explain roughly what generalization and the bias-variance-tradeoff
(Fig. 1) are.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Matrix equations}

a) Let $X,A$ be arbitrary matrices, $A$ invertible. Solve for $X$:
$$ X A + A^\T = \Id $$

b) Let $X,A,B$ be arbitrary matrices, $(C-2A^\T)$ invertible. Solve for $X$:
$$ X^\T C = [2 A (X + B)]^\T $$

c) Let $x\in\RRR^n,y\in\RRR^d,A\in\RRR^{d\times n}$. $A$ obviously \emph{not}
invertible, but let $A^\T A$ be invertible. Solve for $x$:
$$ (A x - y)^\T A = \vec 0_n^\T $$

d) As above, additionally $B\in\RRR^{n\times n}$, $B$
positive-definite. Solve for $x$: 
$$ (A x - y)^\T A + x^\T B = \vec 0_n^\T $$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Vector derivatives}

Let $x\in\RRR^n,y\in\RRR^d,A\in\RRR^{d\times n}$.

a) What is $\frac{\del}{\del x} x$ ~? (Of what type/dimension is this thing?)

b) What is $\frac{\del}{\del x}[x^\T x]$ ~?

c) Let $B$ be symmetric (and pos.def.). What is the minimum of $(Ax -
y)^\T (Ax - y) + x^\T B x$ w.r.t.\ $x$?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Coding}

Future exercises will need you to code some Machine Learning
methods. You are free to choose your programming language. If you're
new to numerics we recommend Python (SciPy \&
scikit-learn) or Matlab/Octave.  I'll support C++, but recommend it really only to
those familiar with C++.

To get started, try to just plot the data set {\small\url{http://ipvs.informatik.uni-stuttgart.de/mlr/marc/teaching/data/dataQuadReg2D.txt}}, e.g.\ in Octave:\\
\quad\begin{code}
\begin{verbatim}
D = importdata('dataQuadReg2D.txt');
plot3(D(:,1),D(:,2),D(:,3), 'ro')
\end{verbatim}
\end{code}
Or in Python\\
\quad\begin{code}
\begin{verbatim}
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

D = np.loadtxt('dataQuadReg2D.txt')

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.plot(D[:,0],D[:,1],D[:,2], 'ro')
plt.show()
\end{verbatim}
\end{code}
Or you can store the grid data in a file and use gnuplot, e.g.:\\
\begin{code}
\begin{verbatim}
splot 'dataQuadReg2D.txt' with points
\end{verbatim}
\end{code}


For those using C++, download and test {\small\url{https://github.com/MarcToussaint/rai}}. In
particular, have a look at test/Core/array with
many examples on how to use the array class. Report on problems with
installation.

\exerfoot

%% n = np.size(D,0)
%% Y = D[:,2]
%% X = np.hstack( [ np.ones([n,1]), D[:,0:2] ] )
%% beta = np.linalg.inv(X.T * X)*X.T * Y;
