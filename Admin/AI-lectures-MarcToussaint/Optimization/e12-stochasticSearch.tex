\input{../shared/shared}

\renewcommand{\course}{Optimization}
\renewcommand{\coursepicture}{optim}
\renewcommand{\coursedate}{Summer 2015}
\renewcommand{\exnum}{7}

\exercises

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{CMA vs.\ twiddle search}

At \url{https://www.lri.fr/~hansen/cmaes_inmatlab.html} there is code
for CMA for all languages (I do not recommend the C++ versions).

a) Test CMA with a standard parameter setting a log-variant of the Rosenbrock
  function (see Wikipedia). My implementation of this function in C++ is:\\
\begin{code}
\begin{verbatim}
 double LogRosenbrock(const arr& x) {
    double f=0.;
    for(uint i=1; i<x.N; i++)
      f += sqr(x(i)-sqr(x(i-1)))
           + .01*sqr(1-x(i-1));
    f = log(1.+f);
    return f;
  }
\end{verbatim}
\end{code}
where @sqr@ computes the square of a double.

Test CMA for the $n=2$ and $n=10$ dimensional Rosenbrock
function. Initialize around the start point $(1,10)$ and $(1,10,..,10)\in\RRR^{10}$
with standard deviation 0.1. You might require up to 1000 iterations.

CMA should have no problem in optimizing this function -- but as it
always samples a whole population of size $\l$, the number of
evaluations is rather large. Plot $f(x_{\text{best}})$ for the best
point found so far versus the total number of function evaluations.

~

b) Implement Twiddle Search (slide 05:15) and test it on the same
function under same conditions. Also plot $f(x_{\text{best}})$ versus
the total number of function evaluations and compare to the CMA results.



\exerfoot
