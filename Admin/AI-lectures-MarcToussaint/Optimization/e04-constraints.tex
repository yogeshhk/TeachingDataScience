\input{../shared/shared}

\renewcommand{\course}{Optimization}
\renewcommand{\coursepicture}{optim}
\renewcommand{\coursedate}{Summer 2015}
\renewcommand{\exnum}{4}

\exercises

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \exsection{Equality Constraint Penalties and augmented Lagrangian}

%% (We don't need to know what the Langangian is (yet) to solving this
%% exercise.)

%% In the lecture we discussed the squared penalty method for inequality
%% constraints. There is a straight-forward version for equality
%% constraints: Instead of 
%% \begin{align}
%% \min_x~ f(x) \st h(x) = 0
%% \end{align}
%% we address
%% \begin{align}
%% \min_x~ f(x) + \mu \sum_{i=1}^m h_i(x)^2 \label{eq1}
%% \end{align}
%% such that the squared penalty pulls the solution onto the constraint
%% $h(x)=0$. Assume that if we minimize (\ref{eq1}) we end up at a solution
%% $x_1$ for which each $h_i(x_1)$ is reasonable small, but not exactly
%% zero.

%% We also mentioned the idea that we could add an additional term which
%% counteracts the violation of the constraint. This can be realized by
%% minimizing
%% \begin{align}
%% \min_x~ f(x) + \mu \sum_{i=1}^m h_i(x)^2 + \sum_{i=1}^m \l_i h_i(x)\label{eq2}
%% \end{align}
%% for a ``good choice'' of each $\l_i$. It turns we can infer this ``good
%% choice'' from the solution $x_1$ of (\ref{eq1}):

%% Proof that setting $\l_i = 2\mu h_i(x_1)$ will, if we assume that the
%% gradients $\na f(x)$ and $\na h(x)$ are (locally) constant,
%% ensure that the minimum of (\ref{eq2}) fulfils exactly the
%% constraints $h(x)=0$.

%% Tip: Think intuitive. Think about how the gradient that arises from
%% the penalty in (\ref{eq1}) is now generated via the $\l_i$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Alternative Barriers \& Penalties}

Propose 3 alternative barrier functions, and 3 alternative penalty
functions. To display functions, gnuplot is useful, e.g.,
@plot -log(-x)@.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \exsection{Trust Region}

%% Consider a function $f(x)=x^\T A x + b^\T x$. For a given $x_0$, solve analytically
%% $$\min_x f(x) \st (x-x_0)^\2 < \a$$


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Squared Penalties \& Log Barriers}

In a previous exercise we defined the ``hole function''
$f^c_{\text{hole}}(x)$, where we now assume a conditioning $c=4$.

Consider the optimization problem
\begin{align}
\min_x f^c_{\text{hole}}(x) \st& g(x) \le 0 \\
& g(x) = \mat{c}{x^\T x - 1 \\ x_n + 1/c}
\end{align}

a) First, assume $n=2$ ($x\in\RRR^2$ is 2-dimensional), $c=4$, and
draw on paper what the problem looks like and where you expect the
optimum.

b) Implement the Squared Penalty Method. (In the inner loop you may
choose any method, including simple gradient methods.) Choose as a
start point $x=(\half, \half)$. Plot its optimization path and report
on the number of total function/gradient evaluations needed.

c) Test the scaling of the method for $n=10$ dimensions.

d) Implement the Log Barrier Method and test as in b) and
c). Compare the function/gradient evaluations needed.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% \exsection{Lagrangian and dual function}

%% (Taken roughly from `Convex Optimization', Ex. 5.1)

%% A simple example. Consider the optimization problem
%% $$\min x^2 + 1 \st (x-2)(x-4) \le 0$$
%% with variable $x \in \RRR$.

%% a) Derive the optimal solution $x^*$ and the optimal value
%% $p^*=f(x^*)$ by hand.

%% b) Write down the Lagrangian $L(x,\l)$. Plot (using gnuplot or so)
%% $L(x,\l)$ over $x$ for various values of $\l\ge 0$. Verify the
%% lower bound property $\min_x L(x,\l) \le p^*$, where $p^*$ is the
%% optimum value of the primal problem.

%% c) Derive the dual function $l(\l) = \min_x L(x,\l)$ and plot it (for $\l\ge
%% 0$). Derive the dual optimal solution $\l^* = \argmax_\l l(\l)$. Is
%% $\max_\l l(\l) = p^*$ (strong duality)?

\exerfoot
