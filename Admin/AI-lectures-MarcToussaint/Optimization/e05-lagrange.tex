\input{../shared/shared}

\renewcommand{\course}{Optimization}
\renewcommand{\coursepicture}{optim}
\renewcommand{\coursedate}{Summer 2015}
\renewcommand{\exnum}{5}

\exercises

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Equality Constraint Penalties and augmented Lagrangian}

Take a squared penalty approach to solving a constrained optimization problem
\begin{align}
\min_x~ f(x) + \mu \sum_{i=1}^m h_i(x)^2 \label{eq1}
\end{align}

The Augmented Lagrangian method adds yet another penalty term
\begin{align}
\min_x~ f(x) + \mu \sum_{i=1}^m h_i(x)^2 + \sum_{i=1}^m \l_i h_i(x)\label{eq2}
\end{align}

Assume that if we minimize (\ref{eq1}) we end up at a solution $\bar{x}$ for
which each $h_i(\bar{x})$ is reasonable small, but not exactly zero.  Prove, in
the context of the Augmented Lagrangian method, that setting $\l_i = 2\mu
h_i(\bar{x})$ will, if we assume that the gradients $\na f(x)$ and $\na h(x)$
are (locally) constant, ensure that the minimum of (\ref{eq2}) fulfills
the constraints $h(x)=0$.

Tip: Think intuitive. Think about how the gradient that arises from
the penalty in (\ref{eq1}) is now generated via the $\l_i$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \exsection{Lagrangian Method of Multipliers}

% In a previous exercise we defined the ``hole function'' $f^c_{\text{hole}}(x)$,
% assume conditioning $c=10$ and use the Lagrangian Method of Multipliers to
% solve on paper the following constrained optimization problem in $2D$.

% \begin{align}
% \min_x f^c_{\text{hole}}(x) \st& h(x)=0 \\
% h(x) = v^\T x - 1
% \end{align}

% Near the very end, you won't be able to proceed until you have special values
% for $v$. Go as far as you can without the need for these values.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Lagrangian and dual function}

(Taken roughly from `Convex Optimization', Ex. 5.1)

A simple example. Consider the optimization problem
$$\min x^2 + 1 \st (x-2)(x-4) \le 0$$
with variable $x \in \RRR$.

a) Derive the optimal solution $x^*$ and the optimal value
$p^*=f(x^*)$ by hand.

b) Write down the Lagrangian $L(x,\l)$. Plot (using gnuplot or so)
$L(x,\l)$ over $x$ for various values of $\l\ge 0$. Verify the
lower bound property $\min_x L(x,\l) \le p^*$, where $p^*$ is the
optimum value of the primal problem.

c) Derive the dual function $l(\l) = \min_x L(x,\l)$ and plot it (for $\l\ge
0$). Derive the dual optimal solution $\l^* = \argmax_\l l(\l)$. Is
$\max_\l l(\l) = p^*$ (strong duality)?


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\exsection{Augmented Lagrangian Programming}

Take last week's programming exercise on Squared Penalty and ``augment'' it so
that it becomes the Augmented Lagrangian method.  Compare the function/gradient
evaluations between the simple Squared Penalty method and the Augmented method.

\exerfoot
