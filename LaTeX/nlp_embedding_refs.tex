\begin{frame}\frametitle{References}
\begin{itemize}
\item Word2Vec - (Girish K.,Sivan Biham \& Adam Yaari, Adrian Colyer)
\item Mikolov et al. (2013) - Word2Vec papers
\item Pennington et al. (2014) - GloVe paper
\item Bojanowski et al. (2017) - FastText
\item Peters et al. (2018) - ELMo
\item Devlin et al. (2018) - BERT
% \item A key idea from the highly cited paper:
% \begin{quote}
% Mikolov, Tomas, Ilya Sutskever, Kai Chen, Greg S. Corrado, and
% Jeff Dean. ``Distributed representations of words and phrases
% and their compositionality." In Advances in neural information
% processing systems, pp. 3111-3119. (2013).
% \end{quote}
% \item And the closely related follow-up:
% \begin{quote}
% Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean.
% ``Efficient estimation of word representations in vector space."
% arXiv preprint arXiv:1301.3781 (2013).
% \end{quote}
% \item Want to use the context of a word to predict other similar
% words that tend to co-occur with it.
% \item  Two approaches used are called {skip grams} and {continuous bag of words}.
\end{itemize}
\end{frame}

