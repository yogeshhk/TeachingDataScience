%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Introduction to LangGraph}
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}\frametitle{What is LangGraph?}

\begin{itemize}
\item Building state-ful multi agent applications using LLMs (Large Language Models)
\item So, components are not in `chain' as in LangChain (ie Sequential) but can a Graph.
\item Like Workflow modeling or orchestration
\end{itemize}

\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{langgraph1}
\end{center}	  


{\tiny (Ref: Introduction to LangGraph | Building an AI Generated Podcast - Prompt Circle AI)}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Introduction to LangGraph}
      \begin{itemize}
        \item LangGraph is a graph-based framework for building complex LLM applications
        \item Represents AI workflows as directed graphs with nodes, edges, and data states
        \item Addresses limitations of LCEL and AgentExecutor in complex scenarios
        \item Provides intuitive and flexible approach to constructing conversational flows
        \item Supports looping, branching, and dynamic execution paths
        \item Enables state persistence and human-machine interaction
        \item Seamlessly integrates with existing LangChain ecosystem
        \item Offers streaming processing and real-time feedback capabilities
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Limitations of LCEL Chain Expressions}
      \begin{itemize}
        \item Linear processes with predefined execution order
        \item Difficulty in dynamic routing and conditional branching
        \item Complex state management in multi-turn conversations
        \item Manual state passing and updates increase code complexity
        \item Non-intuitive tool integration and coordination
        \item Nested tools create highly complex LCEL expressions
        \item Limited flexibility for dynamic conversational scenarios
        \item Error-prone state management across chain calls
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LCEL Complexity Example}

For example, when constructing a parallel sub-problem optimization chain for a problem decomposition strategy, the complexity of LCEL expressions becomes apparent. This example shows that when the nesting level of tools is slightly deeper, constructing LCEL chains becomes quite complex.

      \begin{lstlisting}[language=Python, basicstyle=\tiny]
# Decomposition chain
decomposition_chain = (
    {"question": RunnablePassthrough()}
    | decomposition_prompt
    | ChatOpenAI(model="gpt-4o-mini", temperature=0)
    | StrOutputParser()
    | (lambda x: x.strip().split("\n"))
)

# Sub-question answer generation chain
sub_question_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | sub_question_prompt
    | ChatOpenAI(model="gpt-4o-mini")
    | StrOutputParser()
)

# Assembly chain
chain = (
    {"question": RunnablePassthrough(), "context": decomposition_chain}
    | {"questions": RunnablePassthrough(), "answers": sub_question_chain.map()}
    | RunnableLambda(format_qa_pairs)
    | prompt
    | llm_output_str
)
      \end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Limitations of AgentExecutor}
      \begin{itemize}
        \item Complex configuration for conversational flows and multi-turn dialogues
        \item Limited dynamic routing capability for conditional branches
        \item Lack of built-in state persistence mechanism
        \item Over-encapsulation with fixed input requirements
        \item Black-box uncontrollability in tool usage order
        \item Cannot insert human interaction during execution
        \item Difficult secondary development due to rigid structure
        \item Must restart from scratch when conversation resumes
      \end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Why LangGraph?}

\begin{itemize}
\item Limitations of LCEL and AgentExecutor, need a more flexible and powerful framework to build complex agent applications.
\item Most of the Multi-agent frameworks are rigid, monolithic
\item LangGraph decouples the agents from their orchestration.
\item Here, agents can have different LLMs, can combine even non-LLM services together, can combine agents from other systems such as Autogen or Crew AI etc.
\end{itemize}


{\tiny (Ref: Langgraph: The Agent Orchestrator - Rajib Deb)}

% \begin{lstlisting}
% agent_1 = MyAgent("agent_1")
% agent_2 = MyAgent("agent_2")
% group_chat = [agent_1,agent_2]
% group_chat.invoke("What is GST?")
% \end{lstlisting}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LangChain vs LangGraph}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents64}
		
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents66}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents65}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    
    \end{column}
  \end{columns}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LangChain vs LangGraph – Why a New Approach?}

      \begin{itemize}
        \item LangChain excels at straightforward pipelines with fixed sequential tasks (retrieve → summarize → answer)
        \item Real-world workflows aren't always linear - they need branches, loops, and dynamic decision points
        \item LangGraph specializes in stateful, non-linear workflows within the LangChain ecosystem
        \item LangGraph exposes control flow explicitly, allowing fine-grained control over agent behavior
        \item You define a graph of possible steps instead of a rigid chain structure
        \item Agents can revisit nodes or choose different paths dynamically based on conditions
        \item Use LangChain for simple sequences, LangGraph for conditional logic and extended context
        \item LangGraph enables complex multi-agent systems with evolving task flows
      \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LangGraph Fundamentals: Nodes, Edges \& State}

      \begin{itemize}
        \item \textbf{Nodes (N):} Individual processing steps implemented as Python functions that transform state
        \item Each node encapsulates one sub-task: LLM calls, calculations, file operations, or tool invocations
        \item \textbf{Edges (E):} Directed connections determining execution order and flow between nodes
        \item Edges can be linear progressions or conditional routes based on current state
        \item \textbf{State (S):} Shared data object (dictionary/TypedDict) persisting throughout agent execution
        \item State enables context and memory across workflow, allowing nodes to read previous results
        \item StateGraph ties everything together with designated START and END nodes
        \item This approach handles interactive, conditional loops that static chains struggle with
      \end{itemize}
  

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LangGraph}
\begin{columns}
    \begin{column}[T]{0.5\linewidth}
        \begin{center}
		
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents67}
		
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents68}
		
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    
    \end{column}
    \begin{column}[T]{0.5\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents69}
		
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents70}
		
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents71}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Building an Email Sorting Agent}

      \begin{itemize}
        \item Email processing assistant inspired by Alfred managing Bruce Wayne's inbox
        \item \textbf{EmailState:} Contains email content, spam flag, category, draft response, and message history
        \item \textbf{Five nodes:} read\_email → classify\_email → handle\_spam/drafting\_response → notify\_mr\_wayne
        \item Classify\_email uses LLM to analyze content and set spam status in state
        \item Conditional edge routes to spam handler or response drafter based on classification
        \item Handle\_spam terminates workflow early, drafting\_response continues to notification
        \item Demonstrates clear if/else logic through graph structure rather than buried code
        \item Successfully tested on legitimate and crypto spam emails with correct routing
      \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LangGraph}
\begin{columns}
    \begin{column}[T]{0.5\linewidth}
        \begin{center}
	
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents72}
	
        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents73}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    
    \end{column}
    \begin{column}[T]{0.5\linewidth}
        \begin{center}

        \includegraphics[width=0.8\linewidth,keepaspectratio]{aiagents74}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LangGraph}

        \begin{center}

        \includegraphics[width=\linewidth,keepaspectratio]{aiagents75}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}\frametitle{Concepts}

\begin{itemize}
\item Model: Large Language Model that supports Function Calling
\item Tools: Actions taken by app, ie API calls, Db operations, etc
\item State: Represents info that is carried though out the workflow e.g Message State has list of messages produced from each Node.
\item Node: executable logic container, a Langchain runnable or a Tool invoker. Nodes are connected by edges.
\item Edge: control flow of info, conditional or normal
\item Workflow: The graph, having nodes and edges, can be invoked or streamed from.
\end{itemize}

\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{langgraph2}
\end{center}	  

{\tiny (Ref: Introduction to LangGraph | Building an AI Generated Podcast - Prompt Circle AI)}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Graph and State Machine Concepts}
      \begin{itemize}
        \item State: System's behavioral condition (hunger, sleep, temperature)
        \item Events: Actions that trigger state changes (feeding, soothing)
        \item Nodes: Decision-makers and executors in the workflow
        \item Baby care analogy: Mother decides, elders check, father executes
        \item State updates trigger continuous decision-making cycles
        \item Graph structure provides flexible workflow representation
        \item State machines enable dynamic routing based on conditions
        \item More intuitive than linear processing chains
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LangGraph Core Features}
      \begin{itemize}
        \item Looping and branching capabilities with conditional statements
        \item State persistence with automatic save and restore functionality
        \item Human-machine interaction support with review and editing
        \item Streaming processing for real-time feedback and status updates
        \item Seamless integration with existing LangChain components
        \item Support for LCEL expressions and rich tool ecosystem
        \item Flexible interaction control mechanisms
        \item Enhanced user experience through responsive design
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Core Concept: State}

      \begin{itemize}
        \item State is the foundation of LangGraph applications
        \item Can be simple dictionary or Pydantic model
        \item Contains all information needed during runtime
        \item Passed between nodes and updated throughout execution
      \end{itemize}
	  
      \begin{lstlisting}[language=Python, basicstyle=\small]
from typing import List, Dict
from pydantic import BaseModel

class ChatState(BaseModel):
    messages: List[Dict[str, str]] = []
    current_input: str = ""
    tools_output: Dict[str, str] = {}
    final_response: str = ""
      \end{lstlisting}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Core Concept: Nodes}
Nodes are Python functions used to process state and return updated state:



      \begin{lstlisting}[language=Python, basicstyle=\small]
async def process_input(state: ChatState) -> ChatState:
    # Process user input
    messages = state.messages + [{"role": "user", "content": state.current_input}]
    return ChatState(
        messages=messages,
        current_input=state.current_input,
        tools_output=state.tools_output)

async def generate_response(state: ChatState) -> ChatState:
    # Generate response using LLM
    response = await llm.ainvoke(state.messages)
    messages = state.messages + [{"role": "assistant", "content": response}]
    return ChatState(
        messages=messages,
        current_input=state.current_input,
        tools_output=state.tools_output,
        final_response=response)
      \end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Core Concept: Edges}

      \begin{itemize}
        \item Edges define connections and routing logic between nodes
        \item Support conditional routing based on state
        \item Enable dynamic execution paths
      \end{itemize}
	  
      \begin{lstlisting}[language=Python, basicstyle=\small]
from langgraph.graph import StateGraph, END

# Create graph structure
workflow = StateGraph(ChatState)

# Add nodes
workflow.add_node("process_input", process_input)
workflow.add_node("generate_response", generate_response)

# Define edges and routing logic
workflow.add_edge("process_input", "generate_response")
workflow.add_edge("generate_response", END)
      \end{lstlisting}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Building the Chatbot Graph}

This example demonstrates the basic usage of LangGraph:
      \begin{itemize}
        \item Define state model
        \item Create processing nodes
        \item Build the graph structure
        \item Define routing logic
        \item Compile and run
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Simple Chatbot Implementation}
      \begin{lstlisting}[language=Python, basicstyle=\tiny]
from typing import List, Dict
from pydantic import BaseModel
from langgraph.graph import StateGraph, END
from langchain_core.language_models import ChatOpenAI

class ChatState(BaseModel):
    messages: List[Dict[str, str]] = []
    current_input: str = ""
    should_continue: bool = True

async def process_user_input(state: ChatState) -> ChatState:
    messages = state.messages + [{"role": "user", "content": state.current_input}]
    return ChatState(
        messages=messages,
        current_input=state.current_input,
        should_continue=True
    )

async def generate_ai_response(state: ChatState) -> ChatState:
    llm = ChatOpenAI(temperature=0.7)
    response = await llm.ainvoke(state.messages)
    messages = state.messages + [{"role": "assistant", "content": response}]
    return ChatState(
        messages=messages,
        current_input=state.current_input,
        should_continue=True
    )

def should_continue(state: ChatState) -> str:
    if "goodbye" in state.current_input.lower():
        return "end"
    return "continue"
      \end{lstlisting}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Building the Chatbot Graph}
      \begin{lstlisting}[language=Python, basicstyle=\tiny]
# Build the graph
workflow = StateGraph(ChatState)

# Add nodes
workflow.add_node("process_input", process_user_input)
workflow.add_node("generate_response", generate_ai_response)

# Add edges
workflow.add_edge("process_input", "generate_response")
workflow.add_conditional_edges("generate_response", should_continue, 
    {"continue": "process_input", "end": END})

# Compile the graph
app = workflow.compile()

# Run the conversation
async def chat():
    state = ChatState()
    while True:
        user_input = input("You: ")
        state.current_input = user_input
        state = await app.ainvoke(state)
        print("Bot:", state.messages[-1]["content"])
        if not state.should_continue:
            break

# Run chat
import asyncio
asyncio.run(chat())			
      \end{lstlisting}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Applications}
\end{center}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}\frametitle{Podcast Generator}

\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{langgraph3}
\end{center}	  


{\tiny (Ref: Introduction to LangGraph | Building an AI Generated Podcast - Prompt Circle AI)}

Code at https://github.com/hollaugo/langgraph-framework-tutorial
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{News Aggregator}

\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{langgraph4}
\end{center}	

Code: https://github.com/rajib76/multi\_agent/blob/main/01\_how\_to\_langgraph\_example\_01.py

{\tiny (Ref: Langgraph: The Agent Orchestrator - Rajib Deb)}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Agents using LangGraph}
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Creating a Vision Assistant Agent}
\begin{columns}
    \begin{column}[T]{0.7\linewidth}
      \begin{itemize}
        \item Vision-enabled agent implementing explicit "Thought → Action → Observation" loop
        \item \textbf{AgentState:} Stores input\_file (image path) and messages list for conversation history
        \item \textbf{Assistant node:} GPT-4 with vision capability bound to image analysis and math tools
        \item \textbf{Tools node:} Executes tool functions (extract\_text, divide) and records results
        \item Assistant decides to use tools or provide final answer based on task requirements
        \item Conditional edge uses tools\_condition to route between assistant and tools nodes
        \item Creates cycle: assistant thinks → tool execution → assistant processes results → repeat
        \item Loop continues until assistant provides final answer without requesting tools
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.3\linewidth}
        \begin{center}
        \includegraphics[width=\linewidth,keepaspectratio]{aiagents76}
        \end{center}    
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Creating a Vision Assistant Agent}

        \begin{center}

        \includegraphics[width=0.9\linewidth,keepaspectratio]{aiagents77}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Creating a Vision Assistant Agent}

        \begin{center}

        \includegraphics[width=\linewidth,keepaspectratio]{aiagents78}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    

\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Tracing Agent Workflows with Langfuse}

      \begin{itemize}
        \item Observability crucial for debugging complex agent behaviors with multiple steps
        \item \textbf{Traces:} Detailed execution records capturing prompts, responses, paths, and tool usage
        \item Langfuse provides user-friendly dashboard for inspecting agent workflow traces
        \item Integrates via OpenTelemetry standards with tracing callbacks in LangGraph code
        \item Enables monitoring of both email agent and vision agent execution flows
        \item Tools-assistant loop clearly visible in Langfuse trace visualization
        \item Answers "why did my agent do X?" through accessible trace inspection
        \item Essential best practice for moving from prototypes to production-grade AI systems
      \end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Tracing Agent Workflows with Langfuse}

        \begin{center}

        \includegraphics[width=\linewidth,keepaspectratio]{aiagents79}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Tracing Agent Workflows with Langfuse}

        \begin{center}

        \includegraphics[width=0.7\linewidth,keepaspectratio]{aiagents80}
		
		{\tiny (Ref: Vizuara AI Agents Bootcamp)}
				
        \end{center}    

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Best Practices}

      \begin{itemize}
        \item State Design: Keep the state model simple and clear, only including necessary information. Use type hints to increase code readability.
        \item Node Functions: Maintain single responsibility, handle exceptions, and return new state objects instead of modifying existing state.
        \item Edge Design: Use clear conditional logic, avoid complex cyclic dependencies, and consider all possible paths.
        \item Error Handling: Add error handling at critical nodes, provide fallback mechanisms, and log detailed error information.
      \end{itemize}
\end{frame}
