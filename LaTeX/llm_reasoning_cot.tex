%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Chain of Thought Reasoning}

{\tiny (Ref: Vizuara's Substack)}

\end{center}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Introduction to Reasoning LLMs}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item GPT-3.5 (Dec 2022) was designed to answer like humans, not think like humans
        \item Evolution from basic response models to reasoning-capable LLMs
        \item OpenAI's O1 model was first reasoning-based model
        \item Deep reasoning capabilities emerged in models like DeepSeek
        \item Timeline: 2022 onwards marks serious reasoning LLM development
        \item Most LLM providers now have reasoning models in their arsenal
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{reasoning_timeline}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Inference Time Compute Scaling}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item Humans give better answers when thinking longer (exams, puzzles, chess)
        \item Complex problems require layers of thought and time investment
        \item Examples: Sudoku, crossword puzzles, mathematical proofs
        \item Chess masters spend 10-20 minutes per move analyzing scenarios
        \item Same principle applies to LLMs: more thinking time = better answers
        \item Test time compute: computational resources used before final answer
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{inference_compute}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Test Time Compute Example}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item Problem: Roger has 5 tennis balls, buys 2 cans with 3 balls each
        \item Regular LLM: Direct answer "11" using 3 tokens
        \item Reasoning LLM: Step-by-step approach using 20 tokens
        \item Step 1: "Roger started with 5 balls" (4 tokens)
        \item Step 2: "Two cans of 3 balls each = 6 balls" (11 tokens)
        \item Step 3: "5 + 6 = 11" (5 tokens)
        \item 6-8x more computational resources but improved accuracy
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{compute_scaling}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Chain of Thought Reasoning (2022)}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item Google Brain team's breakthrough paper (12,000+ citations)
        \item Generating intermediate reasoning steps improves complex reasoning
        \item Arithmetic reasoning benefits from natural language rationales
        \item Simple prompting technique - no model weight changes required
        \item Few-shot prompting with reasoning examples teaches the model
        \item Emergent ability that scales with model size
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{chain_of_thought}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Chain of Thought vs Standard Prompting}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item Standard: Input → Direct Answer
        \item Chain of Thought: Input → Reasoning Steps → Answer
        \item Four linked thoughts forming a reasoning chain
        \item Model learns to apply similar reasoning to new problems
        \item Example: Tennis ball problem broken into logical steps
        \item Demonstrates clear improvement in accuracy and reasoning quality
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{cot_comparison}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Few-Shot Prompting Foundation}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item Few-shot prompting existed since 2020 (foundational paper)
        \item Provides multiple input-output examples in prompts
        \item Original approach: Direct question → Direct answer
        \item Chain of Thought innovation: Added reasoning steps between input-output
        \item 10-20 demonstration examples guide model behavior
        \item Model learns expected output format and reasoning approach
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{few_shot}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Three Types of Reasoning Tasks}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item Arithmetic: Mathematical calculations and number problems
        \item Common Sense: "Where might Sammy go to find people?" → Populated areas
        \item Symbolic: Coin flipping logic - heads/tails state tracking
        \item Each requires different Chain of Thought approaches
        \item All three show significant improvement with reasoning prompts
        \item Symbolic reasoning often most challenging for LLMs
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{reasoning_types}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Model Scale and Reasoning Performance}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item PaLM model evaluation on GSM-8K arithmetic dataset
        \item Accuracy increases dramatically with model parameter count
        \item Chain of Thought significantly outperforms standard prompting
        \item Large models (540B params) comparable to supervised fine-tuning
        \item Reasoning is an emergent ability of model scale
        \item Small models fail to understand reasoning nudges effectively
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{model_scale}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Zero-Shot Chain of Thought}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item Even simpler approach: "Let's think step by step"
        \item No input-output examples needed (zero-shot)
        \item Single prompt addition triggers reasoning behavior
        \item Two-step process: reasoning generation + answer extraction
        \item Significant performance improvement over plain zero-shot
        \item Works best with sufficiently large models (540B+ parameters)
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{zero_shot}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Practical Implementation Results}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item Tested models: FLAN-T5, TinyLlama, Zephyr (80M-7B parameters)
        \item GSM-8K dataset evaluation with 50 examples
        \item Small models show very low accuracy (0-5\%) - consistent with theory
        \item Models generate reasoning steps but often incorrect final answers
        \item Chain of Thought effective only for very large models
        \item Zero-shot reasoning outperforms few-shot on logical tasks
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{implementation}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Key Findings and Implications}
\begin{columns}
    \begin{column}[T]{0.6\linewidth}
      \begin{itemize}
        \item Reasoning abilities emerge only in sufficiently large models
        \item Test time compute scaling: more thinking = better accuracy
        \item Chain of Thought works across arithmetic, common sense, symbolic tasks
        \item Zero-shot reasoning surprisingly effective with simple prompts
        \item Model size is critical factor for reasoning capability
        \item Future: All major LLM providers developing reasoning models
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.4\linewidth}
        \begin{center}
        \includegraphics[width=0.8\linewidth,keepaspectratio]{implications}
        \end{center}	
    \end{column}
  \end{columns}
\end{frame}