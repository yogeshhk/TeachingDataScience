%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Conclusions}
\end{center}
\end{frame}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Conclusion}

\begin{itemize}
\item Geometric deep learning is a topical and rapidly evolving field
\item  While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. 
\item This topic is  exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications.
\item Such a 'geometric unification' endeavor, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: 
\begin{itemize}
\item  provides a common mathematical framework to study the most successful neural network architectures, such as CNN's, RNNs, GNNs, and Transformers
\item gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide a principled way to build future architectures yet to be invented
	\end{itemize}
	\end{itemize}

{\tiny (Ref: Geometric Deep Learning, LinkedIn post by Ashish Patel)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Contributions}

Geometric Deep Learning has 3 main contributions:

\begin{itemize}
\item Use of non-euclidean data
\item Maximize on the information from the data we collect
\item Use this data to teach machine learning algorithms
\end{itemize}
	  
{\tiny (Ref: What is Geometric Deep Learning? - Flawnson Tong)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{In Essence}


\begin{itemize}
\item The notion of relationships, connections, and shared properties is a concept that is naturally occurring in humans and nature. 
\item Understanding and learning from these connections is something we take for granted. 
\item Geometric Deep Learning is significant because it allows us to take advantage of data with inherent relationships, connections, and shared properties.
\end{itemize}
	  
{\tiny (Ref: What is Geometric Deep Learning? - Flawnson Tong)}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Key Takeaways}


\begin{itemize}
\item  The Euclidean domain and non-euclidean domain have different rules that are followed; data in each domain specializes in certain formats (image, text vs graphs, manifolds) and convey differing amounts of information
\item  Geometric Deep Learning is the class of Deep Learning that can operate on the non-euclidean domain with the goal of teaching models how to perform predictions and classifications on relational datatypes
\item  The difference between traditional Deep Learning and Geometric Deep Learning can be illustrated by imagining the accuracy between scanning an image of a person versus scanning the surface of the person themselves.
\item  In traditional Deep Learning, dimensionality is directly correlated with the number of features in the data whereas in Geometric Deep Learning, it refers to the type of the data itself, not the number of features it has.
\end{itemize}
	  
{\tiny (Ref: What is Geometric Deep Learning? - Flawnson Tong)}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Conclusion: The Geometric Unification}

% \begin{center}
% \textbf{Key Takeaways}
% \end{center}

\begin{enumerate}
\item \textbf{Unification}: Geometric Deep Learning provides a unified mathematical framework for understanding CNNs, RNNs, Transformers, and GNNs

\item \textbf{Principled Design}: The 5G framework (Grids, Groups, Graphs, Geodesics, Gauges) provides a constructive procedure for building neural architectures

\item \textbf{Efficiency}: Geometric priors dramatically reduce sample complexity by encoding symmetries and invariances

\item \textbf{Generalization}: Understanding geometric structure leads to better generalization across different domains and scales

\item \textbf{Future Path}: Geometric principles will guide the development of more general, efficient, and interpretable AI systems
\end{enumerate}

\vspace{0.5cm}

\begin{block}{The Geometric Deep Learning Promise}
\begin{center}
{\em "By understanding the geometric structure of data, we can build neural networks that are not just more efficient, but fundamentally more aligned with the underlying patterns of our physical world."}
\end{center}
\end{block}

\vspace{0.5cm}

\begin{center}
\textbf{From Felix Klein's 1872 vision to modern AI - geometry remains the key to understanding structure.}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Practical Implementation Guidelines}

% \begin{center}
% \textbf{How to Apply Geometric Deep Learning}
% \end{center}

\begin{itemize}
\item Step 1: Identify Data Geometry
	\begin{itemize}
	\item What symmetries does your data exhibit?
	\item What transformations should leave the output unchanged?
	\item What is the natural neighborhood structure?
	\end{itemize}
\item Step 2: Choose Geometric Domain
	\begin{itemize}
	\item \textbf{Grid}: Regular structure → CNN
	\item \textbf{Group}: Global symmetries → Group-equivariant networks
	\item \textbf{Graph}: Irregular connectivity → GNN
	\item \textbf{Geodesic}: Curved manifolds → Mesh networks
	\item \textbf{Gauge}: Vector fields → Gauge networks
	\end{itemize}
\item Step 3: Design Architecture
	\begin{itemize}
	\item Define local equivariant layers
	\item Add non-linear activations (preserve equivariance)
	\item Include coarsening/pooling for multi-scale
	\item End with global invariant layer
	\end{itemize}
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Tools and Libraries}

% \begin{center}
% \textbf{Implementing Geometric Deep Learning}
% \end{center}

\begin{columns}
\begin{column}{0.5\textwidth}
\textbf{Graph Neural Networks:}
\begin{itemize}
\item \textbf{PyTorch Geometric}: Comprehensive GNN library
\item \textbf{DGL}: Deep Graph Library
\item \textbf{Spektral}: Keras-based graph learning
\item \textbf{JAX-MD}: Molecular dynamics with JAX
\end{itemize}

\textbf{Manifold Learning:}
\begin{itemize}
\item \textbf{Geometric Deep Learning}: Official implementations
\item \textbf{DiffusionNet}: Learning on meshes
\item \textbf{PyMeshLab}: Mesh processing
\end{itemize}
\end{column}
\begin{column}{0.5\textwidth}
\textbf{Group Equivariant Networks:}
\begin{itemize}
\item \textbf{e3nn}: Euclidean neural networks
\item \textbf{escnn}: Equivariant steerable CNNs
\item \textbf{lie-nn}: Lie group neural networks
\item \textbf{SEGNN}: SE(3) equivariant networks
\end{itemize}

\textbf{Spherical Networks:}
\begin{itemize}
\item \textbf{SphericalCNN}: Spherical convolutions
\item \textbf{DeepSphere}: Graph-based spherical CNNs
\item \textbf{s2cnn}: Spherical CNN implementation
\end{itemize}
\end{column}
\end{columns}

\begin{alertblock}{Getting Started}
\begin{center}
PyTorch Geometric provides the most comprehensive and production-ready framework for geometric deep learning
\end{center}
\end{alertblock}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Airbus Job Role – PhD Position}
  \begin{itemize}
    \item \textbf{Topic:} Geometric Deep Learning (GDL) for aerodynamic model generation via geodesic convolutions. Geometric deep learning aims to precisely apply CNNs to non-Euclidean data described according to graph theory.
    \item \textbf{Objective:} Develop a data fusion methodology using DL techniques for aerodynamic analysis (CFD, wind tunnel, flight tests).
    \item \textbf{Goal:} Fuse wing pressure data (CFD, wind tunnel, flight tests) to produce high-dimensional, uncertainty-aware models.
    \item \textbf{Approach:} Design and adapt geodesic convolution techniques for non-Euclidean data.
    \item \textbf{DL Integration:} Apply recent DL advances for surrogate modeling and global data fusion.
    \item \textbf{Outcome:} Create a systematic methodology for selecting optimal fusion strategies across technical contexts.
    \item \textbf{Impact:} Support Airbus aircraft development from early design to flight test analysis.
    \item \textbf{Collaboration:} ISAE-Supaero Aerodynamics Department.
    \item \textbf{Company:} Airbus Operations SAS \quad \textbf{Type:} PhD Research \quad \textbf{Level:} Student	
    \item \textbf{Key Techniques:} GDL, surrogate modeling, uncertainty quantification.
    \item \textbf{Skills:} GNNs, CNNs, GANs, VAEs, Diffusion Models; PyTorch/TensorFlow; Aerodynamics; Python; research aptitude.
    \item \textbf{Collaboration:} ISAE-Supaero Aerodynamics Department.
    \item \textbf{Company:} Airbus Operations SAS \quad \textbf{Type:} PhD Research \quad \textbf{Level:} Student
  \end{itemize}
  
  {\tiny (Ref: CIFRE PhD position on Geometric Deep Learning - AirBus)}
\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Why Me?}

% \begin{itemize}
% \item Confluence of Graphs and Geometry into Deep Learning, my IKIGAI and Specific Knowledge.
% \item Demand, both academically \& professionally, as ML will be better on small but connected data.
% \item PyTorch Geometric is a beautiful, production-ready, research-heavy and good expertize-skill to have.
% \end{itemize}
	  
% \end{frame}
