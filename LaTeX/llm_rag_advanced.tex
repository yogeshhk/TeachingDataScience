%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large RAG Advanced Concepts}
\end{center}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Advanced RAG Approaches}

To  address  the  inefficiencies  of  the  Naive  RAG  approach,  Advanced  RAG
approaches implement strategies focused on three processes:
\begin{itemize}
\item Pre-Retrieval
\item Retrieval
\item Post Retrieval
\end{itemize}	

% More complex integration through various processing layers between retriever and generator modules.

% \begin{itemize}
% \item Hybrid Model: Jointly train retrieval and generation models for stronger synergy.
% \item Conditional Attention: Dynamically weigh retrieved documents based on their relevance to the current generation stage.
% \item Controllable Generation: Introduce mechanisms to steer generated content towards retrieved information.
% \end{itemize}	

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Advanced RAG Approaches}

\begin{center}
\includegraphics[width=0.55\linewidth,keepaspectratio]{rag2}

{\tiny (Ref: Progression of RAG Systems - Abhinav Kimothi )}
\end{center}	
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Advanced RAG Stages: Pre-retrieval}
\textbf{Chunk Optimization}

  \begin{itemize}
    \item Break external documents into appropriately sized chunks
    \item Decision factors: content type, user queries, and application needs
    \item No one-size-fits-all strategy; flexibility is crucial
    \item Current research explores techniques like sliding windows and "small2big" methods
  \end{itemize}
  
\textbf{Metadata Integration}

  \begin{itemize}
    \item Embed information like dates, purpose, chapter summaries, etc., into chunks
    \item Improves retriever efficiency by assessing similarity to metadata
  \end{itemize}
  

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Advanced RAG Stages: Pre-retrieval}
\textbf{Indexing Structure}
  \begin{itemize}
    \item Introduction of graph structures enhances retrieval
    \item Leverages nodes and their relationships
    \item Multi-index paths aimed at increasing efficiency
  \end{itemize}
  
\textbf{Alignment}
  \begin{itemize}
    \item Understanding complex data, like tables, can be tricky for RAG
    % \item Improve indexing with counterfactual training
    % \item Create hypothetical (what-if) questions to increase alignment
    \item Reduce disparity between documents
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Advanced RAG Stages: Retrieval}
\textbf{Query Rewriting}
  \begin{itemize}
    \item Use rewriting approaches for better alignment between user queries and documents
    \item LLMs create pseudo-documents from the query for improved matching
    \item LLMs perform abstract reasoning; multi-querying for solving complex user queries
  \end{itemize}
\textbf{Hybrid Search Exploration}
  \begin{itemize}
    \item RAG system employs different types of searches: keyword, semantic, and vector
    \item Search type depends on user query and available data
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Advanced RAG Stages: Retrieval}
\textbf{Sub Queries}
  \begin{itemize}
    \item Break down complex queries into sub-questions for each relevant data source
    \item Gather intermediate responses and synthesize a final response
  \end{itemize}
\textbf{Query Routing}
  \begin{itemize}
    \item Query router identifies downstream task and decides subsequent action for RAG system
    \item During retrieval, query router identifies most appropriate data source
  \end{itemize}
\textbf{Iterative Retrieval}
  \begin{itemize}
    \item Collect documents repeatedly based on query and generated response
    \item Create a more comprehensive knowledge base
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Advanced RAG Stages: Retrieval}
\textbf{Recursive Retrieval}
  \begin{itemize}
    \item Iteratively retrieves documents and refines search queries based on previous results
    \item Continuous learning process
  \end{itemize}
\textbf{Adaptive Retrieval}
  \begin{itemize}
    \item Enhance RAG framework by empowering LLMs to proactively identify suitable moments and content for retrieval
    % \item Improve efficiency and relevance of information obtained
    \item Dynamically choose when and what to retrieve for more precise and effective results
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Advanced RAG Stages: Retrieval}
\textbf{Hypothetical Document Embeddings (HyDE)}
  \begin{itemize}
    \item LLM-based HyDE forms a hypothetical document in response to a query
    \item Embeds it and retrieves real documents similar to this hypothetical one
    \item Emphasizes similarity between embeddings of different answers
  \end{itemize}
\textbf{Fine-tuned Embeddings}
  \begin{itemize}
    \item Tailor embedding models to improve retrieval accuracy
    \item Particularly useful in specialized domains dealing with uncommon or evolving terms
    \item Fine-tuning utilizes training data generated with language models grounded in document chunks
  \end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Advanced RAG Stages: Post-retrieval}
\textbf{Information Compression}
  \begin{itemize}
    \item Retriever proficient in extracting relevant information from extensive knowledge bases
    \item Challenge: Managing vast amount of information within retrieval documents
    \item Compress retrieved information to extract the most relevant points
    \item Information passed to LLM after compression
  \end{itemize}
\textbf{Reranking}
  \begin{itemize}
    \item Re-ranking model crucial for optimizing the document set retrieved by the retriever
    \item Rearrange document records to prioritize the most relevant ones at the top
    \item Manages the total number of documents effectively
    \item Resolves challenges related to context window expansion during retrieval
    \item Improves efficiency and responsiveness
  \end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Still, Challenges in Adv RAG}
  \begin{itemize}
    \item \textbf{Data Ingestion Complexity:} Handling extensive knowledge bases involves engineering challenges such as parallelizing requests, managing retries, and scaling infrastructure.
    \item \textbf{Efficient Embedding:} Embedding large datasets requires addressing rate limits, implementing robust retry logic, and managing self-hosted models for optimal efficiency.
    \item \textbf{Vector Database Considerations:} Storing data in a vector database introduces challenges like understanding compute resources, monitoring, sharding, and addressing potential bottlenecks.
    \item \textbf{Fine-Tuning and Generalization:} Fine-tuning RAG models for specific tasks while ensuring generalization across diverse knowledge-intensive NLP tasks requires a careful balance.
    % \item \textbf{Hybrid Parametric and Non-Parametric Memory:} Integrating both memory components in RAG poses challenges related to knowledge revision, interpretability, and avoiding hallucinations.
    \item \textbf{Knowledge Update Mechanisms:} Developing mechanisms to update non-parametric memory as real-world knowledge evolves is crucial for adapting to changing information.
  \end{itemize}
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Failure Points of RAG Systems}


		\begin{center}
		\includegraphics[width=\linewidth,keepaspectratio]{rag34}
		\end{center}

{\tiny (Ref: Mastering RAG: How To Architect An Enterprise RAG System - Pratik Bhavsar)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Failure Points}
\begin{itemize}
  \item \textbf{Missing Content (FP1):}
    \begin{itemize}
        \item Question without answer in available documents.
        \item Ideal response: "Sorry, I donâ€™t know."
        \item Risk of system being misled for questions without clear answers.
    \end{itemize}
  
  \item \textbf{Missed Top Ranked Documents (FP2):}
    \begin{itemize}
        \item Answer in document, but not ranked high enough.
        \item Only top K documents returned (K based on performance).
        \item Theoretical ranking vs. practical limitations.
    \end{itemize}
  
  \item \textbf{Not in Context - Consolidation Strategy Limitations (FP3):}
    \begin{itemize}
        \item Relevant answer retrieval hindered during consolidation.
        \item Occurs with a substantial number of returned documents.
        \item Challenge in incorporating retrieved documents into context.
    \end{itemize}
  
  \item \textbf{Not Extracted (FP4):}
    \begin{itemize}
        \item Answer present, but model fails to extract correct information.
        \item Occurs with excessive noise or conflicting information.
    \end{itemize}
  

\end{itemize}

{\tiny (Ref: Mastering RAG: How To Architect An Enterprise RAG System - Pratik Bhavsar)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Failure Points}
\begin{itemize}
  
  \item \textbf{Wrong Format (FP5):}
    \begin{itemize}
        \item Question involves specific format (table/list), but model disregards.
        \item Failure to follow instruction for information extraction.
    \end{itemize}
  
  \item \textbf{Incorrect Specificity (FP6):}
    \begin{itemize}
        \item Response lacks required specificity or is overly specific.
        \item Predetermined outcomes may lead to incorrect specificity.
        \item Unclear user questions may result in overly general responses.
    \end{itemize}
  
  \item \textbf{Incomplete (FP7):}
    \begin{itemize}
        \item Accurate answers lacking some information present in context.
        \item Example: Key points covered in multiple documents.
        \item Approach of asking separate questions for better results.
    \end{itemize}
\end{itemize}

{\tiny (Ref: Mastering RAG: How To Architect An Enterprise RAG System - Pratik Bhavsar)}

\end{frame}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{}
% \begin{center}
% {\Large Model Optimization}
% \end{center}
% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Deploying Large Language Models}
  % \begin{itemize}
    % \item Challenge: LLMs' size and computational demands in production.
    % \item Optimisation strategies crucial for cost-effective deployment.
  % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Model Compression}


		% \begin{center}
		% \includegraphics[width=0.6\linewidth,keepaspectratio]{rag16}
		% \end{center}

% {\tiny (Ref: Knowledge Brain RAG - Abhinav  Kimothi)}

% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Model Quantisation}
  % \begin{itemize}
    % \item Converts parameters and activations to lower precision data types.
    % \item Reduces memory and computation requirements.
    % \item Increases inference speed (2-4x) using int8 arithmetic.
    % \item Approaches: post-training, quantisation-aware training, hybrid quantisation.
    % \item Tradeoff analysis needed between reduced precision and model accuracy.
  % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Model Pruning}
  % \begin{itemize}
    % \item Removes redundant parameters to reduce size and complexity.
    % \item Weight pruning removes individual weights based on magnitude.
    % \item Neuron pruning removes entire neurons based on importance.
    % \item Requires fine-tuning for maintaining accuracy.
    % \item Approaches: post-training, iterative pruning.
  % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Model Distillation}
  % \begin{itemize}
    % \item Transfers knowledge from large "teacher" to smaller "student" model.
    % \item Student mimics teacher's outputs using labeled data and teacher probabilities.
    % \item Enhances efficiency while approximating teacher accuracy.
    % \item Includes knowledge distillation, self-distillation, ensemble distillation.
  % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Combined Optimisation Techniques}
  % \begin{itemize}
    % \item By combining quantisation, pruning, and distillation:
    % \item Unlock benefits of large language models.
    % \item Control deployment costs and energy consumption.
  % \end{itemize}
% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{}
% \begin{center}
% {\Large Multimodal Models}
% \end{center}
% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Multimodal AI Models}
    % \begin{itemize}
        % \item Most AI models historically limited to a single modality (text, images, or video).
        % \item Recent progress in handling multiple modalities, especially text and images.
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Features of Multimodal RAG}
    % \begin{itemize}
        % \item Ability to query/prompt in one or more modalities (e.g., text and images).
        % \item Search and retrieve not only text but also images, tables, audio files related to the query.
        % \item Ability to generate text, image, video, etc., irrespective of the input mode(s).
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Emergent Approaches in Multimodal RAG}
    % \begin{itemize}
        % \item Using multimodal embeddings like CLIP.
        % \item Using LMMs to generate image captions and using text embeddings.
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Multimodal Embeddings in RAG Workflow}
    % \begin{itemize}
        % \item \textbf{Multimodal Embeddings (e.g., CLIP):} Used for embedding both images and text.
        % \item \textbf{Query/Prompt:} User input initiates the process.
        % \item \textbf{Retrieved Context:} User query retrieves context (images and/or text).
        % \item \textbf{LMM (Language Model):} Context, along with the prompt, passed to the Language Model.
        % \item \textbf{Multimodal Response:} The Language Model generates the final response.
        % \item \textbf{Indexing and RAG Pipelines:} Sequential steps involving embedding, retrieval, and response generation.
    % \end{itemize}
% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Multimodal RAG using Multimodal Embeddings}


		% \begin{center}
		% \includegraphics[width=0.6\linewidth,keepaspectratio]{rag12}
		% \end{center}

% {\tiny (Ref: Multimodal RAG - Abhinav  Kimothi)}

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{CLIP : Contrastive Language-Image Pre-training}


		% \begin{center}
		% \includegraphics[width=0.6\linewidth,keepaspectratio]{rag13}
		% \end{center}

% {\tiny (Ref: Multimodal RAG - Abhinav  Kimothi)}

% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{MM-RAG Paper and Implementations}
    % \begin{itemize}
        % \item MM-RAG paper published in June 2023 provides insights into building a retriever for multimodal RAG.
        % \item LangChain cookbook offers a simple implementation of multimodal RAG using a multiquery retriever and OpenAI GPT4V.
        % \item LlamaIndex tutorial explains multimodal RAG implementation in detail.
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Using LMMs for Text Summaries from Images}
    % \begin{itemize}
        % \item \textbf{Indexing:}
            % \begin{itemize}
                % \item LLM generates captions for images in the data.
                % \item Captions and text summaries stored as text embeddings in a vector database.
                % \item Maintains a mapping from image captions to image files.
            % \end{itemize}
        % \item \textbf{Generation:}
            % \begin{itemize}
                % \item User query with text and image.
                % \item LLM generates image captions and embeddings.
                % \item Search for text summaries and image captions; retrieve images based on relevant captions.
                % \item Retrieved content passed to LMM with a prompt.
                % \item LMM generates a multimodal response.
            % \end{itemize}
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Using LMMs for Text Summaries from Images}


		% \begin{center}
		% \includegraphics[width=0.6\linewidth,keepaspectratio]{rag14}
		% \end{center}

% {\tiny (Ref: Multimodal RAG - Abhinav  Kimothi)}

% \end{frame}
