%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Introduction to Generative AI}
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Introduction}
\begin{itemize}
\item Generative AI rapidly generates new data using machine learning algorithms.
% \item Google is one of the leading companies in generative AI, offering tools and frameworks.
\item But What is Generative AI?
\item How is it related to AI-ML-DL?
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Traditional vs. Machine Learning?}
\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{tradml}
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Why Machine Learning?}
\begin{itemize}
\item Problems with High Dimensionality
\item Hard/Expensive to program manually
\item Job \$\$\$
\end{itemize}
%\begin{center}
%\includegraphics[width=0.45\linewidth,keepaspectratio]{hp}
%\end{center}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{ML vs DL: What's the difference?}
Deep learning algorithms attempt to learn (multiple levels of) representation by using a hierarchy of multiple layers
\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{dlfeat1}
\end{center}
\tiny{(Reference: https://www.xenonstack.com/blog/static/public/uploads/media/machine-learning-vs-deep-learning.png)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile] \frametitle{Use Deep Learning When \ldots}

\begin{itemize}
\item You have lots of data (about 10k+ examples)
\item The problem is ``complex'' - speech, vision, natural language
\item The data is unstructured 
\item Techniques to model `ANY' function given `ENOUGH' data.
% \item You need the absolute ``best'' model
\end{itemize}
\tiny{(Ref: Introduction to TensorFlow 2.0 - Brad Miro)}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Relationship between AI, ML, DL}

First, lets see whats AI-ML-DL and relationship among them.

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{ai1}
\end{center}

{\tiny (Ref: https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{What is Gen AI wrt AI, ML, DL}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai11}
\end{center}

{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{What is Deep NLP}
\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{nlp4}

\tiny{(Ref: Deep Learning and NLP A-Z - Kirill Eremenko)}

\tiny{(Note: Size is not indicative of importance)}
\end{center}

Seq2Seq is heavily used technique of DNLP for sequence to sequence modeling, eg Translation, Q \& A, etc. Thats the basis of Large Language Models (LLMs)

	% \begin{itemize}
	% \item Green part is NLP (rule based, linguistic)
	% \item Blue part is Deep Learning not applied to NLP
	% \item Purple is Deep NLP (DNLP), NN applied for NLP use cases
	% \item Seq2Seq is heavily used technique of DNLP for sequence to sequence modeling, eg Translation, Q \& A, etc.
	% \end{itemize}
	

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Types of Approaches}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai12}
\end{center}

{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Types of Approaches}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai13}
\end{center}


{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{What is Foundation Model?}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai14}
\end{center}


{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Same Problem, using different Technologies}
\end{center}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Difference across technologies, old to new}
Lets see how the solutions to the problem of detecting a cat from images using traditional programming, deep learning, and generative AI, respectively.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Traditional Programming}
  \begin{itemize}
    \item Traditional programming involves writing explicit rules to detect a cat in images.
    \item Features like color, texture, and shape can be used to define these rules.
    \item However, designing accurate rules for complex patterns like cat detection can be challenging.
    \item It requires extensive domain knowledge and might not generalize well to different images.
  \end{itemize}
  
\begin{center}
\includegraphics[width=0.3\linewidth,keepaspectratio]{genai1}
\end{center}

{\tiny (Ref: Primer on LLM and Gen AI - Google Cloud)}
  
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Deep Learning}
  \begin{itemize}
    \item Deep learning utilizes neural networks to automatically learn features for cat detection.
    \item Convolutional Neural Networks (CNNs) are particularly effective for image classification tasks.
    \item Large labeled datasets of cat images are used to train the network.
    \item The network learns to identify unique cat features and generalize them to detect cats in new images.
    \item Deep learning offers better accuracy and can handle complex patterns without explicit rule definition.
  \end{itemize}
  
\begin{center}
\includegraphics[width=0.4\linewidth,keepaspectratio]{genai2}
\end{center}

{\tiny (Ref: Primer on LLM and Gen AI - Google Cloud)}  
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Generative AI}
  \begin{itemize}
    \item Generative AI focuses on generating new data, including images of cats.
    \item Generative Adversarial Networks (GANs) are used to generate realistic cat images.
    \item The GAN consists of a generator and a discriminator that compete against each other.
    \item The generator learns to generate increasingly realistic cat images, while the discriminator learns to distinguish real from generated images.
    \item The generated cat images can be used to augment datasets for cat detection models.
  \end{itemize}
  
\begin{center}
\includegraphics[width=0.5\linewidth,keepaspectratio]{genai3}
\end{center}

{\tiny (Ref: Primer on LLM and Gen AI - Google Cloud)}
  
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Modalities in Generative AI}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai15}
\end{center}


{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

Let's foucs on the most popular modality \ldots

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{What is a Language Models?}

\begin{itemize}
\item While typing SMS, have you seen it suggests next word?
\item While typing email, have you seen next few words are suggested?
\item How does it suggest? (suggestions are not random, right?)
\item In the past, for ``Lets go for a \ldots', if you have typed 'coffee' 15 times, 'movie' say 4 times, then it learns that. Machine/Statistical Learning.
\item Next time, when you type ``Lets go for a '', what will be suggested? why?
\item This is called Language Model. Predicting the next word. When done continuously, one after other, it spits sentence, called Generative Model.
\end{itemize}	

\begin{center}
\includegraphics[width=0.6\linewidth,keepaspectratio]{chatgpt34}
\end{center}		

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Why they are called Large? Corpus}

GPT: Generative Pre-trained Transformers

\begin{itemize}
% \item GPT-1 is trained in a self-supervised manner (learn to predict the next word in text data) and fine-tuned in a supervised learning manner. 
% \item GPT-2 is trained in a fully self supervised way, focusing on zero-shot transfer
% \item  GPT-3 is pre-trained in a self supervised manner exploring a bit more the few-shots fine-tuning.
\item GPT-1 is pre-trained on the BooksCorpus dataset, containing ~7000 books amounting to ~5GB of data
\item GPT-2 is pre-trained using the WebText dataset which is a more diverse set of internet data containing ~8M documents for about ~40 GB of data
\item GPT-3 uses an expanded version of the WebText dataset, two internet-based books corpora that are not disclosed and the English-language Wikipedia which constituted ~600 GB of data
\end{itemize}	 

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Why they are called Large? Parameters}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{chatgpt31}
\end{center}				
{\tiny (Ref: Deus.ai https://www.deus.ai/post/gpt-3-what-is-all-the-excitement-about)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Underlying Architecture: Transformers}


\begin{itemize}
\item In its heart it contains an encoding component, a decoding component, and connections between them.
\item The Transformer  is a model that uses attention to boost the speed with which seq2seq with attention models can be trained. 
\item The biggest benefit, however, comes from how The Transformer lends itself to parallelization. How?
\end{itemize}	 

\begin{center}
\includegraphics[width=0.6\linewidth,keepaspectratio]{bert51}
\end{center}	

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Transformer Models}

\begin{columns}
    \begin{column}[T]{0.7\linewidth}
		\begin{center}
		\includegraphics[width=\linewidth,keepaspectratio]{promptengg81}

		{\tiny (Ref: The Complete Prompt Engineering for AI Bootcamp (2023))}
		\end{center}	
    \end{column}
    \begin{column}[T]{0.3\linewidth}
		\begin{itemize}
		\item  No recurrence, so parallelization possible
		\item  Context information captured via attention and positional encodings
		\item Consists of stacks of layers with various sublayers
		\end{itemize}
    \end{column}
  \end{columns}
  
Transformers are basis of (the most) Large Language Models


\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{The Progress of Models \ldots}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai6}
\end{center}

{\tiny (Ref: Primer on LLM and Gen AI - Google Cloud)}
  
\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Why are large language models different? }
% \begin{columns}
    % \begin{column}[T]{0.5\linewidth}
% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{genai7}
% \end{center}
    % \end{column}
    % \begin{column}[T]{0.5\linewidth}  
	
% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{genai8}
% \end{center}

    % \end{column}
  % \end{columns}
  
  
% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{What are large language models?}
% \begin{columns}
    % \begin{column}[T]{0.6\linewidth}
  % \begin{itemize}
    % \item ML algorithms that can recognize, predict, and generate human languages
    % \item Pre-trained on petabyte scale text-based datasets resulting in large models with 10s to 100s of billions of parameters 
    % \item LLMs are normally pre-trained on a large corpus of text followed by fi ne-tuning on a specifi c task
    % \item LLMs can also be called Large Models (includes all types of data modality) and Generative AI (a model that produces content)
  % \end{itemize}
    % \end{column}
    % \begin{column}[T]{0.4\linewidth}  
% \begin{center}
% \includegraphics[width=0.8\linewidth,keepaspectratio]{genai4}
% \end{center}
% {\tiny (Ref: Primer on LLM and Gen AI - Google Cloud)}

    % \end{column}
  % \end{columns}
  
  
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]{Why are large language models different? }
% \begin{columns}
    % \begin{column}[T]{0.6\linewidth}
  % \begin{itemize}
    % \item LLMs are characterized by emergent abilities, or the ability to perform tasks that were not included in their training examples.
    % \item LLMs contextual understanding of human language changes how we interact with data and intelligent systems.
	% \item LLMs can find patterns and connections in massive, disparate data corpora.
  % \end{itemize}
    % \end{column}
    % \begin{column}[T]{0.4\linewidth}  
% \begin{center}
% \includegraphics[width=0.5\linewidth,keepaspectratio]{genai5}
% \end{center}
% {\tiny (Ref: Primer on LLM and Gen AI - Google Cloud)}

    % \end{column}
  % \end{columns}
  
  
% \end{frame}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Prompts driving Generative AI}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai16}
\end{center}


{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Model Types}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai17}
\end{center}


{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Model Types}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai18}
\end{center}


{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Model Types}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai19}
\end{center}


{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Model Types}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai20}
\end{center}


{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Model Types}
Foundation Model:

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{genai21}
\end{center}


{\tiny (Ref: Introduction to Generative AI - Google Cloud Tech)}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LLM Real World Use Cases}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{llm121}
\end{center}				

{\tiny (Ref: Applied LLMs Mastery 2024 - Aishwarya Reganti)}

\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{LLM Real World Use Cases}

% \begin{center}
% \includegraphics[width=\linewidth,keepaspectratio]{llm122}
% \end{center}				

% {\tiny (Ref: Applied LLMs Mastery 2024 - Aishwarya Reganti)}

% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{LLM Challenges}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{llm123}
\end{center}				

{\tiny (Ref: Applied LLMs Mastery 2024 - Aishwarya Reganti)}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large What's IN these days \ldots}
\end{center}

\end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{}
% \begin{center}
% {\Large Progress of Generative AI}
% \end{center}

% {\tiny (Ref: 2023 Kaggle AI Report on Generative AI, by Trushant Kalyanpur)}

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Background: Advancements in Generative AI}
    
    % \begin{itemize}
        % \item Significance of Generative Pre-trained Transformer (GPT)
        % \item GPT: Family of large-scale language models by OpenAI
        % \item GPT architecture based on Transformer
        % \item Transformer: Classic encoder-decoder architecture
        % \item Encoder processes input, decoder generates output
    % \end{itemize}
% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Background: GPT Architecture}

% \begin{itemize}
        % \item GPT based on Transformer
        % \item GPT uses stack of decoders
        % \item Inspired by "Generating Wikipedia by Summarizing Long Sequences"
        % \item Alternate arrangement of transformer block
        % \item Model uses only stack of decoders
        % \item GPT models are autoregressive
        % \item Predicts next value based on previous values
        % \item Sequence prediction mechanism
        % \item Model predicts next value in a sequence
        % \item Utilizes information from prior values		
% \end{itemize}	

% \begin{center}
% \includegraphics[width=0.6\linewidth,keepaspectratio]{llm85}
% \end{center}		

% {\tiny (Ref: Jay Alammar)}

% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{2021: Dall-E}

 Zero-Shot Text-to-Image Generation
 
\begin{itemize}
        \item OpenAI's 2021 release: DALL-E
        \item Text-to-image generation model
        \item Implementation of GPT-3
        \item Generates images from text descriptions
        \item Utilizes text-image dataset	
\end{itemize}	

\begin{center}
\includegraphics[width=0.6\linewidth,keepaspectratio]{llm86}
\end{center}		

{\tiny (Ref: Example prompt "An astronaut riding a horse in photorealistic style" using DALL-E: Open AI)}

\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Contrastive Language-Image Pretraining (CLIP)}
    
    % \begin{itemize}
        % \item Revealed alongside DALL-E
        % \item Trains model to understand text and images
        % \item Learns coherent relationships between them
        % \item Uses large-scale dataset (400 million pairs)
        % \item Visual representations for downstream tasks
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Integration of CLIP with DALL-E}
    
    % \begin{itemize}
        % \item CLIP evaluates DALL-E's output
        % \item Analyzes suitable captions for generated images
        % \item DALL-E's method: Inverted CLIP (unCLIP)
        % \item Generates images from text
        % \item Contrast to CLIP's image-to-text approach
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Implications and Creativity}
    
    % \begin{itemize}
        % \item Concerns about creativity impact
        % \item Worries for artists, designers, illustrators
        % \item DALL-E generates intricate images
        % \item Sparks creativity and new ideas
        % \item Benefits storytelling, concept art, expression
    % \end{itemize}
% \end{frame}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{2022: Pathways Language Model (PaLM)}
    
    % \begin{itemize}
        % \item Developed by Google AI
        % \item Large language model (LLM)
        % \item 540B parameters (3x GPT-3's size)
        % \item Aims for efficiency and scalability
        % \item Achieves state-of-the-art performance
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Pathways Architecture}
    
    % \begin{itemize}
        % \item Utilizes hierarchical Pathways
        % \item Learns various abstraction levels
        % \item Efficient and scalable design
        % \item Scales training to thousands of TPU chips
        % \item Combines data parallelism and model parallelism
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Data and Training}
    
    % \begin{itemize}
        % \item Trained on 780 billion tokens
        % \item Includes webpages, books, Wikipedia, news, code
        % \item Filters diverse sources of data
        % \item Enables broader language understanding
        % \item Expands model's contextual knowledge
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Performance and Achievements}
    
    % \begin{itemize}
        % \item Outperforms previous models
        % \item Improvements across various tasks
        % \item Enhanced text generation: factual and creative
        % \item Improved question answering accuracy
        % \item Fluent machine translation between languages
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{DALL-E 2: Successor to DALL-E}
    
    % \begin{itemize}
        % \item OpenAI released DALL-E 2 in April 2022
        % \item Builds upon DALL-E's foundation
        % \item Uses CLIP embeddings directly
        % \item Decodes images with a diffusion model
        % \item Shift from decoder-only transformer
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Diffusion Model in DALL-E 2}
    
    % \begin{itemize}
        % \item Diffusion model for image generation
        % \item Gradually adds noise to match text
        % \item Avoids one-pixel-at-a-time limitation
        % \item Produces more realistic images
        % \item Improves image quality and coherence
    % \end{itemize}
	
% \begin{center}
% \includegraphics[width=0.6\linewidth,keepaspectratio]{llm87}
% \end{center}		

% {\tiny (Ref: Same prompt: "a painting of a fox sitting in a field at sunrise in the style of Claude Monet": Open AI)}
	
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{CLIP Training and Generation}
    
    % \begin{itemize}
        % \item Joint representation space for text and images
        % \item Text-to-image process with CLIP text embedding
        % \item Autoregressive or diffusion prior
        % \item Image embedding for diffusion decoder
        % \item Diffusion decoder generates final image
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Improved Realism in DALL-E 2}
    
    % \begin{itemize}
        % \item Enhanced image generation quality
        % \item CLIP embeddings, diffusion prior, decoder
        % \item Realistic and accurate images
        % \item Advances over DALL-E's capabilities
        % \item Notable improvement in image fidelity
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Image Quality Comparison}
    
    % \begin{itemize}
        % \item Example: "painting of a fox at sunrise"
        % \item DALL-E 2 vs DALL-E
        % \item Image quality and style differences
        % \item Enhanced fidelity and style representation
        % \item Demonstrates DALL-E 2's advancements
    % \end{itemize}
% \end{frame}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Open Beta Access}
    
    % \begin{itemize}
        % \item Released in open beta via Discord
        % \item Anyone could sign up and use
        % \item High accessibility for image generation
        % \item Among the most accessible LLMs
        % \item Democratizing image creation process
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Evolution of Midjourney Images}
    
    % \begin{itemize}
        % \item Image quality improvement over time
        % \item Different versions of Midjourney
        % \item Same prompt for image generation
        % \item Version range from 1 to 5
        % \item Released between 2022 and March 2023
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Progressive Image Enhancement}
    
    % \begin{itemize}
        % \item Comparison across Midjourney versions
        % \item Images generated with same prompt
        % \item Version 5 (March 2023) > Version 1 (2022)
        % \item Newer versions: more detailed, realistic, creative
        % \item Evident improvements in image quality
    % \end{itemize}
	
% \begin{center}
% \includegraphics[width=0.4\linewidth,keepaspectratio]{llm88}
% \end{center}		

% {\tiny (Ref: Prompt: Teenager, female, seventeen years old, pop culture, modern clothing. Photorealistic, Natural lighting, Pastel. Image credit John Severinson)}
		
% \end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Stable Diffusion: Latent Image Generation}
    
    % \begin{itemize}
        % \item Released in August 2022
        % \item Latent diffusion model
        % \item Generates images from text descriptions
        % \item Notable contribution to open source LLMs
        % \item Developed by CompVis Group, Ludwig Maximilian University
    % \end{itemize}

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Stable Diffusion: Latent Image Generation}
    
    % \begin{itemize}
        % \item ClipText for text encoding - This takes in a text and outputs the text embedding vectors.
        % \item Diffusion: UNet + Scheduler to gradually process/diffuse information in the information (latent) space - This block takes in the text embeddings and an initial tensor made up of noise. It outputs a processed information array.
        % \item Autoencoder Decoder - This decoder paints the final image using the processed information array.
    % \end{itemize}
	
% \begin{center}
% \includegraphics[width=0.6\linewidth,keepaspectratio]{llm89}
% \end{center}		

% {\tiny (Ref: Jay Alammar)}
		
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Open Source Impact}
    
    % \begin{itemize}
        % \item Code and model weights released publicly
        % \item One of the earliest open source LLMs for image generation
        % \item Focus on generating images from text
        % \item Enhances accessibility and collaboration
        % \item Advancement in sharing research and tools
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Latent Diffusion Model}
    
    % \begin{itemize}
        % \item Uses latent space for image representation
        % \item Generates images from noisy inputs
        % \item Gradually reduces noise for realism
        % \item More diverse and creative image generation
        % \item Contrasts with traditional diffusion models
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Collaborative Development}
    
    % \begin{itemize}
        % \item Collaboration between institutions
        % \item Developed by CompVis Group and Runway
        % \item Compute donation by Stability AI
        % \item Training data from non-profit organizations
        % \item Cross-disciplinary efforts for innovation
    % \end{itemize}
% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{ChatGPT - A Tipping Point for Generative AI}
    \begin{itemize}
        \item Released by OpenAI in November 2022
        \item Generative AI chatbot
        \item Rapid worldwide popularity
        \item 1 million users in 5 days
        \item Netflix took 3.5 years for same user count
        \item 100 million monthly active users by January 2023
        \item Fastest-growing application in history
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{THE CHATGPT}
Versatile Capabilities of ChatGPT

    \begin{itemize}
        \item Generates human-like chat conversations
        \item Tasks: questions, creative content, explanations
        \item Suggestions, poems, code generation, and more
    \end{itemize}
	
Pivotal Moment in AI

    \begin{itemize}
        \item Demonstrated advanced language model sophistication
        \item Prompted activity in AI community
        \item Rush to develop similar language models
        \item Expectation of even more impressive models
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{What's Inside?}
Technical Details
    \begin{itemize}
        \item Based on GPT3 architecture
        \item Estimated 175 billion parameters
        \item Fine-tuned on chat-specific task
        \item Curated dataset for fine-tuning
        \item Human AI trainers provide feedback
        \item Model adjusts responses based on feedback
    \end{itemize}
	
Specialization Through Fine-tuning

    \begin{itemize}
        \item Specializes in domains or tasks
        \item Incorporates human preferences and guidelines
        \item Examples: conversational data, customer support
        \item More suitable for interactive applications
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Improving ChatGPT with RLHF}
    \begin{itemize}
        \item Key technique: Reinforcement Learning from Human Feedback (RLHF)
        \item Trains language model to align with human preferences
        \item Collects human feedback on model-generated text
        \item Updates model's parameters using feedback
        \item Enhances ChatGPT responses' quality
        \item Increases factual, informative, and creative output
    \end{itemize}
\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{ChatGPT's Impact on Generative AI}
    % \begin{itemize}
        % \item Represents a tipping point for generative AI
        % \item Demonstrates capability of Language Models (LLMs)
        % \item LLMs generate human-quality chat conversations
        % \item Expands LLM applications across various domains
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Raising Awareness and Potential}
    % \begin{itemize}
        % \item ChatGPT's popularity contributes to raising awareness
        % \item Highlights potential benefits of generative AI
        % \item Opens doors to innovative applications
    % \end{itemize}
% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Midjourney: Image Generation Model}
    
    \begin{itemize}
        \item Developed by Midjourney Inc.
        \item Released in July 2022
        \item Architecture details undisclosed
        \item High-quality image generation
        \item Wide variety of styles and genres
    \end{itemize}
	
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Meta Releases LLaMA}

Open Source LLMs Explode!
 
    \begin{itemize}
        \item February 2023: Meta releases LLM "LLaMA"
        \item LLaMA: 65-billion parameter model
        \item Trained on extensive text and code dataset
    \end{itemize}
	
Significance of LLaMA Release

    \begin{itemize}
        \item One of the largest public LLMs
        \item Suited for complex and challenging tasks
        \item Open source, initially for research purposes
        \item Model weights leaked online, accessible to all
        \item Sparked development of numerous open source LLMs
    \end{itemize}
\end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Meta LLaMA}

% \begin{itemize}
% \item  Open-Source. Need to build a UX and any advanced functionality around it, and may need to fine-tune it.
% \item Many use-cases in the enterprise can’t use OpenAI for fear of sensitive data leaking or being used to train the model (though OpenAI claims to keep API data private).
% \item If you have 200+ examples fine-tuning beats prompt engineering for a specific defined task.
% \end{itemize}	 

% {\tiny (Ref: The Complete Prompt Engineering for AI Bootcamp (2023))}

% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Anthropic Claude}


\begin{columns}
    \begin{column}[T]{0.6\linewidth}
		\begin{center}
		\includegraphics[width=\linewidth,keepaspectratio]{promptengg90}

		{\tiny (Ref: The Complete Prompt Engineering for AI Bootcamp (2023))}
		\end{center}	
    \end{column}
    \begin{column}[T]{0.4\linewidth}
		Created by Anthropic 
		https://console.anthropic.com/ or API
		Uses Constitutional AI rather than RLHF
		
		Constitutional AI trains to follow a set of high-level principles or rules, such as a constitution, that specify the desired behavior and outcomes of the system.
		RLHF uses human feedback, such as ratings, preferences, or corrections, to optimize a language model or an agent’s policy using reinforcement learning
    \end{column}
  \end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Github Copilot: Breakthrough Coding Assistant}
    
    \begin{itemize}
        \item OpenAI introduced Github Copilot in 2021
        \item Built on GPT-3 architecture
        \item Fine-tuned on millions of public code lines
        \item Auto-completes and suggests code
        \item Supports multiple programming languages
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Is everything POSTIVE?}
    
Concerns and Considerations	
    \begin{itemize}
        \item Raised intellectual property rights issues
        \item Trained on publicly available GitHub code
        \item Potential licensing conflicts
        \item Risk of suggesting code with vulnerabilities
        \item Biases and security flaws in training data
    \end{itemize}

Impact on Developer Community
    
    \begin{itemize}
        \item Enhanced productivity among developers
        \item Focus on higher-level tasks and problem-solving
        \item Reduced time spent on repetitive code
        \item Empowers creativity and innovation
        \item New perspectives in software development
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Google is not behind}
Google Releases Bard
    \begin{itemize}
        \item March 2023: Google introduces Bard chatbot
        \item Built on LLM framework
        \item Fine-tuned model based on PaLM 2
        \item PaLM 2: Around 340 billion parameters
        \item Bard trained on dataset 10 times larger than ChatGPT
    \end{itemize}
Bard's Unique Features
    \begin{itemize}
        \item Access to the internet
        \item Continuous learning and knowledge update
        \item More up-to-date and accurate than ChatGPT
        \item ChatGPT limited to training dataset info
        \item Bard surpasses ChatGPT's knowledge scope
    \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Bard | Palm 2/Gemini}


\begin{columns}
    \begin{column}[T]{0.6\linewidth}
		\begin{center}
		\includegraphics[width=\linewidth,keepaspectratio]{promptengg85}

		{\tiny (Ref: The Complete Prompt Engineering for AI Bootcamp (2023))}
		\end{center}	
    \end{column}
    \begin{column}[T]{0.4\linewidth}
		Created by Google
		Access it via chat https://bard.google.com/ or encounter it in search results
    \end{column}
  \end{columns}
\end{frame}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{QLoRA: Quantized LLMs with Low-Rank Adapters}
    % \begin{itemize}
        % \item May 2023: Dettmers et al. released QLoRA
        % \item Built on 2021's LoRA by Hu et al.
        % \item LoRA: Reduces LLM memory footprint with adapters
        % \item Frozen original LLM parameters
        % \item Adapter weights updated during fine-tuning
    % \end{itemize}
	
% \begin{center}
% \includegraphics[width=0.6\linewidth,keepaspectratio]{llm90}
% \end{center}		

% {\tiny (Ref: QLoRA paper)}
			
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{QLoRA's Innovations}
    % \begin{itemize}
        % \item Extension of LoRA technique
        % \item Introduces 4-bit quantization
        % \item Double quantization and paged optimizers
        % \item Utilizes Nvidia's unified memory for paging
        % \item Drastic memory reduction in 65B model finetuning
    % \end{itemize}
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Benefits and Impact}
    % \begin{itemize}
        % \item Enables finetuning on limited resources
        % \item 65B model on a single 48GB GPU
        % \item Maintains full 16-bit finetuning performance
        % \item Essential for pretrained LLMs' ChatGPT-like capabilities
        % \item Expands accessibility to state-of-the-art NLP technology
    % \end{itemize}
% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{The BEST so far}
OpenAI Releases GPT4
    \begin{itemize}
        \item May 2023: OpenAI releases GPT4
        \item Multimodal: accepts image and text inputs
        \item Generates text outputs
        \item 6 months spent on safety and alignment
        \item GPT-4 82\% less likely for disallowed content
        \item 40\% more likely for factual responses than GPT-3.5
    \end{itemize}

GPT4's Performance
    \begin{itemize}
        \item Human-level performance on benchmarks
        \item Passed simulated bar exam in top 10\%
        \item Impressive results on various professional exams
    \end{itemize}
\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{GPT4's Architecture}
    % \begin{itemize}
        % \item Rumored architecture: eight models with 220B parameters
        % \item Linked in Mixture of Experts (MoE) structure
        % \item Total model: 1.76T parameters
        % \item MoE combines different "experts" for decision making
        % \item Enabling complex and diverse capabilities
    % \end{itemize}
% \end{frame}