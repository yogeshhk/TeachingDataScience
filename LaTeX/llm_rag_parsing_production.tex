%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Production Considerations}

\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Modern Parsing Challenges (2024-2025)}
\begin{columns}
    \begin{column}[T]{0.5\linewidth}
      \begin{itemize}
        \item \textbf{Cloud-Native Documents:}
        \begin{itemize}
            \item Google Docs, Notion, Confluence formats
            \item Dynamic content and embedded widgets
            \item Real-time collaborative editing artifacts
            \item Version control and change tracking
        \end{itemize}
        \item \textbf{API-Based Extraction:}
        \begin{itemize}
            \item OAuth authentication requirements
            \item Rate limiting and pagination handling
            \item Incremental sync challenges
        \end{itemize}
      \end{itemize}
    \end{column}
    \begin{column}[T]{0.5\linewidth}
      \begin{itemize}
        \item \textbf{Real-Time Streaming:}
        \begin{itemize}
            \item Processing documents as they're created
            \item Handling partial/incomplete content
            \item Low-latency requirements for live systems
        \end{itemize}
        \item \textbf{Format Complexity:}
        \begin{itemize}
            \item Rich media embeds (videos, interactive charts)
            \item Cross-document references and links
            \item Complex nested structures
            \item Export format inconsistencies
			\item Handling unstructured JSON/XML from APIs, as many modern data sources are API-driven, not file-based
        \end{itemize}
      \end{itemize}
    \end{column}
\end{columns}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Handling Collaborative Document Formats}
      \begin{itemize}
        \item \textbf{Notion Documents:}
        \begin{itemize}
            \item Block-based structure requires specialized parsing
            \item Databases and relations need graph representation
            \item Toggle lists and callouts often lost in conversion
            \item Solution: Use official Notion API + custom post-processing
        \end{itemize}
        \item \textbf{Confluence Pages:}
        \begin{itemize}
            \item Macro expansions and dynamic content
            \item Nested page hierarchies and attachments
            \item Storage format vs. view format discrepancies
            \item Solution: REST API extraction + HTML parsing hybrid
        \end{itemize}
        \item \textbf{Google Workspace:}
        \begin{itemize}
            \item Suggested edits and comments metadata
            \item Real-time sync state management
            \item Permission-based content visibility
            \item Solution: Google Drive API with export format selection
        \end{itemize}
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Multimodal Parsing: The Next Frontier}
      \begin{itemize}
        \item \textbf{Beyond Text: Understanding All Content Types}
        \begin{itemize}
            \item Text, tables, images, charts, diagrams, code blocks
            \item Each modality requires specialized extraction
            \item Traditional parsers lose 40-60\% of information
        \end{itemize}
        \item \textbf{Why Multimodal Matters for RAG:}
        \begin{itemize}
            \item Financial reports: Tables contain critical metrics
            \item Technical docs: Diagrams explain architecture
            \item Research papers: Figures show experimental results
            \item Code repositories: Mixed text and code context
        \end{itemize}
        \item \textbf{Key Technologies:}
        \begin{itemize}
            \item Vision-Language Models (VLMs): BLIP-2, LLaVA, GPT-4V
            \item Layout-aware parsers: Docling, LayoutLMv3
            \item Table extraction: Table Transformer models
            \item OCR + structure: Tesseract + layout analysis
        \end{itemize}
        \item \textit{Note: Detailed multimodal implementation covered in next section}
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Parser Performance Benchmarks}
      \begin{itemize}
        \item \textbf{Benchmark Dataset:} 100 diverse documents (contracts, reports, papers)
        \item \textbf{Metrics:} Text accuracy, table preservation, layout fidelity
      \end{itemize}
      
\begin{table}[h]
\centering
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Parser} & \textbf{Text Acc.} & \textbf{Table Acc.} & \textbf{Layout} & \textbf{Overall} \\
\hline
PyPDF & 85\% & 35\% & 40\% & 53\% \\
\hline
Tesseract OCR & 78\% & 62\% & 55\% & 65\% \\
\hline
Unstructured & 89\% & 71\% & 68\% & 76\% \\
\hline
LlamaParse & 92\% & 88\% & 85\% & 88\% \\
\hline
Docling & 94\% & 91\% & 89\% & 91\% \\
\hline
Azure Doc Intel & 96\% & 94\% & 92\% & 94\% \\
\hline
\end{tabular}
\end{table}

      \begin{itemize}
        \item \textbf{Key Insight:} 20-40 point difference between worst and best performers
        \item \textbf{Impact:} Parser choice often matters more than model selection
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{RAG Performance: Impact of Parser Quality}
      \begin{itemize}
        \item \textbf{Experiment Setup:}
        \begin{itemize}
            \item Same RAG pipeline (embedding model, retriever, LLM)
            \item Same 50 test documents (financial reports, technical docs)
            \item Same 200 evaluation questions with ground truth
            \item Only variable: document parser
        \end{itemize}
        \item \textbf{Results - Answer Accuracy:}
        \begin{itemize}
            \item PyPDF baseline: 58\% correct answers
            \item Tesseract OCR: 64\% (+6 points)
            \item Unstructured: 72\% (+14 points)
            \item LlamaParse: 78\% (+20 points)
            \item Docling: 81\% (+23 points)
        \end{itemize}
        \item \textbf{Key Finding:} Upgrading parser improved accuracy by 23 percentage points
        \item \textbf{Comparison:} Upgrading from GPT-3.5 to GPT-4: +12 points (with same parser)
        \item \textbf{Conclusion:} Parser quality = 2x impact of model upgrade
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Performance Benchmarks: Processing Speed}
      \begin{itemize}
        \item \textbf{Test Setup:} Intel Xeon 8-core, 32GB RAM, NVIDIA RTX 3080
        \item \textbf{Document Types:} Research papers, business reports, technical manuals
      \end{itemize}

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Doc Size} & \textbf{Pages} & \textbf{CPU Only} & \textbf{GPU} & \textbf{Throughput} \\
\hline
Small & 1-5 & 2-5s & 1-2s & 12-30 docs/min \\
\hline
Medium & 10-20 & 8-15s & 3-6s & 4-10 docs/min \\
\hline
Large & 50-100 & 45-90s & 15-30s & 1-2 docs/min \\
\hline
Very Large & 200+ & 3-6min & 1-2min & 0.3-0.5 docs/min \\
\hline
\end{tabular}
\end{table}

      \begin{itemize}
        \item \textbf{Factors Affecting Speed:}
        \begin{itemize}
            \item OCR requirement: +50-100\% processing time
            \item Complex tables: +20-30\% per page
            \item Image resolution: Higher DPI = slower processing
            \item Layout complexity: Multi-column layouts add 10-20\%
        \end{itemize}
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Performance Benchmarks: Memory Requirements}
      \begin{itemize}
        \item \textbf{Base Memory Usage:}
        \begin{itemize}
            \item Python process: ~500 MB
            \item Model loading: ~1-2 GB (layout, table models)
            \item Per-document processing: 50-200 MB depending on size
        \end{itemize}
        \item \textbf{Memory Scaling by Document Size:}
      \end{itemize}

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Document} & \textbf{Peak RAM} & \textbf{GPU VRAM} & \textbf{Disk Cache} \\
\hline
10-page PDF & 2.5 GB & 1 GB & 50 MB \\
\hline
50-page PDF & 4 GB & 2 GB & 200 MB \\
\hline
100-page PDF & 6 GB & 3 GB & 400 MB \\
\hline
500-page PDF & 12 GB & 6 GB & 2 GB \\
\hline
\end{tabular}
\end{table}

      \begin{itemize}
        \item \textbf{Memory Optimization Tips:}
        \begin{itemize}
            \item Process large documents in batches
            \item Clear cache between documents: \texttt{gc.collect()}
            \item Use document streaming for very large files
            \item Disable features not needed (OCR, table extraction)
        \end{itemize}
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Comparison: Docling vs Other Parsers}

\begin{table}[h]
\centering
\tiny
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\textbf{Feature} & \textbf{PyPDF} & \textbf{Tesseract} & \textbf{Unstructured} & \textbf{LlamaParse} & \textbf{Docling} & \textbf{Azure DI} \\
\hline
Text Extraction & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
\hline
Layout Analysis & $ \times $ & $ \times $ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
\hline
Table Structure & $ \times $ & ~ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
\hline
OCR Support & $ \times $ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
\hline
Reading Order & $ \times $ & $ \times $ & ~ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
\hline
Formulas/Math & $ \times $ & $ \times $ & $ \times $ & ~ & $\checkmark$ & ~ \\
\hline
Multi-format & PDF & Image & Many & PDF & Many & Many \\
\hline
Local Execution & $\checkmark$ & $\checkmark$ & $\checkmark$ & $ \checkmark $ & $\checkmark$ & $ \times $ \\
\hline
Open Source & $\checkmark$ & $\checkmark$ & $\checkmark$ & $ \times $ & $\checkmark$ & $ \times $ \\
\hline
Confidence Scores & $ \times $ & ~ & $ \times $ & $ \times $ & $\checkmark$ & $\checkmark$ \\
\hline
Structured Output & $ \times $ & $ \times $ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ \\
\hline
Speed (10pg) & <1s & 5-10s & 3-5s & 8-12s & 2-4s & 4-8s \\
\hline
Cost/1K docs & \$0 & \$0 & \$0-50 & \$100-200 & \$0 & \$150-300 \\
\hline
\end{tabular}
\end{table}

      \begin{itemize}
        \item $\checkmark$ = Full support, ~ = Partial support, $ \times $ = No support
        \item \textbf{Docling's Unique Strengths:} Open source, local execution, confidence scores, unified document model
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Docling Advantages: Key Differentiators}
      \begin{itemize}
        \item \textbf{1. Unified Document Representation}
        \begin{itemize}
            \item Single DoclingDocument format for all content types
            \item Consistent API across PDF, DOCX, PPTX, HTML
            \item Preserves hierarchical structure and metadata
        \end{itemize}
        \item \textbf{2. Advanced Layout Understanding}
        \begin{itemize}
            \item Deep learning models for layout analysis
            \item Accurate reading order detection
            \item Multi-column and complex layout support
        \end{itemize}
        \item \textbf{3. Built-in Quality Assessment}
        \begin{itemize}
            \item Confidence scores at page and document level
            \item Quality grades: POOR, FAIR, GOOD, EXCELLENT
            \item Enables automated quality control
        \end{itemize}
        \item \textbf{4. Production-Ready Features}
        \begin{itemize}
            \item Local execution for data privacy
            \item Plugin system for extensibility
            \item Integration with major RAG frameworks
            \item Comprehensive error handling
        \end{itemize}
		\item \textbf{5. Offline First \& Air-Gapped Environments}: Because Docling can be run entirely locally, it is suitable for high-security or regulated industries like finance and healthcare where data cannot be sent to third-party APIs.
      \end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Cost Comparison: Parsing Solutions}
\begin{table}[h]
\centering
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Solution} & \textbf{Type} & \textbf{Cost/1K docs} & \textbf{Setup} & \textbf{Latency} \\
\hline
PyPDF & Open Source & \$0 & Easy & 0.5s \\
\hline
Tesseract & Open Source & \$0* & Medium & 3-5s \\
\hline
Unstructured & Open/Hosted & \$0-\$50 & Easy & 2-4s \\
\hline
LlamaParse & API & \$100-\$200 & Easy & 5-8s \\
\hline
Docling & Open Source & \$0* & Medium & 2-3s \\
\hline
Azure Doc Intel & Cloud API & \$150-\$300 & Easy & 3-6s \\
\hline
AWS Textract & Cloud API & \$150-\$500 & Easy & 4-7s \\
\hline
\end{tabular}
\end{table}

      \begin{itemize}
        \item *Compute costs only (CPU/GPU hours)
        \item \textbf{Open source:} Higher setup, lower marginal cost, full control
        \item \textbf{API services:} Quick start, predictable pricing, limited customization
        \item \textbf{Recommendation:} Start with open source, switch to API at scale
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Cost-Performance Tradeoff Analysis}
      \begin{itemize}
        \item \textbf{Total Cost of Ownership (TCO) for 1M documents/year:}
      \end{itemize}

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Parser} & \textbf{API Cost} & \textbf{Compute} & \textbf{Dev/Ops} & \textbf{Total} \\
\hline
PyPDF & \$0 & \$500 & \$2,000 & \$2,500 \\
\hline
Docling & \$0 & \$2,000 & \$5,000 & \$7,000 \\
\hline
LlamaParse & \$100,000 & \$0 & \$1,000 & \$101,000 \\
\hline
Azure Doc Intel & \$200,000 & \$0 & \$1,000 & \$201,000 \\
\hline
\end{tabular}
\end{table}

      \begin{itemize}
        \item \textbf{Decision Matrix:}
        \begin{itemize}
            \item less than 100K docs/year: Any parser works, optimize for dev time
            \item 100K-1M docs/year: Open source (Docling) offers best ROI
            \item 1M-10M docs/year: Hybrid approach (open source + API fallback)
            \item More than 10M docs/year: Custom solution or negotiated enterprise API pricing
        \end{itemize}
        \item \textbf{Quality Factor:} Higher accuracy reduces downstream costs (fewer errors, less human review)
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Hidden Costs in Production Parsing}
      \begin{itemize}
        \item \textbf{Infrastructure Costs:}
        \begin{itemize}
            \item GPU requirements for advanced parsers (Docling, LayoutLM)
            \item Storage for raw + processed documents
            \item Network bandwidth for cloud API calls
            \item Caching infrastructure to reduce redundant processing
        \end{itemize}
        \item \textbf{Operational Costs:}
        \begin{itemize}
            \item Monitoring and error tracking systems
            \item Human review for failed/low-confidence parses (10-20\% of docs)
            \item Retry logic and fallback parser costs
            \item Version upgrades and model retraining
        \end{itemize}
        \item \textbf{Quality Costs:}
        \begin{itemize}
            \item False negatives in retrieval due to poor parsing
            \item User trust loss from incorrect RAG responses
            \item Manual data cleaning and correction
        \end{itemize}
        \item \textbf{Rule of Thumb:} Budget 2-3x the direct parsing cost for full production system
      \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Choosing a Parser: Decision Framework}
      \begin{itemize}
        \item \textbf{Step 1: Assess Your Document Types}
        \begin{itemize}
            \item Simple text PDFs → PyPDF, pypdf
            \item Scanned documents → Tesseract, Docling (with OCR)
            \item Complex layouts/tables → Docling, LlamaParse, Azure Doc Intel
            \item Cloud-native → API-based solutions (Notion API, etc.)
        \end{itemize}
        \item \textbf{Step 2: Define Quality Requirements}
        \begin{itemize}
            \item Acceptable error rate? (Text: <5\%, Tables: <10\%)
            \item Manual review budget available?
            \item Impact of parsing errors on downstream tasks
        \end{itemize}
        \item \textbf{Step 3: Calculate Total Cost}
        \begin{itemize}
            \item API pricing × volume
            \item Compute costs (GPU hours × rate)
            \item Development + operational overhead
        \end{itemize}
        \item \textbf{Step 4: Prototype and Benchmark}
        \begin{itemize}
            \item Test 2-3 parsers on representative sample (50-100 docs)
            \item Measure accuracy, speed, cost
            \item Run end-to-end RAG evaluation
        \end{itemize}
      \end{itemize}
\end{frame}